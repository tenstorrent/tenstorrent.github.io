Search.setIndex({"docnames": ["_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/001", "_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/002", "_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/003", "_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/004", "_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/005", "_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/006", "_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/007", "index", "resources/contributing", "resources/support", "tt_metal_models/get_performance", "tt_metal_models/get_started", "ttnn/about", "ttnn/adding_new_ttnn_operation", "ttnn/api", "ttnn/converting_torch_model_to_ttnn", "ttnn/demos", "ttnn/dependencies/examples", "ttnn/dependencies/index", "ttnn/dependencies/tensor", "ttnn/dependencies/tt_lib", "ttnn/get_started", "ttnn/onboarding", "ttnn/profiling_ttnn_operations", "ttnn/tensor", "ttnn/ttnn/MaxPool2d", "ttnn/ttnn/abs", "ttnn/ttnn/acos", "ttnn/ttnn/acosh", "ttnn/ttnn/add", "ttnn/ttnn/addcdiv", "ttnn/ttnn/addcmul", "ttnn/ttnn/arange", "ttnn/ttnn/argmax", "ttnn/ttnn/as_tensor", "ttnn/ttnn/asin", "ttnn/ttnn/asinh", "ttnn/ttnn/atan", "ttnn/ttnn/atan2", "ttnn/ttnn/atanh", "ttnn/ttnn/cbrt", "ttnn/ttnn/celu", "ttnn/ttnn/clip", "ttnn/ttnn/clone", "ttnn/ttnn/close_device", "ttnn/ttnn/concat", "ttnn/ttnn/cos", "ttnn/ttnn/cosh", "ttnn/ttnn/create_sharded_memory_config", "ttnn/ttnn/deallocate", "ttnn/ttnn/deg2rad", "ttnn/ttnn/digamma", "ttnn/ttnn/dump_tensor", "ttnn/ttnn/elu", "ttnn/ttnn/embedding", "ttnn/ttnn/empty", "ttnn/ttnn/eq", "ttnn/ttnn/eqz", "ttnn/ttnn/erf", "ttnn/ttnn/erfc", "ttnn/ttnn/erfinv", "ttnn/ttnn/exp", "ttnn/ttnn/exp2", "ttnn/ttnn/expm1", "ttnn/ttnn/from_device", "ttnn/ttnn/from_torch", "ttnn/ttnn/full", "ttnn/ttnn/full_like", "ttnn/ttnn/ge", "ttnn/ttnn/geglu", "ttnn/ttnn/gelu", "ttnn/ttnn/gez", "ttnn/ttnn/global_avg_pool2d", "ttnn/ttnn/glu", "ttnn/ttnn/group_norm", "ttnn/ttnn/gt", "ttnn/ttnn/gtz", "ttnn/ttnn/hardshrink", "ttnn/ttnn/hardsigmoid", "ttnn/ttnn/hardswish", "ttnn/ttnn/hardtanh", "ttnn/ttnn/heaviside", "ttnn/ttnn/hypot", "ttnn/ttnn/i0", "ttnn/ttnn/isclose", "ttnn/ttnn/isfinite", "ttnn/ttnn/isinf", "ttnn/ttnn/isnan", "ttnn/ttnn/isneginf", "ttnn/ttnn/isposinf", "ttnn/ttnn/kv_cache/fill_cache_for_user_", "ttnn/ttnn/kv_cache/update_cache_for_token_", "ttnn/ttnn/l1_loss", "ttnn/ttnn/layer_norm", "ttnn/ttnn/ldexp", "ttnn/ttnn/le", "ttnn/ttnn/leaky_relu", "ttnn/ttnn/lerp", "ttnn/ttnn/lez", "ttnn/ttnn/lgamma", "ttnn/ttnn/linear", "ttnn/ttnn/load_tensor", "ttnn/ttnn/log", "ttnn/ttnn/log10", "ttnn/ttnn/log1p", "ttnn/ttnn/log2", "ttnn/ttnn/log_sigmoid", "ttnn/ttnn/logaddexp", "ttnn/ttnn/logaddexp2", "ttnn/ttnn/logical_and", "ttnn/ttnn/logical_not", "ttnn/ttnn/logical_or", "ttnn/ttnn/logical_xor", "ttnn/ttnn/logit", "ttnn/ttnn/lt", "ttnn/ttnn/ltz", "ttnn/ttnn/mac", "ttnn/ttnn/manage_device", "ttnn/ttnn/matmul", "ttnn/ttnn/max", "ttnn/ttnn/maximum", "ttnn/ttnn/mean", "ttnn/ttnn/min", "ttnn/ttnn/minimum", "ttnn/ttnn/mish", "ttnn/ttnn/model_preprocessing/preprocess_model", "ttnn/ttnn/model_preprocessing/preprocess_model_parameters", "ttnn/ttnn/mse_loss", "ttnn/ttnn/multigammaln", "ttnn/ttnn/multiply", "ttnn/ttnn/ne", "ttnn/ttnn/neg", "ttnn/ttnn/nextafter", "ttnn/ttnn/nez", "ttnn/ttnn/ones", "ttnn/ttnn/ones_like", "ttnn/ttnn/open_device", "ttnn/ttnn/pad", "ttnn/ttnn/permute", "ttnn/ttnn/polygamma", "ttnn/ttnn/polyval", "ttnn/ttnn/pow", "ttnn/ttnn/prelu", "ttnn/ttnn/rad2deg", "ttnn/ttnn/reallocate", "ttnn/ttnn/reciprocal", "ttnn/ttnn/register_post_operation_hook", "ttnn/ttnn/register_pre_operation_hook", "ttnn/ttnn/reglu", "ttnn/ttnn/relu", "ttnn/ttnn/relu6", "ttnn/ttnn/repeat", "ttnn/ttnn/repeat_interleave", "ttnn/ttnn/reshape", "ttnn/ttnn/rms_norm", "ttnn/ttnn/rsqrt", "ttnn/ttnn/set_printoptions", "ttnn/ttnn/sigmoid", "ttnn/ttnn/sigmoid_accurate", "ttnn/ttnn/sign", "ttnn/ttnn/signbit", "ttnn/ttnn/silu", "ttnn/ttnn/sin", "ttnn/ttnn/sinh", "ttnn/ttnn/softmax", "ttnn/ttnn/softplus", "ttnn/ttnn/softshrink", "ttnn/ttnn/softsign", "ttnn/ttnn/split", "ttnn/ttnn/sqrt", "ttnn/ttnn/square", "ttnn/ttnn/squared_difference", "ttnn/ttnn/std", "ttnn/ttnn/subtract", "ttnn/ttnn/sum", "ttnn/ttnn/swiglu", "ttnn/ttnn/swish", "ttnn/ttnn/synchronize_device", "ttnn/ttnn/tan", "ttnn/ttnn/tanh", "ttnn/ttnn/tanhshrink", "ttnn/ttnn/threshold", "ttnn/ttnn/to_device", "ttnn/ttnn/to_layout", "ttnn/ttnn/to_memory_config", "ttnn/ttnn/to_torch", "ttnn/ttnn/topk", "ttnn/ttnn/transformer/attention_softmax", "ttnn/ttnn/transformer/attention_softmax_", "ttnn/ttnn/transformer/concatenate_heads", "ttnn/ttnn/transformer/rotary_embedding", "ttnn/ttnn/transformer/split_query_key_value_and_split_heads", "ttnn/ttnn/tril", "ttnn/ttnn/triu", "ttnn/ttnn/upsample", "ttnn/ttnn/var", "ttnn/ttnn/where", "ttnn/ttnn/xlogy", "ttnn/ttnn/zeros", "ttnn/ttnn/zeros_like", "ttnn/tutorials", "ttnn/tutorials/graphing_torch_dit", "ttnn/tutorials/matmul", "ttnn/tutorials/multihead-attention", "ttnn/tutorials/profiling", "ttnn/tutorials/resnet-basic-block", "ttnn/tutorials/tensor_and_add_operation", "ttnn/tutorials/ttnn-tracer", "ttnn/tutorials/ttnn_tutorials/001", "ttnn/tutorials/ttnn_tutorials/002", "ttnn/tutorials/ttnn_tutorials/003", "ttnn/tutorials/ttnn_tutorials/004", "ttnn/tutorials/ttnn_tutorials/005", "ttnn/tutorials/ttnn_tutorials/006", "ttnn/tutorials/ttnn_tutorials/007", "ttnn/usage", "ttnn_sweeps/index"], "filenames": ["_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/001.ipynb", "_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/002.ipynb", "_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/003.ipynb", "_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/004.ipynb", "_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/005.ipynb", "_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/006.ipynb", "_build/doctrees/nbsphinx/ttnn/tutorials/ttnn_tutorials/007.ipynb", "index.rst", "resources/contributing.rst", "resources/support.rst", "tt_metal_models/get_performance.rst", "tt_metal_models/get_started.rst", "ttnn/about.rst", "ttnn/adding_new_ttnn_operation.rst", "ttnn/api.rst", "ttnn/converting_torch_model_to_ttnn.rst", "ttnn/demos.rst", "ttnn/dependencies/examples.rst", "ttnn/dependencies/index.rst", "ttnn/dependencies/tensor.rst", "ttnn/dependencies/tt_lib.rst", "ttnn/get_started.rst", "ttnn/onboarding.rst", "ttnn/profiling_ttnn_operations.rst", "ttnn/tensor.rst", "ttnn/ttnn/MaxPool2d.rst", "ttnn/ttnn/abs.rst", "ttnn/ttnn/acos.rst", "ttnn/ttnn/acosh.rst", "ttnn/ttnn/add.rst", "ttnn/ttnn/addcdiv.rst", "ttnn/ttnn/addcmul.rst", "ttnn/ttnn/arange.rst", "ttnn/ttnn/argmax.rst", "ttnn/ttnn/as_tensor.rst", "ttnn/ttnn/asin.rst", "ttnn/ttnn/asinh.rst", "ttnn/ttnn/atan.rst", "ttnn/ttnn/atan2.rst", "ttnn/ttnn/atanh.rst", "ttnn/ttnn/cbrt.rst", "ttnn/ttnn/celu.rst", "ttnn/ttnn/clip.rst", "ttnn/ttnn/clone.rst", "ttnn/ttnn/close_device.rst", "ttnn/ttnn/concat.rst", "ttnn/ttnn/cos.rst", "ttnn/ttnn/cosh.rst", "ttnn/ttnn/create_sharded_memory_config.rst", "ttnn/ttnn/deallocate.rst", "ttnn/ttnn/deg2rad.rst", "ttnn/ttnn/digamma.rst", "ttnn/ttnn/dump_tensor.rst", "ttnn/ttnn/elu.rst", "ttnn/ttnn/embedding.rst", "ttnn/ttnn/empty.rst", "ttnn/ttnn/eq.rst", "ttnn/ttnn/eqz.rst", "ttnn/ttnn/erf.rst", "ttnn/ttnn/erfc.rst", "ttnn/ttnn/erfinv.rst", "ttnn/ttnn/exp.rst", "ttnn/ttnn/exp2.rst", "ttnn/ttnn/expm1.rst", "ttnn/ttnn/from_device.rst", "ttnn/ttnn/from_torch.rst", "ttnn/ttnn/full.rst", "ttnn/ttnn/full_like.rst", "ttnn/ttnn/ge.rst", "ttnn/ttnn/geglu.rst", "ttnn/ttnn/gelu.rst", "ttnn/ttnn/gez.rst", "ttnn/ttnn/global_avg_pool2d.rst", "ttnn/ttnn/glu.rst", "ttnn/ttnn/group_norm.rst", "ttnn/ttnn/gt.rst", "ttnn/ttnn/gtz.rst", "ttnn/ttnn/hardshrink.rst", "ttnn/ttnn/hardsigmoid.rst", "ttnn/ttnn/hardswish.rst", "ttnn/ttnn/hardtanh.rst", "ttnn/ttnn/heaviside.rst", "ttnn/ttnn/hypot.rst", "ttnn/ttnn/i0.rst", "ttnn/ttnn/isclose.rst", "ttnn/ttnn/isfinite.rst", "ttnn/ttnn/isinf.rst", "ttnn/ttnn/isnan.rst", "ttnn/ttnn/isneginf.rst", "ttnn/ttnn/isposinf.rst", "ttnn/ttnn/kv_cache/fill_cache_for_user_.rst", "ttnn/ttnn/kv_cache/update_cache_for_token_.rst", "ttnn/ttnn/l1_loss.rst", "ttnn/ttnn/layer_norm.rst", "ttnn/ttnn/ldexp.rst", "ttnn/ttnn/le.rst", "ttnn/ttnn/leaky_relu.rst", "ttnn/ttnn/lerp.rst", "ttnn/ttnn/lez.rst", "ttnn/ttnn/lgamma.rst", "ttnn/ttnn/linear.rst", "ttnn/ttnn/load_tensor.rst", "ttnn/ttnn/log.rst", "ttnn/ttnn/log10.rst", "ttnn/ttnn/log1p.rst", "ttnn/ttnn/log2.rst", "ttnn/ttnn/log_sigmoid.rst", "ttnn/ttnn/logaddexp.rst", "ttnn/ttnn/logaddexp2.rst", "ttnn/ttnn/logical_and.rst", "ttnn/ttnn/logical_not.rst", "ttnn/ttnn/logical_or.rst", "ttnn/ttnn/logical_xor.rst", "ttnn/ttnn/logit.rst", "ttnn/ttnn/lt.rst", "ttnn/ttnn/ltz.rst", "ttnn/ttnn/mac.rst", "ttnn/ttnn/manage_device.rst", "ttnn/ttnn/matmul.rst", "ttnn/ttnn/max.rst", "ttnn/ttnn/maximum.rst", "ttnn/ttnn/mean.rst", "ttnn/ttnn/min.rst", "ttnn/ttnn/minimum.rst", "ttnn/ttnn/mish.rst", "ttnn/ttnn/model_preprocessing/preprocess_model.rst", "ttnn/ttnn/model_preprocessing/preprocess_model_parameters.rst", "ttnn/ttnn/mse_loss.rst", "ttnn/ttnn/multigammaln.rst", "ttnn/ttnn/multiply.rst", "ttnn/ttnn/ne.rst", "ttnn/ttnn/neg.rst", "ttnn/ttnn/nextafter.rst", "ttnn/ttnn/nez.rst", "ttnn/ttnn/ones.rst", "ttnn/ttnn/ones_like.rst", "ttnn/ttnn/open_device.rst", "ttnn/ttnn/pad.rst", "ttnn/ttnn/permute.rst", "ttnn/ttnn/polygamma.rst", "ttnn/ttnn/polyval.rst", "ttnn/ttnn/pow.rst", "ttnn/ttnn/prelu.rst", "ttnn/ttnn/rad2deg.rst", "ttnn/ttnn/reallocate.rst", "ttnn/ttnn/reciprocal.rst", "ttnn/ttnn/register_post_operation_hook.rst", "ttnn/ttnn/register_pre_operation_hook.rst", "ttnn/ttnn/reglu.rst", "ttnn/ttnn/relu.rst", "ttnn/ttnn/relu6.rst", "ttnn/ttnn/repeat.rst", "ttnn/ttnn/repeat_interleave.rst", "ttnn/ttnn/reshape.rst", "ttnn/ttnn/rms_norm.rst", "ttnn/ttnn/rsqrt.rst", "ttnn/ttnn/set_printoptions.rst", "ttnn/ttnn/sigmoid.rst", "ttnn/ttnn/sigmoid_accurate.rst", "ttnn/ttnn/sign.rst", "ttnn/ttnn/signbit.rst", "ttnn/ttnn/silu.rst", "ttnn/ttnn/sin.rst", "ttnn/ttnn/sinh.rst", "ttnn/ttnn/softmax.rst", "ttnn/ttnn/softplus.rst", "ttnn/ttnn/softshrink.rst", "ttnn/ttnn/softsign.rst", "ttnn/ttnn/split.rst", "ttnn/ttnn/sqrt.rst", "ttnn/ttnn/square.rst", "ttnn/ttnn/squared_difference.rst", "ttnn/ttnn/std.rst", "ttnn/ttnn/subtract.rst", "ttnn/ttnn/sum.rst", "ttnn/ttnn/swiglu.rst", "ttnn/ttnn/swish.rst", "ttnn/ttnn/synchronize_device.rst", "ttnn/ttnn/tan.rst", "ttnn/ttnn/tanh.rst", "ttnn/ttnn/tanhshrink.rst", "ttnn/ttnn/threshold.rst", "ttnn/ttnn/to_device.rst", "ttnn/ttnn/to_layout.rst", "ttnn/ttnn/to_memory_config.rst", "ttnn/ttnn/to_torch.rst", "ttnn/ttnn/topk.rst", "ttnn/ttnn/transformer/attention_softmax.rst", "ttnn/ttnn/transformer/attention_softmax_.rst", "ttnn/ttnn/transformer/concatenate_heads.rst", "ttnn/ttnn/transformer/rotary_embedding.rst", "ttnn/ttnn/transformer/split_query_key_value_and_split_heads.rst", "ttnn/ttnn/tril.rst", "ttnn/ttnn/triu.rst", "ttnn/ttnn/upsample.rst", "ttnn/ttnn/var.rst", "ttnn/ttnn/where.rst", "ttnn/ttnn/xlogy.rst", "ttnn/ttnn/zeros.rst", "ttnn/ttnn/zeros_like.rst", "ttnn/tutorials.rst", "ttnn/tutorials/graphing_torch_dit.rst", "ttnn/tutorials/matmul.rst", "ttnn/tutorials/multihead-attention.rst", "ttnn/tutorials/profiling.rst", "ttnn/tutorials/resnet-basic-block.rst", "ttnn/tutorials/tensor_and_add_operation.rst", "ttnn/tutorials/ttnn-tracer.rst", "ttnn/tutorials/ttnn_tutorials/001.ipynb", "ttnn/tutorials/ttnn_tutorials/002.ipynb", "ttnn/tutorials/ttnn_tutorials/003.ipynb", "ttnn/tutorials/ttnn_tutorials/004.ipynb", "ttnn/tutorials/ttnn_tutorials/005.ipynb", "ttnn/tutorials/ttnn_tutorials/006.ipynb", "ttnn/tutorials/ttnn_tutorials/007.ipynb", "ttnn/usage.rst", "ttnn_sweeps/index.rst"], "titles": ["Tensor and Add Operation", "Matrix Multiplication", "Multi-Head Attention", "Tracing ttnn operations and torch modules/functions", "Profiling ttnn operations", "Resnet Block", "Build a graph of a pytorch based model", "Welcome to TT-NN documentation!", "Contributing as a developer", "Support", "Performance", "Getting Started", "What is ttnn?", "Adding New ttnn Operation", "APIs", "Converting torch Model to ttnn", "Building and Uplifting Demos", "Examples of Tensor and TT-LIB Use", "Dependencies", "Tensor", "TT-LIB", "Getting Started", "Onboarding New Functionality", "Profiling ttnn Operations", "Tensor", "ttnn.MaxPool2d", "ttnn.abs", "ttnn.acos", "ttnn.acosh", "ttnn.add", "ttnn.addcdiv", "ttnn.addcmul", "ttnn.arange", "ttnn.argmax", "ttnn.as_tensor", "ttnn.asin", "ttnn.asinh", "ttnn.atan", "ttnn.atan2", "ttnn.atanh", "ttnn.cbrt", "ttnn.celu", "ttnn.clip", "ttnn.clone", "ttnn.close_device", "ttnn.concat", "ttnn.cos", "ttnn.cosh", "ttnn.create_sharded_memory_config", "ttnn.deallocate", "ttnn.deg2rad", "ttnn.digamma", "ttnn.dump_tensor", "ttnn.elu", "ttnn.embedding", "ttnn.empty", "ttnn.eq", "ttnn.eqz", "ttnn.erf", "ttnn.erfc", "ttnn.erfinv", "ttnn.exp", "ttnn.exp2", "ttnn.expm1", "ttnn.from_device", "ttnn.from_torch", "ttnn.full", "ttnn.full_like", "ttnn.ge", "ttnn.geglu", "ttnn.gelu", "ttnn.gez", "ttnn.global_avg_pool2d", "ttnn.glu", "ttnn.group_norm", "ttnn.gt", "ttnn.gtz", "ttnn.hardshrink", "ttnn.hardsigmoid", "ttnn.hardswish", "ttnn.hardtanh", "ttnn.heaviside", "ttnn.hypot", "ttnn.i0", "ttnn.isclose", "ttnn.isfinite", "ttnn.isinf", "ttnn.isnan", "ttnn.isneginf", "ttnn.isposinf", "ttnn.kv_cache.fill_cache_for_user_", "ttnn.kv_cache.update_cache_for_token_", "ttnn.l1_loss", "ttnn.layer_norm", "ttnn.ldexp", "ttnn.le", "ttnn.leaky_relu", "ttnn.lerp", "ttnn.lez", "ttnn.lgamma", "ttnn.linear", "ttnn.load_tensor", "ttnn.log", "ttnn.log10", "ttnn.log1p", "ttnn.log2", "ttnn.log_sigmoid", "ttnn.logaddexp", "ttnn.logaddexp2", "ttnn.logical_and", "ttnn.logical_not", "ttnn.logical_or", "ttnn.logical_xor", "ttnn.logit", "ttnn.lt", "ttnn.ltz", "ttnn.mac", "ttnn.manage_device", "ttnn.matmul", "ttnn.max", "ttnn.maximum", "ttnn.mean", "ttnn.min", "ttnn.minimum", "ttnn.mish", "ttnn.model_preprocessing.preprocess_model", "ttnn.model_preprocessing.preprocess_model_parameters", "ttnn.mse_loss", "ttnn.multigammaln", "ttnn.multiply", "ttnn.ne", "ttnn.neg", "ttnn.nextafter", "ttnn.nez", "ttnn.ones", "ttnn.ones_like", "ttnn.open_device", "ttnn.pad", "ttnn.permute", "ttnn.polygamma", "ttnn.polyval", "ttnn.pow", "ttnn.prelu", "ttnn.rad2deg", "ttnn.reallocate", "ttnn.reciprocal", "ttnn.register_post_operation_hook", "ttnn.register_pre_operation_hook", "ttnn.reglu", "ttnn.relu", "ttnn.relu6", "ttnn.repeat", "ttnn.repeat_interleave", "ttnn.reshape", "ttnn.rms_norm", "ttnn.rsqrt", "ttnn.set_printoptions", "ttnn.sigmoid", "ttnn.sigmoid_accurate", "ttnn.sign", "ttnn.signbit", "ttnn.silu", "ttnn.sin", "ttnn.sinh", "ttnn.softmax", "ttnn.softplus", "ttnn.softshrink", "ttnn.softsign", "ttnn.split", "ttnn.sqrt", "ttnn.square", "ttnn.squared_difference", "ttnn.std", "ttnn.subtract", "ttnn.sum", "ttnn.swiglu", "ttnn.swish", "ttnn.synchronize_device", "ttnn.tan", "ttnn.tanh", "ttnn.tanhshrink", "ttnn.threshold", "ttnn.to_device", "ttnn.to_layout", "ttnn.to_memory_config", "ttnn.to_torch", "ttnn.topk", "ttnn.transformer.attention_softmax", "ttnn.transformer.attention_softmax_", "ttnn.transformer.concatenate_heads", "ttnn.transformer.rotary_embedding", "ttnn.transformer.split_query_key_value_and_split_heads", "ttnn.tril", "ttnn.triu", "ttnn.upsample", "ttnn.var", "ttnn.where", "ttnn.xlogy", "ttnn.zeros", "ttnn.zeros_like", "Tutorials", "Graphing Torch DiT_XL_2 With TTNN", "Matmul Operation", "Multi-Head Attention", "ttnn Profiling", "Resnet Basic Block", "Tensor and Add Operation", "ttnn Tracer", "Tensor and Add Operation", "Matrix Multiplication", "Multi-Head Attention", "Tracing ttnn operations and torch modules/functions", "Profiling ttnn operations", "Resnet Block", "Build a graph of a pytorch based model", "Using ttnn", "Placeholder title"], "terms": {"i": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 33, 43, 48, 54, 56, 68, 72, 75, 95, 114, 118, 125, 126, 130, 136, 137, 146, 147, 152, 164, 183, 185, 187, 188, 190, 191, 194, 196, 200, 208, 209, 210, 211, 212, 213, 214, 215], "central": [0, 208], "It": [0, 10, 19, 20, 125, 126, 208], "similar": [0, 2, 23, 208, 210], "sens": [0, 208], "repres": [0, 9, 19, 20, 23, 24, 208], "multi": [0, 7, 20, 24, 34, 194, 200, 208], "dimension": [0, 20, 24, 118, 208], "matrix": [0, 7, 18, 24, 54, 100, 118, 200, 202, 208, 215], "contain": [0, 10, 11, 19, 20, 24, 54, 208], "element": [0, 20, 24, 25, 26, 27, 28, 33, 35, 36, 37, 39, 40, 46, 47, 50, 51, 53, 57, 58, 59, 60, 61, 62, 63, 70, 71, 72, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 96, 98, 99, 102, 103, 104, 105, 106, 115, 124, 128, 131, 133, 137, 140, 143, 145, 149, 150, 151, 152, 155, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 176, 178, 179, 180, 192, 193, 196, 208], "singl": [0, 15, 22, 23, 24, 208], "The": [0, 1, 6, 12, 15, 16, 17, 19, 20, 21, 22, 23, 24, 53, 54, 72, 81, 90, 91, 96, 118, 146, 147, 151, 152, 194, 208, 209, 214, 215], "ar": [0, 1, 2, 10, 11, 13, 15, 16, 17, 19, 20, 21, 23, 24, 118, 146, 147, 191, 194, 200, 208, 209, 210, 215], "few": [0, 16, 24, 208], "kei": [0, 2, 4, 7, 15, 24, 191, 208, 210, 212], "differ": [0, 19, 20, 24, 118, 171, 208, 215], "can": [0, 1, 2, 6, 9, 10, 11, 12, 15, 17, 19, 20, 21, 23, 24, 118, 146, 147, 165, 200, 208, 209, 210, 214, 215], "store": [0, 19, 20, 23, 24, 208], "sram": [0, 208], "dram": [0, 19, 20, 24, 30, 31, 38, 41, 42, 69, 73, 77, 82, 92, 97, 112, 113, 116, 120, 123, 127, 139, 141, 148, 166, 175, 181, 184, 197, 208], "tenstorr": [0, 1, 6, 9, 12, 13, 15, 16, 21, 200, 208, 209, 214], "doesn": [0, 125, 126, 208], "t": [0, 2, 4, 17, 19, 20, 23, 125, 126, 208, 210, 212], "have": [0, 6, 9, 10, 11, 16, 19, 20, 23, 24, 33, 48, 200, 208, 214], "concept": [0, 208], "stride": [0, 5, 20, 25, 208, 213], "howev": [0, 20, 208], "ha": [0, 6, 15, 16, 17, 19, 20, 23, 24, 125, 126, 191, 194, 208, 214, 215], "row": [0, 1, 4, 10, 19, 20, 23, 24, 208, 209, 212], "major": [0, 1, 19, 20, 24, 208, 209], "tile": [0, 1, 4, 19, 20, 23, 24, 26, 27, 29, 35, 37, 46, 53, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 74, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195, 208, 209, 212], "support": [0, 5, 7, 8, 12, 17, 19, 20, 24, 29, 48, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 171, 173, 208, 213], "bfp8": [0, 208], "exampl": [0, 6, 7, 12, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 34, 35, 36, 37, 39, 40, 43, 45, 46, 47, 48, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 68, 70, 71, 72, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 118, 124, 128, 129, 130, 131, 133, 138, 143, 145, 149, 150, 151, 152, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 173, 176, 178, 179, 180, 183, 185, 192, 193, 208, 214], "": [0, 1, 2, 6, 10, 11, 12, 16, 19, 20, 24, 125, 126, 208, 209, 210, 214], "shape": [0, 1, 2, 5, 6, 7, 13, 15, 19, 20, 23, 45, 48, 55, 66, 72, 100, 118, 134, 137, 138, 151, 152, 153, 189, 191, 198, 208, 209, 210, 213, 214], "pad": [0, 5, 7, 14, 17, 18, 19, 20, 24, 25, 43, 54, 183, 208, 213], "ad": [0, 7, 19, 20, 22, 25, 100, 208], "due": [0, 2, 23, 24, 208, 210], "tile_layout": [0, 1, 2, 12, 15, 24, 43, 152, 183, 208, 209, 210, 215], "recommend": [0, 15, 208], "wai": [0, 10, 12, 15, 20, 125, 126, 208], "function": [0, 7, 13, 15, 16, 17, 18, 19, 29, 34, 53, 56, 68, 75, 81, 84, 94, 95, 96, 100, 107, 108, 109, 111, 114, 118, 125, 126, 129, 130, 153, 165, 171, 173, 182, 200, 207, 208], "simpli": [0, 19, 20, 43, 183, 208], "call": [0, 2, 4, 17, 19, 20, 22, 23, 24, 137, 146, 147, 208, 210, 212, 215], "from_torch": [0, 1, 2, 3, 5, 7, 13, 14, 15, 26, 27, 28, 29, 35, 36, 37, 39, 40, 43, 45, 46, 47, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 118, 124, 128, 129, 130, 131, 133, 138, 143, 145, 149, 150, 151, 152, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 173, 176, 178, 179, 180, 183, 184, 185, 192, 193, 208, 209, 210, 211, 213, 215], "so": [0, 6, 15, 17, 19, 20, 208, 214], "let": [0, 2, 20, 24, 208, 210], "import": [0, 1, 2, 3, 4, 5, 6, 13, 15, 16, 17, 23, 208, 209, 210, 211, 212, 213, 214, 215], "both": [0, 5, 9, 15, 16, 19, 20, 23, 24, 25, 118, 208, 213], "1": [0, 1, 2, 3, 4, 5, 6, 7, 10, 13, 17, 19, 20, 22, 24, 25, 26, 27, 28, 34, 35, 36, 37, 39, 40, 43, 45, 46, 47, 50, 51, 53, 57, 58, 59, 60, 61, 62, 63, 65, 69, 70, 71, 72, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 96, 98, 99, 102, 103, 104, 105, 106, 115, 118, 124, 128, 131, 133, 138, 143, 145, 148, 149, 150, 151, 152, 153, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 175, 176, 178, 179, 180, 183, 184, 191, 192, 193, 208, 209, 210, 211, 212, 213, 214], "And": [0, 1, 15, 19, 20, 24, 208, 209], "now": [0, 2, 11, 21, 24, 194, 208, 210], "2": [0, 1, 2, 3, 4, 5, 7, 18, 19, 24, 26, 27, 28, 29, 34, 35, 36, 37, 39, 40, 46, 47, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 68, 70, 71, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 118, 119, 121, 122, 124, 128, 129, 130, 131, 133, 137, 138, 143, 145, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 185, 191, 192, 193, 194, 195, 200, 201, 208, 209, 210, 211, 212, 213], "torch_tensor": [0, 185, 208], "rand": [0, 3, 5, 13, 54, 152, 208, 211, 213, 215], "3": [0, 1, 2, 3, 4, 5, 6, 7, 10, 19, 20, 24, 34, 45, 54, 65, 72, 84, 138, 151, 153, 164, 183, 185, 191, 208, 209, 210, 211, 212, 213, 214], "4": [0, 1, 2, 3, 4, 5, 6, 7, 19, 20, 24, 26, 27, 29, 33, 35, 37, 45, 46, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 74, 75, 76, 81, 83, 84, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 152, 153, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 187, 188, 189, 190, 194, 195, 208, 209, 210, 211, 212, 213, 214], "ttnn_tensor": [0, 185, 208], "print": [0, 1, 2, 4, 6, 17, 19, 20, 23, 24, 34, 45, 65, 100, 118, 138, 151, 152, 164, 183, 185, 208, 209, 210, 212, 214, 215], "f": [0, 1, 2, 4, 6, 208, 209, 210, 212, 214, 215], "dtype": [0, 1, 2, 3, 5, 15, 19, 20, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 39, 40, 43, 45, 46, 47, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 118, 119, 121, 122, 124, 128, 129, 130, 131, 132, 133, 134, 135, 138, 140, 143, 145, 149, 150, 151, 152, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 198, 199, 208, 209, 210, 211, 213, 215], "row_major": [0, 17, 19, 20, 23, 26, 27, 33, 35, 37, 46, 48, 53, 54, 57, 58, 59, 60, 61, 62, 63, 70, 71, 74, 76, 81, 83, 85, 86, 87, 88, 89, 93, 96, 98, 102, 103, 105, 106, 115, 131, 133, 145, 149, 150, 151, 154, 155, 157, 159, 160, 161, 162, 165, 169, 170, 178, 179, 183, 184, 194, 208], "datatyp": [0, 17, 19, 20, 25, 26, 27, 29, 33, 34, 35, 37, 43, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 100, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 118, 119, 121, 122, 129, 130, 131, 132, 133, 134, 135, 140, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195, 198, 199, 208], "float32": [0, 5, 15, 19, 23, 24, 183, 184, 208, 213, 215], "As": [0, 1, 208, 209], "expect": [0, 16, 19, 20, 22, 118, 191, 208], "we": [0, 1, 6, 9, 10, 11, 12, 13, 16, 17, 20, 22, 24, 118, 208, 209, 214, 215], "get": [0, 1, 4, 7, 13, 15, 17, 19, 189, 196, 200, 205, 208, 209, 212], "In": [0, 6, 11, 13, 15, 17, 20, 23, 24, 43, 118, 183, 188, 208, 214], "thi": [0, 1, 2, 6, 8, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 72, 118, 165, 190, 200, 208, 209, 210, 214, 215], "particular": [0, 15, 20, 208], "case": [0, 15, 16, 20, 24, 43, 183, 208], "becaus": [0, 1, 2, 24, 208, 209, 210], "contigu": [0, 20, 191, 208], "match": [0, 1, 3, 4, 5, 7, 19, 20, 24, 125, 126, 194, 200, 203, 208, 209, 211, 212, 213], "current": [0, 20, 21, 24, 48, 118, 125, 126, 200, 201, 202, 203, 204, 205, 206, 207, 208, 215], "set": [0, 4, 6, 10, 11, 15, 17, 19, 20, 23, 189, 191, 196, 200, 208, 212, 214, 215], "1234": [0, 208], "again": [0, 208], "see": [0, 4, 6, 16, 20, 22, 208, 212, 214], "action": [0, 208], "origin": [0, 7, 16, 22, 125, 126, 200, 203, 208], "n": [0, 1, 4, 6, 12, 20, 23, 118, 194, 208, 209, 212, 214], "new": [0, 7, 16, 18, 23, 32, 151, 208], "all": [0, 2, 4, 7, 12, 13, 15, 16, 19, 20, 22, 23, 24, 33, 72, 125, 126, 140, 177, 208, 210, 212], "go": [0, 7, 208], "0": [0, 1, 2, 3, 4, 5, 6, 10, 13, 15, 17, 19, 20, 23, 24, 25, 34, 45, 65, 138, 185, 191, 208, 209, 210, 211, 212, 213, 214, 215], "868396": [0, 208], "199809": [0, 208], "505658": [0, 208], "0919966": [0, 208], "441207": [0, 208], "465399": [0, 208], "225584": [0, 208], "497159": [0, 208], "205919": [0, 208], "219386": [0, 208], "0836022": [0, 208], "761129": [0, 208], "try": [0, 4, 16, 208, 212], "our": [0, 7, 10, 11, 12, 16, 20, 22, 24, 208], "best": [0, 15, 208], "don": [0, 20, 208], "choic": [0, 208], "automat": [0, 1, 16, 17, 20, 23, 24, 43, 100, 118, 183, 208, 209], "pick": [0, 208], "copi": [0, 7, 18, 19, 20, 43, 208], "float16": [0, 208], "bfloat16": [0, 1, 2, 4, 5, 15, 17, 19, 20, 23, 24, 26, 27, 28, 29, 33, 34, 35, 36, 37, 39, 40, 43, 45, 46, 47, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 68, 70, 71, 72, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 118, 119, 121, 122, 124, 128, 129, 130, 131, 133, 138, 143, 145, 149, 150, 151, 152, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 183, 184, 185, 187, 188, 189, 190, 192, 193, 194, 195, 208, 209, 210, 212, 213, 215], "9375": [0, 208], "0683594": [0, 208], "765625": [0, 208], "894531": [0, 208], "100098": [0, 208], "285156": [0, 208], "597656": [0, 208], "21582": [0, 208], "203125": [0, 208], "730469": [0, 208], "310547": [0, 208], "453125": [0, 208], "control": [0, 11, 20, 25, 208], "explicitli": [0, 208], "when": [0, 2, 5, 9, 16, 19, 20, 22, 24, 43, 48, 118, 125, 183, 190, 196, 208, 210, 213, 215], "convers": [0, 7, 17, 19, 20, 183, 208], "from": [0, 2, 3, 4, 7, 9, 10, 11, 12, 13, 15, 16, 18, 19, 23, 24, 34, 44, 90, 91, 173, 196, 200, 201, 205, 208, 210, 211, 212], "5": [0, 1, 2, 3, 4, 5, 6, 7, 19, 20, 48, 54, 153, 208, 209, 210, 211, 212, 213, 214], "hardwar": [0, 9, 12, 13, 15, 16, 21, 24, 208, 215], "most": [0, 208], "effici": [0, 1, 208, 209], "util": [0, 1, 6, 19, 208, 209, 214], "run": [0, 1, 4, 7, 12, 13, 16, 18, 20, 21, 22, 23, 125, 146, 147, 200, 203, 205, 208, 209, 212], "size": [0, 7, 18, 19, 20, 24, 25, 32, 54, 191, 194, 208], "hard": [0, 20, 165, 208], "code": [0, 4, 9, 17, 20, 21, 22, 23, 33, 146, 147, 191, 208, 212, 215], "32": [0, 1, 3, 4, 13, 17, 19, 20, 24, 43, 45, 72, 100, 118, 138, 152, 164, 183, 184, 208, 209, 211, 212, 215], "wa": [0, 6, 16, 23, 24, 208, 214], "determin": [0, 1, 2, 3, 4, 5, 20, 100, 118, 125, 126, 208, 209, 210, 211, 212, 213], "optim": [0, 7, 20, 200, 203, 208], "given": [0, 2, 15, 19, 20, 23, 33, 43, 45, 125, 126, 136, 152, 194, 208, 210], "comput": [0, 1, 10, 12, 20, 23, 72, 74, 93, 94, 100, 107, 108, 109, 111, 118, 154, 164, 171, 187, 188, 191, 208, 209], "memori": [0, 2, 7, 15, 16, 19, 20, 23, 26, 27, 28, 29, 33, 34, 35, 36, 37, 39, 40, 43, 45, 46, 47, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 68, 70, 71, 72, 75, 76, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 118, 124, 128, 129, 130, 131, 132, 133, 137, 143, 145, 149, 150, 151, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 173, 176, 178, 179, 180, 183, 187, 188, 189, 190, 191, 192, 193, 196, 208, 210], "transfer": [0, 208], "constraint": [0, 208], "provid": [0, 2, 11, 12, 16, 19, 20, 22, 23, 24, 33, 125, 126, 164, 208, 210, 215], "easi": [0, 10, 208], "intuit": [0, 12, 208], "back": [0, 2, 17, 23, 189, 208, 210], "6": [0, 1, 2, 3, 4, 5, 6, 7, 19, 20, 24, 208, 209, 210, 211, 212, 213, 214], "nshape": [0, 208], "nlayout": [0, 208], "to_layout": [0, 1, 2, 7, 12, 14, 24, 208, 209, 210], "row_major_layout": [0, 1, 2, 12, 24, 34, 43, 54, 65, 183, 208, 209, 210], "020752": [0, 208], "0820312": [0, 208], "664062": [0, 208], "0742188": [0, 208], "0463867": [0, 208], "785156": [0, 208], "0195312": [0, 208], "304688": [0, 208], "287109": [0, 208], "671875": [0, 208], "808594": [0, 208], "note": [0, 2, 6, 17, 19, 20, 23, 24, 43, 118, 208, 210, 214], "insert": [0, 208], "put": [0, 2, 5, 15, 125, 126, 208, 210, 213], "remov": [0, 4, 6, 19, 20, 44, 118, 185, 208, 212, 214], "after": [0, 17, 20, 22, 23, 118, 132, 137, 146, 208, 215], "done": [0, 4, 16, 19, 20, 23, 208, 212], "cale": [0, 208], "7": [0, 1, 2, 3, 4, 5, 6, 7, 19, 54, 208, 209, 210, 211, 212, 213, 214], "to_torch": [0, 1, 2, 3, 5, 7, 13, 14, 15, 19, 208, 209, 210, 211, 213, 215], "alwai": [0, 2, 4, 200, 208, 210, 212], "final": [0, 15, 16, 17, 22, 118, 208], "order": [0, 2, 19, 20, 23, 24, 48, 118, 138, 200, 208, 210, 215], "actual": [0, 17, 20, 24, 208], "need": [0, 1, 2, 8, 9, 13, 16, 17, 20, 23, 24, 208, 209, 210, 215], "handl": [0, 17, 208], "8": [0, 1, 2, 3, 4, 5, 6, 7, 19, 23, 24, 48, 54, 184, 208, 209, 210, 211, 212, 213, 214], "device_id": [0, 1, 2, 3, 5, 54, 117, 136, 183, 184, 208, 209, 210, 211, 213, 215], "open_devic": [0, 1, 2, 3, 5, 7, 14, 54, 183, 184, 208, 209, 210, 211, 213, 215], "metal": [0, 1, 2, 3, 4, 5, 6, 9, 12, 19, 21, 200, 208, 209, 210, 211, 212, 213, 214], "info": [0, 1, 2, 3, 4, 5, 6, 208, 209, 210, 211, 212, 213, 214], "user": [0, 1, 2, 3, 4, 5, 6, 11, 12, 16, 20, 21, 22, 125, 126, 208, 209, 210, 211, 212, 213, 214, 215], "mode": [0, 1, 2, 3, 4, 5, 20, 58, 59, 61, 70, 155, 208, 209, 210, 211, 212, 213], "driver": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "2024": [0, 1, 2, 3, 4, 5, 6, 208, 209, 210, 211, 212, 213, 214], "02": [0, 1, 3, 4, 5, 208, 209, 211, 212, 213], "16": [0, 1, 2, 4, 6, 10, 24, 208, 209, 210, 212, 214], "19": [0, 3, 4, 6, 208, 211, 212, 214], "46": [0, 1, 4, 5, 10, 208, 209, 212, 213], "597": [0, 208], "silicondriv": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "detect": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "pci": [0, 1, 2, 3, 4, 5, 17, 208, 209, 210, 211, 212, 213], "610": [0, 208], "warn": [0, 1, 2, 3, 4, 5, 23, 208, 209, 210, 211, 212, 213], "init_detect_tt_device_numanod": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "could": [0, 1, 2, 3, 4, 5, 12, 208, 209, 210, 211, 212, 213], "numanodeset": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "tt": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 18, 30, 31, 38, 41, 42, 69, 73, 77, 82, 92, 97, 112, 113, 116, 120, 123, 127, 139, 141, 148, 166, 175, 181, 197, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214], "physical_device_id": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "pci_bus_id": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "0000": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "00": [0, 1, 2, 3, 4, 5, 6, 208, 209, 210, 211, 212, 213, 214], "08": [0, 1, 3, 4, 5, 84, 208, 209, 211, 212, 213], "find": [0, 1, 2, 3, 4, 5, 11, 208, 209, 210, 211, 212, 213], "612": [0, 208], "bind_area_memory_nodeset": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "unabl": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "numanod": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "map": [0, 1, 2, 3, 4, 5, 34, 208, 209, 210, 211, 212, 213], "skip": [0, 1, 2, 3, 4, 5, 6, 208, 209, 210, 211, 212, 213, 214], "membind": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "ttsilicondevic": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "init_hugepag": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "bind_area_to_memory_nodeset": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "fail": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "ch": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "hugepag": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "alloc": [0, 1, 2, 3, 4, 5, 24, 208, 209, 210, 211, 212, 213], "side": [0, 1, 2, 3, 4, 5, 20, 23, 25, 208, 209, 210, 211, 212, 213], "effect": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "decreas": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "gt": [0, 1, 2, 3, 4, 5, 6, 7, 14, 208, 209, 210, 211, 212, 213, 214], "perf": [0, 1, 2, 3, 4, 5, 7, 208, 209, 210, 211, 212, 213], "issu": [0, 1, 2, 3, 4, 5, 9, 16, 22, 23, 165, 208, 209, 210, 211, 212, 213], "893": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "ai": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "clk": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "1202": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "mhz": [0, 1, 2, 3, 4, 5, 208, 209, 210, 211, 212, 213], "To": [0, 1, 10, 17, 20, 22, 208, 209, 215], "chang": [0, 4, 7, 20, 43, 208, 212], "9": [0, 1, 2, 3, 4, 5, 6, 7, 19, 20, 54, 208, 209, 210, 211, 212, 213, 214], "manual_se": [0, 1, 2, 5, 6, 13, 15, 208, 209, 210, 213, 214], "torch_input_tensor_a": [0, 208], "torch_input_tensor_b": [0, 208], "input_tensor_a": [0, 29, 38, 56, 68, 75, 82, 84, 92, 94, 95, 97, 100, 107, 108, 109, 111, 112, 114, 118, 120, 123, 127, 129, 130, 132, 140, 171, 173, 197, 208, 215], "input_tensor_b": [0, 29, 38, 56, 68, 75, 82, 84, 92, 94, 95, 97, 100, 107, 108, 109, 111, 112, 114, 118, 120, 123, 127, 129, 130, 132, 171, 173, 197, 208, 215], "overload": [0, 19, 20, 153, 182, 208], "therefor": [0, 2, 208, 210], "instead": [0, 2, 6, 20, 34, 208, 210, 214], "10": [0, 1, 2, 4, 6, 7, 17, 19, 20, 54, 72, 84, 100, 118, 183, 184, 208, 209, 210, 212, 214], "output_tensor": [0, 5, 13, 20, 29, 33, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 171, 173, 208, 213, 215], "seen": [0, 1, 48, 208, 209], "same": [0, 2, 20, 23, 24, 29, 43, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 125, 126, 129, 130, 171, 173, 183, 208, 210], "produc": [0, 1, 13, 17, 20, 208, 209], "11": [0, 1, 2, 4, 7, 208, 209, 210, 212], "gener": [0, 2, 4, 20, 23, 208, 210, 212, 215, 216], "stai": [0, 208], "unless": [0, 208, 215], "explicit": [0, 208], "argument": [0, 13, 19, 20, 25, 100, 118, 146, 147, 208], "modifi": [0, 17, 20, 165, 208], "them": [0, 11, 20, 23, 191, 208], "pass": [0, 4, 7, 15, 17, 20, 22, 146, 147, 190, 191, 200, 205, 208, 212], "obviou": [0, 208], "except": [0, 2, 4, 20, 208, 210, 212], "like": [0, 8, 15, 17, 20, 24, 165, 208, 215], "an": [0, 2, 6, 7, 9, 10, 12, 19, 20, 21, 22, 23, 24, 25, 54, 72, 118, 208, 210, 214], "embed": [0, 7, 18, 20, 190, 208], "take": [0, 12, 13, 16, 19, 20, 21, 24, 25, 146, 147, 189, 208], "uint32": [0, 19, 20, 23, 24, 33, 54, 72, 151, 183, 184, 208], "move": [0, 2, 3, 4, 5, 16, 17, 19, 20, 208, 210, 211, 212, 213], "figur": [0, 208], "out": [0, 2, 5, 9, 20, 185, 208, 210, 213], "12": [0, 1, 2, 4, 6, 7, 15, 74, 93, 154, 208, 209, 210, 212, 214], "veri": [0, 2, 12, 23, 165, 208, 210], "step": [0, 6, 7, 16, 17, 20, 22, 32, 208, 214], "hang": [0, 208], "properli": [0, 208], "13": [0, 1, 2, 4, 5, 6, 7, 208, 209, 210, 212, 213, 214], "close_devic": [0, 1, 2, 3, 5, 7, 14, 208, 209, 210, 211, 213, 215], "ttnn": [1, 6, 11, 14, 19, 22, 24, 200, 203, 205, 206, 209, 214], "open": [1, 2, 3, 4, 5, 6, 7, 117, 136, 200, 206, 209, 210, 211, 212, 213, 214, 215], "01": [1, 5, 209, 213], "29": [1, 4, 10, 209, 212], "23": [1, 4, 209, 212], "902": [1, 209], "913": [1, 209], "915": [1, 209], "host": [1, 2, 3, 4, 5, 7, 17, 18, 19, 23, 24, 34, 177, 183, 200, 206, 209, 210, 211, 212, 213, 215], "speed": [1, 12, 209], "up": [1, 6, 12, 20, 23, 200, 209, 214], "execut": [1, 2, 4, 10, 16, 17, 20, 23, 146, 147, 209, 210, 212, 215], "oper": [1, 2, 5, 7, 12, 16, 17, 18, 19, 21, 22, 26, 27, 28, 35, 36, 37, 39, 40, 43, 45, 46, 47, 50, 51, 53, 57, 58, 59, 60, 61, 62, 63, 70, 71, 72, 76, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 96, 98, 99, 100, 102, 103, 104, 105, 106, 115, 118, 124, 128, 131, 133, 137, 143, 145, 146, 147, 149, 150, 151, 152, 155, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 176, 177, 178, 179, 180, 183, 185, 192, 193, 200, 204, 207, 209, 210, 213], "repeatedli": [1, 209], "enable_program_cach": [1, 2, 209, 210], "op": [1, 4, 7, 18, 20, 22, 23, 48, 209, 212, 215], "m": [1, 20, 209], "1024": [1, 13, 209], "k": [1, 20, 209], "torch_a": [1, 209], "randn": [1, 2, 6, 17, 19, 34, 65, 72, 100, 118, 183, 184, 185, 209, 210, 214], "torch_b": [1, 209], "finish": [1, 4, 20, 23, 209, 212], "175489": [1, 209], "nanosecond": [1, 23, 209], "to_devic": [1, 2, 7, 14, 29, 43, 54, 56, 68, 75, 84, 94, 95, 100, 107, 108, 109, 111, 114, 118, 129, 130, 138, 164, 171, 173, 183, 184, 209, 210], "326608": [1, 209], "47769": [1, 209], "165459": [1, 209], "longer": [1, 209], "first": [1, 7, 10, 15, 17, 19, 20, 23, 100, 118, 137, 200, 203, 209], "time": [1, 2, 4, 10, 16, 20, 23, 118, 125, 129, 151, 209, 210, 212], "kernel": [1, 20, 23, 25, 100, 118, 209], "compil": [1, 4, 10, 20, 209, 212, 215], "reshap": [1, 2, 3, 4, 5, 7, 14, 17, 18, 19, 20, 191, 209, 210, 211, 212, 213], "38930": [1, 209], "35890": [1, 209], "tt_metal": [1, 4, 13, 19, 20, 23, 30, 31, 38, 41, 42, 69, 73, 77, 82, 92, 97, 112, 113, 116, 120, 123, 127, 139, 141, 148, 166, 175, 181, 197, 209, 212], "matmul": [1, 2, 4, 7, 14, 18, 20, 100, 200, 209, 210, 212], "576872807": [1, 209], "577071926": [1, 209], "99419": [1, 209], "re": [1, 15, 20, 21, 209], "show": [1, 2, 19, 24, 209, 210], "signific": [1, 209], "39200": [1, 209], "22440": [1, 209], "1183694": [1, 209], "1224093": [1, 209], "64480": [1, 209], "That": [1, 19, 24, 209], "much": [1, 20, 23, 209], "acceler": [1, 4, 7, 18, 19, 20, 209, 212], "compar": [1, 12, 20, 56, 68, 75, 114, 130, 209], "aslo": [1, 209], "why": [1, 209], "log": [1, 3, 4, 7, 14, 18, 23, 209, 211, 212], "tiliz": [1, 2, 7, 18, 20, 34, 209, 210], "input": [1, 2, 5, 6, 7, 13, 16, 17, 18, 19, 23, 25, 28, 32, 36, 39, 40, 47, 50, 51, 78, 79, 80, 84, 90, 91, 99, 100, 104, 116, 118, 124, 128, 132, 137, 138, 140, 143, 144, 158, 163, 167, 176, 180, 191, 192, 193, 209, 210, 213, 214, 215], "conver": [1, 209], "thei": [1, 2, 16, 20, 209, 210], "learn": [1, 4, 21, 24, 209, 212], "about": [1, 24, 209], "here": [1, 6, 7, 9, 209, 214, 216], "todo": [1, 209], "convert": [1, 7, 12, 17, 18, 20, 34, 43, 65, 125, 126, 184, 185, 200, 203, 206, 209], "chunk": [1, 6, 7, 18, 20, 209, 214], "until": [1, 7, 13, 18, 20, 185, 209], "508667002": [1, 209], "nanosecondsprint": [1, 209], "508783061": [1, 209], "from_devic": [1, 3, 4, 7, 14, 209, 211, 212], "1352602": [1, 209], "1744890": [1, 209], "34": [1, 4, 5, 209, 212, 213], "25": [1, 4, 6, 23, 183, 209, 212, 214], "625": [1, 209], "3125": [1, 209], "964844": [1, 54, 209], "45312": [1, 209], "26": [1, 4, 209, 212], "875": [1, 209], "125": [1, 209], "39062": [1, 209], "20": [1, 4, 6, 13, 20, 23, 165, 209, 212, 214], "375": [1, 34, 65, 209], "33": [1, 4, 19, 209, 212], "8125": [1, 209], "6875": [1, 209], "18": [1, 2, 4, 6, 209, 210, 212, 214], "14": [1, 2, 4, 7, 10, 24, 209, 210, 212], "42": [1, 2, 4, 6, 209, 210, 212, 214], "75": [1, 209], "27": [1, 4, 6, 209, 212, 214], "44": [1, 3, 4, 209, 211, 212], "43": [1, 3, 4, 209, 211, 212], "45": [1, 2, 4, 20, 209, 210, 212], "39": [1, 2, 4, 6, 54, 209, 210, 212, 214], "4375": [1, 209], "5625": [1, 209], "__getitem__": [1, 7, 209], "711456": [1, 209], "123629": [1, 209], "190228": [1, 209], "By": [1, 22, 165, 209], "default": [1, 17, 19, 20, 23, 25, 48, 54, 100, 118, 125, 126, 187, 188, 209], "might": [1, 16, 20, 209], "effeci": [1, 209], "further": [1, 209], "specifi": [1, 2, 15, 19, 20, 32, 125, 126, 137, 151, 209, 210], "how": [1, 2, 11, 16, 19, 20, 23, 24, 209, 210, 215], "mani": [1, 6, 11, 15, 209, 214], "core": [1, 2, 4, 7, 15, 20, 23, 24, 48, 100, 118, 209, 210, 212], "want": [1, 17, 20, 209, 215], "significantli": [1, 12, 209], "memory_config": [1, 2, 5, 15, 19, 20, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 143, 144, 145, 148, 149, 150, 151, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199, 209, 210, 213], "l1_memory_config": [1, 2, 15, 24, 43, 209, 210], "46380": [1, 209], "33729": [1, 209], "1330892": [1, 209], "1996019": [1, 209], "556706140": [1, 209], "556884870": [1, 209], "424187": [1, 209], "473467": [1, 209], "onc": [1, 13, 209], "core_grid": [1, 2, 15, 48, 100, 118, 209, 210], "coregrid": [1, 2, 48, 100, 118, 209, 210], "y": [1, 2, 6, 19, 20, 23, 24, 196, 209, 210, 214], "x": [1, 2, 5, 6, 19, 20, 23, 24, 100, 118, 196, 209, 210, 213, 214], "116419": [1, 209], "27450": [1, 209], "primari": [1, 7, 12, 18, 209], "652476970": [1, 209], "652929758": [1, 209], "86579": [1, 209], "enjoi": [1, 209], "massiv": [1, 209], "subsequ": [1, 7, 200, 203, 209], "38110": [1, 209], "24079": [1, 209], "129909": [1, 209], "164599": [1, 209], "24209": [1, 209], "part": [2, 11, 16, 20, 23, 210], "transform": [2, 3, 4, 7, 15, 20, 100, 210, 211, 212], "base": [2, 7, 10, 11, 20, 24, 48, 196, 200, 201, 210], "tutori": [2, 6, 7, 201, 202, 203, 204, 205, 206, 207, 210, 214], "l1_small_siz": [2, 3, 210, 211], "8192": [2, 3, 210, 211], "04": [2, 6, 210, 214], "615": [2, 210], "debug": [2, 7, 12, 20, 22, 210], "lt": [2, 4, 5, 6, 7, 14, 20, 210, 212, 213, 214], "modul": [2, 6, 7, 12, 15, 20, 21, 125, 126, 200, 205, 207, 210, 214], "126": [2, 210], "config": [2, 3, 4, 7, 15, 29, 33, 43, 54, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 132, 171, 173, 187, 188, 189, 190, 191, 196, 200, 202, 210, 211, 212, 215], "cache_path": [2, 210], "posixpath": [2, 210], "home": [2, 4, 6, 210, 212, 214], "ubuntu": [2, 4, 6, 210, 212, 214], "comparison_mode_pcc": [2, 210], "9999": [2, 15, 210], "enable_comparison_mod": [2, 210, 215], "fals": [2, 4, 5, 6, 15, 20, 25, 26, 27, 29, 33, 35, 37, 46, 48, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 74, 75, 76, 81, 83, 84, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195, 196, 210, 212, 213, 214, 215], "enable_detailed_buffer_report": [2, 210, 215], "enable_detailed_tensor_report": [2, 210, 215], "enable_fast_runtime_mod": [2, 210, 215], "enable_graph_report": [2, 210, 215], "enable_log": [2, 210, 215], "enable_model_cach": [2, 210], "model_cache_path": [2, 210], "report_nam": [2, 210, 215], "none": [2, 3, 4, 5, 19, 20, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 118, 119, 121, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 140, 143, 144, 145, 146, 147, 149, 150, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 182, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 195, 196, 198, 199, 210, 211, 212, 213], "root_report_path": [2, 210], "report": [2, 4, 7, 16, 210, 212, 215], "throw_exception_on_fallback": [2, 210], "tmp_dir": [2, 6, 210, 214], "tmp": [2, 5, 6, 125, 210, 213, 214], "906": [2, 210], "918": [2, 210], "07": [2, 3, 210, 211], "920": [2, 210], "NOT": [2, 20, 210], "just": [2, 6, 210, 214], "add": [2, 4, 5, 7, 14, 16, 20, 22, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 137, 171, 173, 187, 188, 200, 210, 212, 213, 215], "permut": [2, 5, 7, 14, 18, 20, 191, 210, 213], "mul": [2, 20, 210], "softmax": [2, 7, 14, 18, 20, 187, 188, 210], "exact": [2, 20, 24, 210], "api": [2, 7, 11, 12, 15, 18, 21, 22, 210, 215], "do": [2, 10, 13, 16, 17, 210], "fashion": [2, 210], "should": [2, 16, 19, 20, 21, 22, 23, 137, 183, 210], "mind": [2, 210], "tensor": [2, 3, 5, 6, 7, 11, 12, 13, 15, 18, 23, 28, 30, 31, 32, 34, 36, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 64, 65, 67, 69, 73, 77, 78, 79, 80, 82, 84, 90, 91, 92, 97, 99, 100, 101, 104, 112, 113, 116, 118, 120, 123, 124, 125, 126, 127, 128, 132, 135, 137, 138, 139, 140, 141, 143, 144, 148, 153, 158, 163, 166, 167, 175, 176, 180, 181, 182, 185, 191, 192, 193, 196, 197, 199, 200, 202, 210, 211, 213, 214], "layout": [2, 7, 15, 17, 19, 20, 23, 26, 27, 29, 33, 34, 35, 37, 43, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 134, 135, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195, 198, 199, 200, 202, 206, 210, 215], "def": [2, 3, 4, 5, 6, 13, 15, 210, 211, 212, 213, 214, 215], "multi_head_attent": [2, 210], "hidden_st": [2, 3, 15, 210, 211], "attention_mask": [2, 20, 187, 188, 210], "query_weight": [2, 210], "query_bia": [2, 210], "key_weight": [2, 210], "key_bia": [2, 210], "value_weight": [2, 210], "value_bia": [2, 210], "output_weight": [2, 210], "output_bia": [2, 210], "num_head": [2, 189, 191, 210], "fallback_reshap": [2, 210], "get_fallback_funct": [2, 210], "batch_siz": [2, 3, 4, 15, 20, 25, 72, 189, 191, 210, 211, 212], "sequence_s": [2, 3, 4, 15, 189, 191, 210, 211, 212], "hidden_s": [2, 3, 15, 191, 210, 211], "head_siz": [2, 187, 188, 189, 191, 210], "queri": [2, 7, 20, 191, 210], "valu": [2, 7, 16, 17, 19, 20, 25, 32, 33, 48, 72, 81, 90, 91, 132, 137, 165, 191, 200, 202, 206, 210, 215], "attention_scor": [2, 210], "attention_prob": [2, 210], "dim": [2, 6, 7, 18, 19, 20, 24, 33, 45, 48, 69, 73, 119, 121, 122, 148, 152, 164, 172, 174, 175, 191, 195, 210, 214], "context_lay": [2, 210], "self_output": [2, 210], "return": [2, 3, 4, 5, 6, 13, 15, 17, 19, 20, 29, 32, 33, 43, 56, 68, 72, 75, 94, 95, 100, 107, 108, 109, 111, 114, 118, 129, 130, 132, 136, 140, 144, 146, 147, 151, 171, 173, 183, 189, 191, 210, 211, 212, 213, 214], "written": [2, 7, 90, 91, 200, 207, 210], "creat": [2, 6, 7, 11, 17, 19, 20, 22, 24, 48, 200, 205, 206, 210, 214], "test": [2, 4, 7, 10, 11, 15, 16, 22, 23, 210, 212, 215], "384": [2, 3, 13, 15, 210, 211], "64": [2, 3, 4, 5, 19, 20, 24, 43, 45, 48, 100, 118, 138, 164, 183, 184, 210, 211, 212, 213, 215], "torch_hidden_st": [2, 15, 210], "torch_attention_mask": [2, 3, 210, 211], "torch_query_weight": [2, 210], "torch_query_bia": [2, 210], "torch_key_weight": [2, 210], "torch_key_bia": [2, 210], "torch_value_weight": [2, 210], "torch_value_bia": [2, 210], "torch_output_weight": [2, 210], "torch_output_bia": [2, 210], "start": [2, 4, 7, 15, 19, 20, 23, 32, 210, 212], "end": [2, 4, 16, 19, 20, 23, 32, 210, 212], "durat": [2, 4, 23, 210, 212], "752": [2, 210], "decor": [2, 4, 22, 210, 212], "call_wrapp": [2, 210], "557": [2, 210], "fall": [2, 210], "cpu": [2, 4, 6, 7, 10, 17, 18, 19, 20, 23, 210, 212, 214], "tt_throw": [2, 210], "cpp": [2, 13, 210], "hpp": [2, 13, 210], "98": [2, 4, 210, 212], "fatal": [2, 6, 210, 214], "47": [2, 4, 5, 210, 212, 213], "240": [2, 4, 210, 212], "605": [2, 210], "50": [2, 210], "150": [2, 210], "ran": [2, 23, 210], "second": [2, 4, 10, 19, 20, 23, 100, 118, 137, 210, 212], "2719199657440186": [2, 210], "786": [2, 210], "813": [2, 210], "51": [2, 10, 210], "171": [2, 210], "535": [2, 210], "3269269466400146": [2, 210], "ahead": [2, 210], "more": [2, 4, 6, 7, 8, 20, 21, 23, 24, 200, 202, 210, 212, 214], "perform": [2, 7, 15, 16, 19, 20, 21, 22, 23, 72, 200, 202, 210], "fuse": [2, 7, 15, 18, 210], "bia": [2, 5, 15, 20, 74, 93, 100, 210, 213], "number": [2, 6, 19, 20, 22, 23, 24, 25, 29, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 137, 151, 152, 171, 173, 187, 188, 210, 214], "everi": [2, 16, 19, 23, 210, 215], "l1": [2, 19, 24, 48, 100, 118, 184, 210], "bfloat8_b": [2, 15, 19, 20, 23, 24, 26, 27, 29, 35, 37, 43, 46, 53, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195, 210], "data_typ": [2, 19, 20, 210], "custom": [2, 146, 147, 210], "dealloc": [2, 7, 14, 24, 144, 210], "otherwis": [2, 19, 20, 210, 215], "optimized_multi_head_attent": [2, 210], "fused_qkv_weight": [2, 210], "fused_qkv_bia": [2, 210], "self_output_weight": [2, 210], "self_output_bia": [2, 210], "num_cores_x": [2, 15, 210], "_": [2, 6, 15, 23, 210, 214], "fused_qkv_output": [2, 210], "linear": [2, 7, 14, 15, 18, 20, 165, 210], "split_query_key_value_and_split_head": [2, 7, 14, 210], "attention_softmax_": [2, 7, 14, 210], "context_layer_after_concatenate_head": [2, 210], "concatenate_head": [2, 7, 14, 210], "qkv": [2, 210], "bias": [2, 15, 20, 210], "preprocess_linear_weight": [2, 15, 210], "preprocess_linear_bia": [2, 15, 210], "model_preprocess": [2, 3, 4, 5, 7, 14, 15, 210, 211, 212, 213], "torch_qkv_weight": [2, 210], "cat": [2, 6, 191, 210, 214], "torch_qkv_bia": [2, 210], "qkv_weight": [2, 210], "qkv_bia": [2, 210], "optimized_output": [2, 210], "9824471473693848": [2, 210], "15": [2, 4, 210, 212], "002396821975708008": [2, 210], "magnitud": [2, 210], "faster": [2, 23, 210], "than": [2, 20, 23, 68, 75, 95, 114, 210, 215], "17": [2, 4, 6, 210, 212, 214], "torch_output": [2, 15, 210], "torch_optimized_output": [2, 210], "assert": [2, 210, 215], "allclos": [2, 210], "disabl": [2, 4, 7, 20, 125, 126, 210, 212], "clear": [2, 4, 16, 22, 210, 212], "tracer": [3, 5, 6, 7, 12, 200, 211, 213, 214, 215], "visual": [3, 5, 6, 7, 12, 211, 213, 214], "set_verbosity_error": [3, 211], "randint": [3, 17, 211], "100": [3, 4, 211, 212], "exp": [3, 7, 13, 14, 17, 18, 20, 211, 215], "model_nam": [3, 4, 15, 125, 126, 211, 212], "googl": [3, 6, 211, 214], "bert_uncased_l": [3, 211], "4_h": [3, 211], "256_a": [3, 211], "bertconfig": [3, 15, 211], "from_pretrain": [3, 6, 15, 211, 214], "bert": [3, 4, 15, 21, 211, 212], "modeling_bert": [3, 15, 211], "bertselfoutput": [3, 211], "eval": [3, 4, 5, 6, 15, 211, 212, 213, 214], "input_tensor": [3, 5, 13, 20, 26, 27, 28, 30, 31, 33, 35, 36, 37, 39, 40, 41, 42, 45, 46, 47, 50, 51, 53, 54, 57, 58, 59, 60, 61, 62, 63, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 93, 96, 98, 99, 102, 103, 104, 105, 106, 113, 115, 119, 121, 122, 124, 128, 131, 133, 137, 138, 139, 141, 143, 144, 145, 148, 149, 150, 151, 152, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 172, 174, 175, 176, 178, 179, 180, 181, 187, 188, 189, 190, 191, 192, 193, 194, 195, 211, 213, 215], "output": [3, 7, 10, 13, 15, 16, 17, 18, 19, 23, 26, 27, 28, 29, 33, 35, 36, 37, 39, 40, 43, 45, 46, 47, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 118, 124, 128, 129, 130, 131, 132, 133, 138, 143, 145, 146, 149, 150, 152, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 173, 176, 178, 179, 180, 183, 187, 188, 189, 190, 191, 192, 193, 196, 200, 202, 203, 206, 211, 215], "devic": [3, 4, 5, 6, 7, 12, 13, 15, 16, 18, 19, 23, 24, 25, 26, 27, 28, 29, 32, 34, 35, 36, 37, 39, 40, 43, 44, 45, 46, 47, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 72, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 117, 118, 124, 125, 126, 128, 129, 130, 131, 133, 134, 135, 136, 138, 143, 144, 145, 149, 150, 151, 152, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 173, 176, 177, 178, 179, 180, 182, 183, 184, 192, 193, 198, 199, 200, 202, 203, 206, 211, 212, 213, 214], "initi": [3, 4, 5, 7, 15, 17, 20, 125, 126, 200, 202, 203, 206, 211, 212, 213], "59": [3, 211], "074": [3, 211], "085": [3, 211], "086": [3, 211], "demo": [3, 7, 11, 23, 211], "ttnn_bert": [3, 15, 211], "ttnn_optimized_bert": [3, 15, 211], "preprocess_model_paramet": [3, 7, 14, 15, 211], "phiyodr": [3, 15, 211], "larg": [3, 15, 165, 211], "finetun": [3, 15, 211], "squad2": [3, 15, 211], "num_hidden_lay": [3, 211], "paramet": [3, 7, 12, 13, 15, 20, 25, 30, 31, 41, 53, 77, 81, 96, 113, 125, 126, 139, 141, 165, 166, 200, 203, 205, 211], "initialize_model": [3, 5, 15, 125, 126, 211, 213], "lambda": [3, 5, 15, 20, 211, 213], "bertforquestionansw": [3, 211], "custom_preprocessor": [3, 15, 125, 126, 211], "input_id": [3, 211], "vocab_s": [3, 211], "int32": [3, 20, 151, 183, 184, 211], "torch_token_type_id": [3, 211], "zero": [3, 7, 14, 18, 19, 20, 25, 43, 45, 138, 164, 211], "torch_position_id": [3, 211], "els": [3, 5, 6, 19, 20, 211, 213, 214], "ttnn_bert_input": [3, 211], "preprocess_input": [3, 211], "bert_for_question_answ": [3, 211], "032": [3, 211], "338": [3, 211], "weight": [3, 4, 5, 7, 15, 20, 54, 74, 93, 97, 100, 154, 200, 203, 211, 212, 213], "054": [3, 211], "340": [3, 211], "close": [3, 4, 5, 7, 17, 44, 117, 200, 202, 203, 206, 211, 212, 213], "document": [4, 11, 13, 16, 22, 212], "bash": [4, 212], "cd": [4, 23, 212], "tt_metal_hom": [4, 23, 212], "unset": [4, 212], "silent": [4, 212], "make": [4, 15, 24, 125, 126, 165, 191, 212, 215], "nuke": [4, 212], "script": [4, 10, 11, 16, 23, 212], "build_script": [4, 23, 212], "build_with_profiler_opt": [4, 23, 212], "sh": [4, 10, 11, 16, 23, 212], "jobserv": [4, 212], "unavail": [4, 212], "us": [4, 6, 7, 10, 11, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 34, 45, 48, 54, 58, 59, 61, 70, 100, 118, 125, 126, 137, 138, 146, 147, 151, 155, 164, 165, 183, 184, 185, 190, 191, 200, 202, 203, 206, 207, 212, 214], "j1": [4, 212], "parent": [4, 212], "rule": [4, 212], "artifact": [4, 212], "write": [4, 7, 8, 10, 11, 15, 24, 48, 100, 118, 200, 203, 212], "pip": [4, 6, 212, 214], "conf": [4, 212], "instal": [4, 6, 7, 10, 16, 23, 200, 212, 214], "python": [4, 6, 7, 11, 20, 22, 23, 212, 214], "env": [4, 6, 212, 214], "build": [4, 7, 17, 200, 201, 212], "backend": [4, 212], "requir": [4, 6, 10, 13, 16, 19, 20, 23, 48, 125, 126, 212, 214], "look": [4, 6, 16, 21, 24, 118, 212, 214], "index": [4, 6, 7, 19, 20, 23, 90, 91, 190, 212, 214], "http": [4, 7, 21, 200, 201, 212], "pypi": [4, 6, 212, 214], "org": [4, 6, 212, 214], "simpl": [4, 6, 7, 212, 214], "download": [4, 7, 200, 201, 212], "pytorch": [4, 7, 10, 12, 18, 20, 33, 191, 200, 201, 212], "whl": [4, 6, 212, 214], "alreadi": [4, 6, 17, 125, 126, 136, 200, 212, 214], "satisfi": [4, 6, 212, 214], "setuptool": [4, 212], "python_env": [4, 6, 11, 212, 214], "lib": [4, 6, 7, 11, 18, 212, 214], "python3": [4, 6, 212, 214], "site": [4, 6, 212, 214], "packag": [4, 6, 212, 214], "collect": [4, 16, 23, 200, 212], "wheel": [4, 212], "cach": [4, 6, 7, 10, 12, 18, 23, 24, 34, 44, 90, 91, 125, 126, 190, 200, 202, 203, 212, 214], "py3": [4, 212], "ani": [4, 10, 12, 16, 17, 20, 212], "65": [4, 6, 19, 212, 214], "kb": [4, 212], "successfulli": [4, 6, 16, 200, 212, 214], "edit": [4, 212], "dev": [4, 212], "version": [4, 7, 20, 23, 118, 125, 126, 200, 203, 205, 212], "tt_eager": [4, 13, 20, 212], "obtain": [4, 24, 212], "file": [4, 6, 7, 9, 11, 16, 23, 34, 212, 214, 215], "git": [4, 7, 125, 126, 200, 201, 212], "depend": [4, 7, 11, 12, 16, 20, 23, 24, 43, 118, 183, 200, 212], "statu": [4, 212], "prepar": [4, 11, 16, 212], "metadata": [4, 6, 212, 214], "click": [4, 212], "96": [4, 19, 212], "loguru": [4, 212], "58": [4, 212], "ipywidget": [4, 212], "139": [4, 212], "process": [4, 7, 20, 23, 200, 203, 212], "90": [4, 212], "db": [4, 212], "290ab3a34f2ef0b5a0f89235dc2d40fea83e77de84ed2dc05c": [4, 212], "pyyaml": [4, 6, 212, 214], "cp38": [4, 212], "linux_x86_64": [4, 212], "jupyterlab": [4, 212], "mb": [4, 212], "pyelftool": [4, 212], "py2": [4, 212], "174": [4, 212], "4f": [4, 212], "ed": [4, 212], "863cf4386fe6db3c09333712009ec1c5146a36f3904b469d13": [4, 212], "curtsi": [4, 212], "91": [4, 212], "b7": [4, 212], "0c117d73912c6c2beb1eb0d7d6884f4e79e6e5b5e91eeb34f5": [4, 212], "torchtrail": [4, 5, 212, 213], "numpi": [4, 6, 19, 24, 212, 214], "manylinux_2_12_x86_64": [4, 212], "manylinux2010_x86_64": [4, 212], "matplotlib": [4, 212], "toolz": [4, 212], "55": [4, 212], "pillow": [4, 6, 212, 214], "manylinux_2_17_x86_64": [4, 212], "manylinux2014_x86_64": [4, 212], "panda": [4, 212], "torch": [4, 6, 7, 12, 13, 17, 19, 24, 26, 27, 28, 29, 33, 34, 35, 36, 37, 39, 40, 43, 45, 46, 47, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 68, 70, 71, 72, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 118, 124, 125, 126, 128, 129, 130, 131, 133, 138, 143, 145, 149, 150, 151, 152, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 173, 176, 178, 179, 180, 183, 184, 185, 191, 192, 193, 200, 202, 203, 205, 206, 207, 212, 214], "2bcpu": [4, 212], "199": [4, 212], "dash": [4, 212], "rich": [4, 212], "238": [4, 212], "seaborn": [4, 212], "293": [4, 212], "plotli": [4, 212], "traitlet": [4, 212], "85": [4, 212], "widgetsnbextens": [4, 212], "ipython": [4, 5, 6, 212, 213, 214], "798": [4, 212], "widget": [4, 212], "jupyterlab_widget": [4, 212], "215": [4, 212], "comm": [4, 212], "async": [4, 212], "lru": [4, 212], "async_lru": [4, 212], "tomli": [4, 212], "python_vers": [4, 212], "jupyt": [4, 21, 200, 212], "server": [4, 212], "jupyter_serv": [4, 212], "380": [4, 212], "jinja2": [4, 6, 212, 214], "133": [4, 212], "ipykernel": [4, 212], "116": [4, 212], "notebook": [4, 6, 21, 200, 212, 214], "shim": [4, 212], "notebook_shim": [4, 212], "jupyterlab_serv": [4, 212], "lsp": [4, 212], "jupyter_lsp": [4, 212], "68": [4, 212], "53": [4, 212], "importlib": [4, 6, 212, 214], "resourc": [4, 212], "importlib_resourc": [4, 212], "importlib_metadata": [4, 212], "jupyter_cor": [4, 212], "28": [4, 6, 24, 212, 214], "tornado": [4, 212], "abi3": [4, 212], "manylinux_2_5_x86_64": [4, 212], "manylinux1_x86_64": [4, 212], "435": [4, 212], "bless": [4, 212], "cwcwidth": [4, 212], "92": [4, 212], "pyrsist": [4, 212], "121": [4, 212], "graphviz": [4, 212], "networkx": [4, 6, 12, 212, 214], "pypars": [4, 212], "103": [4, 212], "kiwisolv": [4, 212], "contourpi": [4, 212], "301": [4, 5, 212, 213], "fonttool": [4, 212], "22": [4, 212], "48": [4, 212], "dateutil": [4, 212], "python_dateutil": [4, 212], "247": [4, 212], "cycler": [4, 212], "pytz": [4, 212], "2020": [4, 212], "505": [4, 212], "type": [4, 6, 7, 13, 15, 17, 18, 19, 23, 29, 33, 34, 43, 56, 65, 68, 72, 75, 94, 95, 100, 107, 108, 109, 111, 114, 118, 129, 130, 132, 153, 171, 173, 183, 184, 200, 206, 212, 214], "extens": [4, 6, 212, 214], "typing_extens": [4, 212], "html": [4, 212], "compon": [4, 20, 212], "dash_html_compon": [4, 212], "tabl": [4, 10, 13, 20, 212], "dash_tabl": [4, 212], "flask": [4, 212], "101": [4, 212], "dash_core_compon": [4, 212], "pygment": [4, 212], "markdown": [4, 212], "py": [4, 10, 13, 15, 16, 23, 212, 215], "markdown_it_pi": [4, 212], "84": [4, 212], "tenac": [4, 212], "24": [4, 6, 212, 214], "pickleshar": [4, 212], "prompt": [4, 212], "toolkit": [4, 212], "37": [4, 212], "30": [4, 10, 212], "prompt_toolkit": [4, 212], "386": [4, 212], "stack": [4, 212], "data": [4, 7, 13, 15, 17, 19, 20, 23, 29, 33, 34, 43, 56, 65, 68, 72, 75, 94, 95, 100, 107, 108, 109, 111, 114, 118, 129, 130, 132, 171, 173, 183, 184, 194, 200, 206, 212, 215], "stack_data": [4, 212], "backcal": [4, 212], "jedi": [4, 212], "pexpect": [4, 212], "sys_platform": [4, 212], "win32": [4, 212], "63": [4, 19, 212], "inlin": [4, 212], "matplotlib_inlin": [4, 212], "send2trash": [4, 212], "anyio": [4, 212], "termin": [4, 212], "jupyter_server_termin": [4, 212], "client": [4, 212], "jupyter_cli": [4, 212], "105": [4, 212], "nbformat": [4, 212], "77": [4, 212], "overrid": [4, 212, 215], "nbconvert": [4, 212], "257": [4, 212], "event": [4, 212], "jupyter_ev": [4, 212], "websocket": [4, 212], "websocket_cli": [4, 212], "pyzmq": [4, 212], "prometheu": [4, 212], "prometheus_cli": [4, 212], "54": [4, 212], "argon2": [4, 212], "cffi": [4, 212], "argon2_cffi": [4, 212], "terminado": [4, 212], "markupsaf": [4, 6, 212, 214], "nest": [4, 212], "asyncio": [4, 212], "nest_asyncio": [4, 212], "psutil": [4, 212], "cp36": [4, 212], "288": [4, 212], "debugpi": [4, 212], "babel": [4, 212], "request": [4, 6, 7, 22, 43, 183, 212, 214], "31": [4, 6, 17, 19, 20, 212, 214], "62": [4, 212], "jsonschema": [4, 212], "21": [4, 6, 212, 214], "json5": [4, 212], "zipp": [4, 6, 212, 214], "platformdir": [4, 212], "six": [4, 212], "wcwidth": [4, 212], "itsdanger": [4, 212], "blinker": [4, 212], "werkzeug": [4, 212], "226": [4, 212], "mdurl": [4, 212], "pure": [4, 212], "pure_ev": [4, 212], "asttoken": [4, 212], "parso": [4, 212], "ptyprocess": [4, 212], "exceptiongroup": [4, 212], "idna": [4, 6, 212, 214], "61": [4, 212], "sniffio": [4, 212], "fastjsonschema": [4, 212], "defusedxml": [4, 212], "beautifulsoup4": [4, 212], "147": [4, 5, 212, 213], "jupyterlab_pyg": [4, 212], "pandocfilt": [4, 212], "mistun": [4, 212], "tinycss2": [4, 212], "bleach": [4, 212], "162": [4, 212], "nbclient": [4, 212], "rfc3986": [4, 212], "valid": [4, 13, 15, 16, 19, 20, 23, 118, 125, 126, 212], "rfc3986_valid": [4, 212], "json": [4, 212, 215], "logger": [4, 212], "python_json_logg": [4, 212], "referenc": [4, 22, 212], "rfc3339": [4, 212], "rfc3339_valid": [4, 212], "bind": [4, 212], "argon2_cffi_bind": [4, 212], "86": [4, 212], "urllib3": [4, 6, 212, 214], "120": [4, 23, 212], "charset": [4, 6, 212, 214], "normal": [4, 6, 7, 20, 212, 214], "charset_norm": [4, 212], "141": [4, 212], "certifi": [4, 6, 212, 214], "2017": [4, 6, 19, 212, 214], "163": [4, 212], "specif": [4, 16, 20, 24, 212], "2023": [4, 6, 212, 214], "03": [4, 212], "jsonschema_specif": [4, 212], "pkgutil": [4, 212], "resolv": [4, 212], "name": [4, 6, 10, 15, 19, 20, 22, 23, 34, 125, 126, 212, 214, 215], "pkgutil_resolve_nam": [4, 212], "attr": [4, 25, 212], "60": [4, 212], "rpd": [4, 212], "rpds_py": [4, 212], "soupsiev": [4, 212], "36": [4, 212], "webencod": [4, 212], "444": [4, 212], "pycpars": [4, 212], "118": [4, 212], "setup": [4, 6, 16, 21, 212, 214], "develop": [4, 7, 11, 21, 22, 23, 212], "environ": [4, 6, 10, 11, 20, 21, 212, 214, 215], "pre": [4, 7, 147, 200, 201, 203, 212], "commit": [4, 16, 212], "pre_commit": [4, 212], "202": [4, 212], "black": [4, 212], "twine": [4, 212], "yamllint": [4, 212], "docutil": [4, 212], "570": [4, 212], "sphinx": [4, 212], "rtd": [4, 212], "theme": [4, 212], "sphinx_rtd_them": [4, 212], "sphinxcontrib": [4, 212], "email": [4, 212], "sphinxcontrib_email": [4, 212], "lxml": [4, 212], "manylinux_2_24_x86_64": [4, 212], "breath": [4, 212], "35": [4, 212], "nbsphinx": [4, 212], "jqueri": [4, 212], "sphinxcontrib_jqueri": [4, 212], "r": [4, 13, 20, 212], "doc": [4, 11, 13, 212], "txt": [4, 212], "line": [4, 13, 212], "3a": [4, 212], "a8": [4, 212], "3237a93e3a6261bd24edabf3277ca59f64c1710b3d8c7c72a0": [4, 212], "pandoc": [4, 212], "pytest": [4, 10, 11, 13, 15, 16, 23, 212, 215], "317": [4, 212], "timeout": [4, 212], "pytest_timeout": [4, 212], "6c": [4, 212], "40": [4, 212], "1d": [4, 20, 32, 100, 118, 212], "5706d21e6b4dff52e7af12bff9ca126a3f15beb4dff386aa29": [4, 212], "jsbeautifi": [4, 212], "dataset": [4, 212], "462": [4, 212], "torchvis": [4, 6, 7, 200, 205, 212, 214], "xlsxwriter": [4, 212], "152": [4, 212], "tiktoken": [4, 212], "tqdm": [4, 6, 212, 214], "sentencepiec": [4, 212], "97": [4, 19, 212], "numba": [4, 212], "56": [4, 5, 212, 213], "librosa": [4, 212], "252": [4, 212], "timm": [4, 6, 212, 214], "549": [4, 212], "opencv": [4, 212], "headless": [4, 212], "74": [4, 212], "opencv_python_headless": [4, 212], "cp37": [4, 212], "49": [4, 6, 212, 214], "diffus": [4, 6, 212, 214], "604": [4, 212], "219": [4, 212], "ftfy": [4, 212], "gitpython": [4, 212], "188": [4, 212], "einop": [4, 212], "multiprocess": [4, 212], "70": [4, 212], "py38": [4, 212], "132": [4, 212], "evalu": [4, 212], "81": [4, 212], "score": [4, 191, 212], "bert_scor": [4, 212], "fsspec": [4, 6, 212, 214], "173": [4, 212], "nodeenv": [4, 212], "cfgv": [4, 212], "identifi": [4, 212], "virtualenv": [4, 212], "pathspec": [4, 212], "mypi": [4, 212], "mypy_extens": [4, 212], "pyproject_hook": [4, 212], "readm": [4, 6, 11, 16, 212, 214], "render": [4, 212], "readme_render": [4, 212], "pkginfo": [4, 212], "toolbelt": [4, 212], "requests_toolbelt": [4, 212], "keyr": [4, 212], "38": [4, 54, 212], "images": [4, 212], "serializinghtml": [4, 212], "sphinxcontrib_serializinghtml": [4, 212], "94": [4, 212], "jsmath": [4, 212], "sphinxcontrib_jsmath": [4, 212], "snowballstemm": [4, 212], "93": [4, 212], "htmlhelp": [4, 212], "sphinxcontrib_htmlhelp": [4, 212], "99": [4, 212], "alabast": [4, 212], "applehelp": [4, 212], "sphinxcontrib_applehelp": [4, 212], "devhelp": [4, 212], "sphinxcontrib_devhelp": [4, 212], "qthelp": [4, 212], "sphinxcontrib_qthelp": [4, 212], "ply": [4, 212], "plumbum": [4, 212], "127": [4, 19, 212], "iniconfig": [4, 212], "pluggi": [4, 212], "0rc8": [4, 212], "editorconfig": [4, 212], "respons": [4, 212], "pyarrow": [4, 212], "xxhash": [4, 212], "194": [4, 212], "huggingfac": [4, 6, 212, 214], "hub": [4, 6, 212, 214], "huggingface_hub": [4, 212], "330": [4, 212], "aiohttp": [4, 212], "dill": [4, 212], "110": [4, 212], "token": [4, 20, 54, 91, 190, 212], "regex": [4, 6, 212, 214], "2019": [4, 6, 212, 214], "777": [4, 212], "filelock": [4, 6, 212, 214], "llvmlite": [4, 212], "0dev0": [4, 212], "soxr": [4, 212], "soundfil": [4, 212], "pooch": [4, 212], "lazi": [4, 212], "loader": [4, 212], "lazy_load": [4, 212], "scipi": [4, 212], "joblib": [4, 212], "302": [4, 212], "audioread": [4, 212], "scikit": [4, 212], "scikit_learn": [4, 212], "msgpack": [4, 212], "534": [4, 212], "gitdb": [4, 212], "distlib": [4, 212], "468": [4, 212], "nh3": [4, 212], "secretstorag": [4, 212], "linux": [4, 212], "jeepnei": [4, 212], "jaraco": [4, 212], "class": [4, 5, 6, 15, 16, 19, 20, 23, 24, 25, 116, 212, 213, 214], "2015": [4, 19, 212], "frozenlist": [4, 212], "async_timeout": [4, 212], "aiosign": [4, 212], "yarl": [4, 212], "308": [4, 212], "multidict": [4, 212], "129": [4, 212], "threadpoolctl": [4, 212], "smmap": [4, 212], "cryptographi": [4, 212], "itertool": [4, 212], "more_itertool": [4, 212], "57": [4, 212], "pyproject": [4, 212], "hook": [4, 7, 146, 147, 212], "attempt": [4, 10, 20, 212], "uninstal": [4, 212], "found": [4, 6, 10, 15, 200, 212, 214], "exist": [4, 6, 19, 136, 212, 214], "msg": [4, 212], "tool": [4, 23, 212], "profile_thi": [4, 7, 212], "t5": [4, 212], "c": [4, 7, 20, 23, 24, 194, 212], "integration_test": [4, 212], "test_perform": [4, 212], "test_t5_for_conditional_gener": [4, 212], "functional_t5": [4, 212], "model": [4, 5, 10, 12, 16, 22, 23, 125, 126, 200, 201, 203, 207, 212, 213], "experiment": [4, 7, 11, 13, 16, 18, 212], "ttnn_functional_t5": [4, 212], "small": [4, 212], "09": [4, 20, 212], "373": [4, 212], "__main__": [4, 17, 212], "main": [4, 6, 22, 200, 212, 214, 215], "flag": [4, 20, 34, 212], "folder": [4, 11, 16, 21, 23, 212], "locat": [4, 20, 21, 23, 212, 215], "ops_devic": [4, 212], "session": [4, 212], "platform": [4, 19, 21, 212], "bin": [4, 11, 212], "cachedir": [4, 212], "pytest_cach": [4, 212], "rootdir": [4, 212], "configfil": [4, 212], "ini": [4, 212], "plugin": [4, 212], "600": [4, 212], "method": [4, 13, 20, 24, 212], "signal": [4, 20, 25, 72, 212], "func_onli": [4, 212], "item": [4, 23, 212], "670": [4, 212], "681": [4, 212], "684": [4, 212], "llruntim": [4, 212], "watcher": [4, 212], "built": [4, 6, 11, 212, 214], "attach": [4, 125, 126, 212], "thread": [4, 19, 183, 212, 215], "watch": [4, 212], "program": [4, 7, 10, 12, 13, 18, 23, 100, 118, 187, 188, 200, 202, 203, 212], "enabl": [4, 6, 7, 10, 20, 22, 200, 202, 203, 212, 214], "109": [4, 212], "preprocess_model": [4, 5, 7, 14, 212, 213], "465": [4, 212], "save": [4, 5, 6, 212, 213, 214], "ttnn_t5": [4, 212], "6ba823894": [4, 212], "149": [4, 212], "484": [4, 212], "487": [4, 212], "216": [4, 212], "489": [4, 212], "check": [4, 7, 9, 16, 19, 21, 200, 203, 212], "721": [4, 212], "359902381896973": [4, 212], "infer": [4, 10, 16, 23, 212], "07123565673828": [4, 212], "722": [4, 212], "102": [4, 212], "per": [4, 20, 212], "44269247283137575": [4, 212], "detach": [4, 212], "short": [4, 212], "summari": [4, 212], "627": [4, 212], "638": [4, 212], "639": [4, 212], "458": [4, 212], "load": [4, 6, 212, 214], "224": [4, 212], "460": [4, 212], "292": [4, 212], "41": [4, 212], "164": [4, 212], "22393798828125": [4, 212], "165": [4, 212], "322504758834839": [4, 212], "407821983919596": [4, 212], "pd": [4, 212], "o": [4, 6, 23, 212, 214], "glob": [4, 212], "getenv": [4, 212], "get_latest_report": [4, 212], "base_path": [4, 212], "latest_dir": [4, 212], "max": [4, 6, 7, 14, 20, 25, 212, 214], "path": [4, 6, 23, 34, 52, 101, 212, 214, 215], "join": [4, 9, 212], "d": [4, 12, 212], "listdir": [4, 212], "isdir": [4, 212], "getmtim": [4, 212], "valueerror": [4, 5, 212, 213], "latest_profile_report": [4, 212], "df": [4, 212], "read_csv": [4, 212], "resnet": [4, 7, 21, 23, 200, 212], "2024_02_09_01_38_37": [4, 212], "ops_perf_results_resnet_2024_02_09_01_38_37": [4, 212], "csv": [4, 10, 13, 23, 212, 215], "global": [4, 23, 212], "count": [4, 19, 20, 23, 212], "attribut": [4, 7, 15, 20, 23, 24, 200, 206, 212, 215], "math": [4, 7, 18, 23, 48, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 171, 173, 212], "fidel": [4, 23, 212], "parallel": [4, 20, 23, 212], "strategi": [4, 19, 20, 23, 24, 48, 118, 212], "output_0_w": [4, 212], "output_0_z": [4, 212], "output_0_i": [4, 212], "output_0_x": [4, 212], "output_0_layout": [4, 212], "output_0_data": [4, 212], "output_0_memori": [4, 212], "depth": [4, 212], "compileprogram": [4, 212], "averag": [4, 20, 23, 72, 212], "load_tensor_ttnn": [4, 212], "load_tensor": [4, 7, 14, 212], "python_fallback": [4, 23, 212], "nan": [4, 20, 212], "137428381893955": [4, 212], "137428382188762": [4, 212], "294807": [4, 212], "137428382500949": [4, 212], "137428399402163": [4, 212], "16901214": [4, 212], "137428399802068": [4, 212], "137428399873758": [4, 212], "71690": [4, 212], "137428400102635": [4, 212], "137428400351033": [4, 212], "248398": [4, 212], "137428400548071": [4, 212], "137428400792528": [4, 212], "244457": [4, 212], "4391": [4, 212], "reshape_ttnn": [4, 212], "4392": [4, 212], "137450414555424": [4, 212], "137450414599894": [4, 212], "44470": [4, 212], "4393": [4, 212], "137450414740752": [4, 212], "137450414782422": [4, 212], "41670": [4, 212], "tt_dnn_devic": [4, 23, 212], "4394": [4, 212], "bcast_batch": [4, 212], "true": [4, 5, 6, 15, 19, 20, 26, 27, 29, 33, 35, 37, 46, 48, 49, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 70, 71, 72, 74, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195, 196, 212, 213, 214, 215], "output_mem_config": [4, 20, 212], "tt_me": [4, 212], "hifi4": [4, 23, 212], "108": [4, 212], "matmulparallelizationstrategi": [4, 212], "multi_cor": [4, 212], "137450414881851": [4, 212], "137450414983440": [4, 212], "101589": [4, 212], "32128": [4, 212], "dev_0_dram_interleav": [4, 212], "4395": [4, 212], "137450415113099": [4, 212], "137450415158748": [4, 212], "45649": [4, 212], "from_device_ttnn": [4, 212], "4396": [4, 212], "137450415235897": [4, 212], "137450453493048": [4, 212], "38257151": [4, 212], "column": [4, 23, 24, 212], "157": [5, 213], "159": [5, 213], "conv3x3": [5, 213], "in_plan": [5, 213], "int": [5, 6, 19, 20, 25, 29, 32, 33, 38, 45, 48, 54, 56, 66, 67, 68, 69, 73, 74, 75, 82, 90, 91, 94, 95, 97, 107, 108, 109, 111, 112, 114, 117, 119, 120, 121, 122, 123, 129, 130, 136, 137, 138, 148, 152, 153, 164, 171, 172, 173, 174, 175, 185, 187, 188, 190, 191, 195, 197, 213, 214], "out_plan": [5, 213], "group": [5, 20, 213], "dilat": [5, 20, 25, 213], "nn": [5, 12, 13, 15, 19, 125, 126, 200, 201, 202, 203, 204, 205, 206, 207, 213], "conv2d": [5, 7, 18, 20, 213], "3x3": [5, 213], "convolut": [5, 20, 213], "kernel_s": [5, 20, 25, 213], "torchbasicblock": [5, 213], "expans": [5, 213], "__init__": [5, 7, 15, 18, 19, 213], "self": [5, 15, 19, 20, 24, 213], "inplan": [5, 213], "plane": [5, 20, 25, 72, 213], "downsampl": [5, 213], "base_width": [5, 213], "norm_lay": [5, 213], "super": [5, 15, 213], "batchnorm2d": [5, 7, 18, 20, 213], "rais": [5, 20, 213], "basicblock": [5, 213], "onli": [5, 15, 16, 19, 20, 21, 23, 24, 48, 118, 191, 200, 201, 202, 203, 204, 205, 206, 207, 213, 215], "notimplementederror": [5, 213], "conv1": [5, 213], "layer": [5, 20, 23, 213], "bn1": [5, 213], "relu": [5, 7, 14, 17, 18, 20, 96, 165, 213], "inplac": [5, 213], "conv2": [5, 213], "bn2": [5, 213], "forward": [5, 15, 20, 213], "ident": [5, 7, 18, 20, 213], "torch_model": [5, 213], "torch_input_tensor": [5, 13, 152, 213, 215], "reader_patterns_cach": [5, 25, 125, 213], "run_model": [5, 125, 213], "222": [5, 213], "_initialize_model_and_preprocess_paramet": [5, 213], "434": [5, 213], "infer_ttnn_module_arg": [5, 213], "368": [5, 213], "dump": [5, 6, 20, 125, 213, 214, 215], "model_graph": [5, 125, 213], "svg": [5, 6, 125, 213, 214, 215], "346": [5, 213], "multidigraph": [5, 213], "visualize_graph": [5, 213], "316": [5, 213], "550": [5, 213], "543": [5, 213], "551": [5, 213], "545": [5, 213], "conv": [5, 7, 18, 20, 213], "object": [5, 6, 12, 15, 19, 20, 22, 48, 213, 214], "0x7f29c3b0fc10": [5, 213], "0x7f299d093eb0": [5, 213], "ttnnbasicblock": [5, 213], "__call__": [5, 213], "get_memory_config": [5, 213], "to_memory_config": [5, 7, 14, 24, 213], "dram_memory_config": [5, 24, 32, 43, 84, 100, 118, 132, 137, 140, 191, 213], "run_conv": [5, 213], "copy_input_to_devic": [5, 213], "copy_output_from_devic": [5, 213], "ttnn_model": [5, 213], "walk": [6, 214], "you": [6, 8, 9, 10, 11, 12, 16, 17, 19, 20, 21, 23, 165, 200, 214, 215, 216], "through": [6, 7, 18, 214], "chosen": [6, 20, 23, 214], "mirror": [6, 214], "what": [6, 7, 16, 23, 214], "colab": [6, 214], "research": [6, 214], "blob": [6, 214], "run_dit": [6, 214], "ipynb": [6, 214], "detail": [6, 8, 21, 214, 215], "tab": [6, 214], "ov": [6, 214], "assumpt": [6, 214], "access": [6, 8, 9, 214], "machin": [6, 17, 19, 20, 23, 200, 214], "been": [6, 16, 125, 126, 214], "follow": [6, 10, 13, 15, 17, 19, 20, 21, 22, 23, 24, 118, 146, 147, 200, 214, 215], "chdir": [6, 214], "pythonpath": [6, 11, 214], "content": [6, 214], "upgrad": [6, 214], "save_imag": [6, 214], "create_diffus": [6, 214], "autoencoderkl": [6, 214], "find_model": [6, 214], "collis": [6, 214], "namespac": [6, 13, 214], "also": [6, 10, 16, 17, 19, 20, 21, 23, 43, 214], "append": [6, 23, 118, 214], "front": [6, 23, 214], "dit_xl_2": [6, 7, 200, 214], "pil": [6, 214], "imag": [6, 7, 18, 20, 23, 24, 214], "set_grad_en": [6, 214], "cuda": [6, 214], "is_avail": [6, 214], "gpu": [6, 214], "05": [6, 10, 20, 84, 214], "322": [6, 214], "destin": [6, 214], "empti": [6, 7, 14, 18, 20, 118, 214], "directori": [6, 200, 214], "date": [6, 214], "safetensor": [6, 214], "sympi": [6, 214], "mpmath": [6, 214], "image_s": [6, 214], "256": [6, 214], "param": [6, 20, 214], "512": [6, 214], "vae_model": [6, 214], "stabilityai": [6, 214], "sd": [6, 214], "vae": [6, 214], "ft": [6, 214], "ema": [6, 214], "mse": [6, 214], "latent_s": [6, 214], "input_s": [6, 214], "state_dict": [6, 214], "pt": [6, 214], "load_state_dict": [6, 214], "seed": [6, 214], "num_sampling_step": [6, 214], "250": [6, 214], "slider": [6, 214], "min": [6, 7, 14, 20, 214], "1000": [6, 23, 214], "cfg_scale": [6, 214], "class_label": [6, 214], "207": [6, 214], "360": [6, 214], "387": [6, 214], "974": [6, 214], "88": [6, 214], "979": [6, 214], "417": [6, 214], "279": [6, 214], "raw": [6, 214], "samples_per_row": [6, 214], "str": [6, 13, 19, 20, 29, 34, 52, 56, 68, 75, 92, 94, 95, 100, 101, 107, 108, 109, 111, 114, 118, 125, 126, 127, 129, 130, 156, 171, 173, 214], "nois": [6, 214], "len": [6, 214], "z": [6, 19, 20, 23, 214], "classifi": [6, 214], "free": [6, 214], "guidanc": [6, 214], "y_null": [6, 214], "model_kwarg": [6, 214], "dict": [6, 19, 25, 52, 125, 126, 214], "p_sample_loop": [6, 214], "forward_with_cfg": [6, 214], "clip_denois": [6, 214], "progress": [6, 11, 214], "null": [6, 214], "where": [6, 7, 9, 10, 11, 14, 16, 18, 20, 23, 24, 43, 48, 118, 183, 214], "captur": [6, 214], "trace": [6, 7, 12, 200, 205, 207, 214], "decod": [6, 214], "18215": [6, 214], "file_nam": [6, 52, 101, 214, 215], "dit_model_graph": [6, 214], "option": [6, 7, 13, 18, 19, 23, 26, 27, 28, 29, 33, 34, 35, 36, 37, 39, 40, 46, 47, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 72, 75, 76, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 118, 124, 128, 129, 130, 131, 132, 133, 134, 135, 143, 145, 149, 150, 154, 155, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 171, 173, 176, 178, 179, 180, 182, 183, 184, 187, 188, 190, 192, 193, 198, 199, 214, 215], "png": [6, 214], "nrow": [6, 214], "value_rang": [6, 214], "06": [6, 20, 214], "987": [6, 214], "210": [6, 214], "show_svg": [6, 214], "filenam": [6, 23, 214], "featur": [7, 20, 22, 215], "explor": 7, "head": [7, 187, 188, 189, 191, 200], "attent": [7, 187, 188, 191, 200], "basic": [7, 21, 200], "slice": [7, 20], "intermedi": 7, "graph": [7, 12, 18, 125, 200, 205], "tt_lib": [7, 12, 13, 17, 18, 19, 30, 31, 38, 41, 42, 45, 49, 64, 69, 73, 77, 82, 92, 97, 112, 113, 116, 120, 123, 127, 138, 139, 141, 144, 148, 153, 166, 175, 181, 182, 197], "string": [7, 20, 125, 126], "represent": [7, 20, 165], "web": 7, "browser": [7, 200], "regist": [7, 146, 147], "post": [7, 20, 23, 146], "fallback": [7, 17, 18, 22], "storag": [7, 18, 20, 200, 206], "shard": [7, 48, 100, 118, 184, 191], "rank": [7, 19, 20, 24, 185], "with_tile_pad": [7, 24], "manage_devic": [7, 14], "synchronize_devic": [7, 14], "create_sharded_memory_config": [7, 14, 24], "as_tensor": [7, 14], "dump_tensor": [7, 14], "realloc": [7, 14], "creation": [7, 18, 19], "arang": [7, 14, 18, 19, 20], "zeros_lik": [7, 14, 18, 20], "ones": [7, 14, 18, 20], "ones_lik": [7, 14, 18, 20], "full": [7, 12, 14, 16, 18, 20, 23], "full_lik": [7, 14, 18, 20], "multipl": [7, 19, 20, 23, 43, 118, 125, 183, 200, 202], "pointwis": 7, "unari": [7, 20], "ab": [7, 14, 18, 20], "aco": [7, 14, 18, 20], "acosh": [7, 14, 18, 20], "asin": [7, 14, 18, 20], "asinh": [7, 14, 18, 20], "atan": [7, 14, 18, 20], "atan2": [7, 14, 18, 20], "atanh": [7, 14, 18, 20], "cbrt": [7, 14, 18, 20], "celu": [7, 14, 18, 20], "clip": [7, 14, 18, 20], "clone": [7, 14, 18, 20, 191, 200, 201], "co": [7, 14, 18, 20], "cosh": [7, 14, 18, 20], "deg2rad": [7, 14, 18, 20], "digamma": [7, 14, 18, 20], "elu": [7, 14, 18, 20], "erf": [7, 14, 18, 20], "erfc": [7, 14, 18, 20], "erfinv": [7, 14, 18, 20], "exp2": [7, 14, 18, 20], "expm1": [7, 14, 18, 20], "geglu": [7, 14, 18, 20], "gelu": [7, 14, 15, 18, 20], "glu": [7, 14, 18, 20], "hardshrink": [7, 14, 18, 20], "hardsigmoid": [7, 14, 18, 20], "hardswish": [7, 14, 18, 20], "hardtanh": [7, 14, 18, 20], "heavisid": [7, 14, 18, 20], "hypot": [7, 14, 18, 20], "i0": [7, 14, 18, 20], "isfinit": [7, 14, 18, 20], "isinf": [7, 14, 18, 20], "isnan": [7, 14, 18, 20], "isneginf": [7, 14, 18, 20], "isposinf": [7, 14, 18, 20], "leaky_relu": [7, 14, 18, 20], "lerp": [7, 14, 18, 20], "lgamma": [7, 14, 18, 20], "log10": [7, 14, 18, 20], "log1p": [7, 14, 18, 20], "log2": [7, 14, 18, 20], "log_sigmoid": [7, 14, 18, 20], "logical_not": [7, 14], "logit": [7, 14, 18, 20], "mish": [7, 14, 18, 20], "multigammaln": [7, 14, 18, 20], "neg": [7, 14, 18, 20, 25], "prelu": [7, 14], "reglu": [7, 14, 18, 20], "relu6": [7, 14, 18, 20], "rsqrt": [7, 14, 18, 20], "sigmoid": [7, 14, 18, 20], "sigmoid_accur": [7, 14, 18, 20], "sign": [7, 14, 18, 20], "silu": [7, 14, 17, 18, 20], "sin": [7, 14, 18, 20], "sinh": [7, 14, 18, 20], "softplu": [7, 14, 18, 20], "softshrink": [7, 14, 18, 20], "softsign": [7, 14, 18, 20], "swish": [7, 14, 18, 20], "tan": [7, 14, 18, 20], "tanh": [7, 14, 18, 20], "signbit": [7, 14, 18, 20], "polygamma": [7, 14, 18, 20], "rad2deg": [7, 14, 18, 20], "reciproc": [7, 14, 20], "sqrt": [7, 14, 18, 20], "squar": [7, 14, 18, 20, 24, 171, 187, 188], "swiglu": [7, 14, 18, 20], "tril": [7, 14, 18, 20], "triu": [7, 14, 18, 20], "tanhshrink": [7, 14, 18, 20], "threshold": [7, 14, 18, 20, 165], "binari": [7, 20], "multipli": [7, 14, 20, 100, 118, 194, 200, 202, 215], "subtract": [7, 10, 14, 20, 191, 215], "pow": [7, 14, 17, 18, 20], "ldexp": [7, 14, 20], "logical_and": [7, 14], "logical_or": [7, 14], "logical_xor": [7, 14, 18, 20], "logaddexp": [7, 14, 20], "logaddexp2": [7, 14, 20], "xlogi": [7, 14, 18, 20], "squared_differ": [7, 14], "gtz": [7, 14, 18, 20], "ltz": [7, 14, 18, 20], "gez": [7, 14, 18, 20], "lez": [7, 14, 18, 20], "nez": [7, 14, 18, 20], "eqz": [7, 14, 18, 20], "ge": [7, 14], "le": [7, 14, 20], "eq": [7, 14], "ne": [7, 14], "isclos": [7, 14, 18, 20], "polyv": [7, 14, 18, 20], "nextaft": [7, 14, 18, 20], "maximum": [7, 14, 20, 33], "minimum": [7, 14, 20, 24], "ternari": [7, 18], "addcdiv": [7, 14, 18, 20], "addcmul": [7, 14, 18, 20], "mac": [7, 14, 18, 20], "loss": [7, 18], "l1_loss": [7, 14], "mse_loss": [7, 14], "reduct": [7, 20], "mean": [7, 14, 17, 20, 24, 100, 118], "std": [7, 13, 14, 19, 20, 30, 31, 33, 38, 41, 42, 69, 73, 77, 82, 92, 97, 112, 113, 116, 120, 123, 127, 139, 141, 148, 166, 175, 181, 197], "sum": [7, 14, 18, 20], "var": [7, 14, 20], "argmax": [7, 14, 18, 20], "topk": [7, 14], "movement": 7, "concat": [7, 14, 18, 20, 22], "repeat": [7, 12, 14, 18, 20, 152], "repeat_interleav": [7, 14, 18, 20], "group_norm": [7, 14, 18, 20], "layer_norm": [7, 14, 18, 20], "rms_norm": [7, 14, 93], "attention_softmax": [7, 14], "rotary_embed": [7, 14], "pool": [7, 20, 25, 72], "global_avg_pool2d": [7, 14], "maxpool2d": [7, 14, 18, 20], "vision": 7, "upsampl": [7, 14, 20], "kv": 7, "kv_cach": [7, 14], "fill_cache_for_user_": [7, 14], "update_cache_for_token_": [7, 14], "set_printopt": [7, 14], "register_pre_operation_hook": [7, 14, 215], "register_post_operation_hook": [7, 14, 215], "borrow": [7, 19, 24, 200, 206], "v": [7, 20, 200, 206], "own": [7, 19, 24, 200, 206], "b": [7, 20, 152, 190, 200, 202, 206], "random": [7, 17, 200, 202, 206], "inspect": [7, 200, 202, 206], "configur": [7, 10, 11, 16, 19, 26, 27, 28, 34, 35, 36, 37, 39, 40, 45, 46, 47, 50, 51, 53, 54, 57, 58, 59, 60, 61, 62, 63, 65, 70, 71, 72, 76, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 96, 98, 99, 100, 102, 103, 104, 105, 106, 115, 118, 124, 128, 131, 133, 137, 143, 145, 149, 150, 151, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 176, 178, 179, 180, 183, 192, 193, 200, 202, 203], "result": [7, 10, 12, 17, 20, 23, 118, 200, 202], "activ": [7, 11, 15, 20, 29, 56, 68, 75, 94, 95, 100, 107, 108, 109, 111, 114, 118, 129, 130, 171, 173, 200, 203], "iter": [7, 200, 203], "implement": [7, 10, 12, 15, 20, 22, 23, 118, 191, 200, 203, 205, 215], "profil": [7, 10, 18, 156, 200, 215], "block": [7, 20, 24, 48, 64, 118, 200], "preprocess": [7, 34, 125, 126, 200, 205], "displai": [7, 200, 201, 205], "constructor": [7, 19, 200, 205], "With": [7, 200], "librari": [7, 11, 12, 17, 18, 19, 200, 201], "github": [7, 9, 21, 200, 201], "com": [7, 21, 200, 201], "facebookresearch": [7, 200, 201], "dit": [7, 200, 201], "xl": [7, 200, 201], "sampl": [7, 20, 200, 201], "train": [7, 20, 200, 201], "onboard": 7, "rewrit": 7, "switch": [7, 165], "pybind": 7, "unit": [7, 16, 20], "sweep": [7, 22], "header": [7, 10, 13], "descript": [7, 13, 19, 20, 22], "overview": [7, 18], "infrastructur": [7, 12, 18], "member": [7, 9, 18, 19], "fast": [7, 18, 58, 59, 61, 70, 155], "dispatch": [7, 18, 19, 23], "synchron": [7, 18, 20, 177, 215], "layernorm": [7, 18, 20], "add_layernorm": [7, 18, 20], "softmax_in_plac": [7, 18, 20], "moreh_softmax": [7, 18, 20], "moreh_softmax_backward": [7, 18, 20], "moreh_softmin": [7, 18, 20], "moreh_softmin_backward": [7, 18, 20], "moreh_logsoftmax": [7, 18, 20], "moreh_logsoftmax_backward": [7, 18, 20], "scale_mask_softmax_in_plac": [7, 18, 20], "moreh_mean": [7, 18, 20], "moreh_mean_backward": [7, 18, 20], "moreh_groupnorm": [7, 18, 20], "moreh_groupnorm_backward": [7, 18, 20], "moreh_norm": [7, 18, 20], "moreh_norm_backward": [7, 18, 20], "enum": [7, 18], "bcastopmath": [7, 18, 20], "bcastopdim": [7, 18, 20], "reduceopmath": [7, 18, 20], "reduceopdim": [7, 18, 20], "elementwis": [7, 18], "div": [7, 18, 20], "div_no_nan": [7, 18, 20], "add_unari": [7, 18, 20], "sub_unari": [7, 18, 20], "mul_unari": [7, 18, 20], "div_unari": [7, 18, 20], "relu_min": [7, 18, 20], "relu_max": [7, 18, 20], "recip": [7, 18, 20], "add1": [7, 18, 20], "right_shift": [7, 18, 20], "left_shift": [7, 18, 20], "logical_xori": [7, 18, 20], "logical_not_unari": [7, 18, 20], "subalpha": [7, 18, 20], "addalpha": [7, 18, 20], "bias_gelu_unari": [7, 18, 20], "logical_andi": [7, 18, 20], "assign": [7, 17, 18, 20], "logical_ori": [7, 18, 20], "floor": [7, 18, 20], "trunc": [7, 18, 20], "round": [7, 18, 20], "floor_div": [7, 18, 20], "relat": [7, 18], "unary_n": [7, 18, 20], "unary_gt": [7, 18, 20], "unary_lt": [7, 18, 20], "bmm": [7, 18, 20], "transpos": [7, 18, 20, 190, 191], "tilize_with_val_pad": [7, 18, 20], "untilize_with_unpad": [7, 18, 20], "tilize_with_zero_pad": [7, 18, 20], "unpad": [7, 17, 18, 19, 20, 43, 183], "typecast": [7, 18, 20], "split_last_dim_two_chunks_til": [7, 18, 20], "broadcast": [7, 18, 29, 56, 68, 75, 94, 95, 100, 107, 108, 109, 111, 114, 118, 129, 130, 152, 171, 173, 215], "reduc": [7, 18, 33], "bcast": [7, 18, 20], "global_min": [7, 18, 20], "global_max": [7, 18, 20], "global_sum": [7, 18, 20], "global_mean": [7, 18, 20], "rpow": [7, 18, 20], "rsub": [7, 18, 20], "rdiv": [7, 18, 20], "tensor_slic": [7, 18, 20], "interpol": [7, 18, 20], "groupnorm": [7, 18, 20], "adaptiveavgpool2d": [7, 18, 20], "ceil": [7, 18, 20], "unary_fmod": [7, 18, 20], "binary_fmod": [7, 18, 20], "bitwise_not": [7, 18, 20], "unary_bitwise_or": [7, 18, 20], "unary_bitwise_and": [7, 18, 20], "unary_bitwise_xor": [7, 18, 20], "binary_bitwise_or": [7, 18, 20], "binary_bitwise_and": [7, 18, 20], "binary_bitwise_xor": [7, 18, 20], "unary_bitwise_left_shift": [7, 18, 20], "unary_bitwise_right_shift": [7, 18, 20], "binary_bitwise_left_shift": [7, 18, 20], "binary_bitwise_right_shift": [7, 18, 20], "torch_argmax": [7, 18, 20], "torch_argmin": [7, 18, 20], "mini": [7, 18], "addandnorm": [7, 18, 20], "complex": [7, 18], "complex_add": [7, 18, 20], "complex_sub": [7, 18, 20], "complex_mul": [7, 18, 20], "complex_div": [7, 18, 20], "real": [7, 18, 19, 20], "complex_ab": [7, 18, 20], "conj": [7, 18, 20], "complex_recip": [7, 18, 20], "polar": [7, 18, 20], "other": [7, 9, 12, 13, 15, 16, 18, 21, 24, 215], "fill_rm": [7, 18, 20], "fill_ones_rm": [7, 18, 20], "rmsnorm": [7, 18, 20], "convert_conv_weight_tensor_to_tiled_layout": [7, 18, 20], "prod": [7, 18, 20, 48], "tiled_prod": [7, 18, 20], "mean_hw": [7, 18, 20], "var_hw": [7, 18, 20], "logical_noti": [7, 18, 20], "std_hw": [7, 18, 20], "normalize_hw": [7, 18, 20], "normalize_glob": [7, 18, 20], "lamb_optim": [7, 18, 20], "argmin": [7, 18, 20], "backward": [7, 18], "prod_bw": [7, 18, 20], "addalpha_bw": [7, 18, 20], "addcmul_bw": [7, 18, 20], "addcdiv_bw": [7, 18, 20], "conj_bw": [7, 18, 20], "unary_mul_bw": [7, 18, 20], "unary_add_bw": [7, 18, 20], "unary_assign_bw": [7, 18, 20], "binary_assign_bw": [7, 18, 20], "unary_div_bw": [7, 18, 20], "div_bw": [7, 18, 20], "rdiv_bw": [7, 18, 20], "sqrt_bw": [7, 18, 20], "mul_bw": [7, 18, 20], "max_bw": [7, 18, 20], "min_bw": [7, 18, 20], "add_bw": [7, 18, 20], "tan_bw": [7, 18, 20], "exp_bw": [7, 18, 20], "exp2_bw": [7, 18, 20], "expm1_bw": [7, 18, 20], "unary_pow_bw": [7, 18, 20], "embedding_bw": [7, 18, 20], "where_bw": [7, 18, 20], "tanh_bw": [7, 18, 20], "fill_zero_bw": [7, 18, 20], "fill_bw": [7, 18, 20], "sub_bw": [7, 18, 20], "unary_sub_bw": [7, 18, 20], "log_bw": [7, 18, 20], "rsub_bw": [7, 18, 20], "abs_bw": [7, 18, 20], "complex_abs_bw": [7, 18, 20], "rsqrt_bw": [7, 18, 20], "neg_bw": [7, 18, 20], "lt_bw": [7, 18, 20], "gt_bw": [7, 18, 20], "relu_bw": [7, 18, 20], "ne_bw": [7, 18, 20], "clamp_bw": [7, 18, 20], "clamp_min_bw": [7, 18, 20], "clamp_max_bw": [7, 18, 20], "binary_le_bw": [7, 18, 20], "atan2_bw": [7, 18, 20], "hypot_bw": [7, 18, 20], "gelu_bw": [7, 18, 20], "bias_gelu_bw": [7, 18, 20], "bias_gelu_unary_bw": [7, 18, 20], "squared_difference_bw": [7, 18, 20], "lerp_bw": [7, 18, 20], "ldexp_bw": [7, 18, 20], "xlogy_bw": [7, 18, 20], "logaddexp_bw": [7, 18, 20], "logaddexp2_bw": [7, 18, 20], "concat_bw": [7, 18, 20], "hardsigmoid_bw": [7, 18, 20], "i0_bw": [7, 18, 20], "hardshrink_bw": [7, 18, 20], "softshrink_bw": [7, 18, 20], "hardswish_bw": [7, 18, 20], "softplus_bw": [7, 18, 20], "polygamma_bw": [7, 18, 20], "atan_bw": [7, 18, 20], "atanh_bw": [7, 18, 20], "asin_bw": [7, 18, 20], "asinh_bw": [7, 18, 20], "cosh_bw": [7, 18, 20], "cos_bw": [7, 18, 20], "acosh_bw": [7, 18, 20], "acos_bw": [7, 18, 20], "erfinv_bw": [7, 18, 20], "leaky_relu_bw": [7, 18, 20], "elu_bw": [7, 18, 20], "hardtanh_bw": [7, 18, 20], "angle_bw": [7, 18, 20], "sin_bw": [7, 18, 20], "sinh_bw": [7, 18, 20], "celu_bw": [7, 18, 20], "binary_lt_bw": [7, 18, 20], "subalpha_bw": [7, 18, 20], "log10_bw": [7, 18, 20], "log1p_bw": [7, 18, 20], "binary_ne_bw": [7, 18, 20], "erf_bw": [7, 18, 20], "erfc_bw": [7, 18, 20], "digamma_bw": [7, 18, 20], "deg2rad_bw": [7, 18, 20], "rad2deg_bw": [7, 18, 20], "reciprocal_bw": [7, 18, 20], "relu6_bw": [7, 18, 20], "rpow_bw": [7, 18, 20], "silu_bw": [7, 18, 20], "selu_bw": [7, 18, 20], "binary_ge_bw": [7, 18, 20], "binary_eq_bw": [7, 18, 20], "binary_gt_bw": [7, 18, 20], "square_bw": [7, 18, 20], "lgamma_bw": [7, 18, 20], "trunc_bw": [7, 18, 20], "frac_bw": [7, 18, 20], "log_sigmoid_bw": [7, 18, 20], "tanhshrink_bw": [7, 18, 20], "threshold_bw": [7, 18, 20], "unary_eq_bw": [7, 18, 20], "logit_bw": [7, 18, 20], "logiteps_bw": [7, 18, 20], "softsign_bw": [7, 18, 20], "sign_bw": [7, 18, 20], "ceil_bw": [7, 18, 20], "log2_bw": [7, 18, 20], "ge_bw": [7, 18, 20], "le_bw": [7, 18, 20], "unary_fmod_bw": [7, 18, 20], "unary_remainder_bw": [7, 18, 20], "complex_recip_bw": [7, 18, 20], "imag_bw": [7, 18, 20], "real_bw": [7, 18, 20], "complex_mul_bw": [7, 18, 20], "complex_div_bw": [7, 18, 20], "polar_bw": [7, 18, 20], "complex_add_bw": [7, 18, 20], "complex_sub_bw": [7, 18, 20], "multigammaln_bw": [7, 18, 20], "repeat_bw": [7, 18, 20], "floor_bw": [7, 18, 20], "round_bw": [7, 18, 20], "unary_div_no_nan_bw": [7, 18, 20], "mseloss": [7, 18, 20], "maeloss": [7, 18, 20], "buffer": [7, 18, 19, 20, 23, 24, 215], "get_dtyp": [7, 18, 19], "get_layout": [7, 18, 19], "get_legacy_shap": [7, 17, 18, 19], "pad_to_til": [7, 18, 19], "storage_typ": [7, 18, 19], "unpad_from_til": [7, 18, 19], "memoryconfig": [7, 18, 20, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 143, 144, 145, 148, 149, 150, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197, 198, 199], "between": [7, 12, 18, 20, 25], "one": [7, 18, 20, 118], "odd": [7, 18], "last": [7, 18, 19, 20, 23, 24, 43, 183, 191], "uplift": 7, "placehold": 7, "titl": 7, "prerequisit": 7, "next": [7, 20, 24, 132], "bug": 7, "propos": [7, 22], "troubleshoot": [7, 16], "tip": 7, "commun": 7, "contribut": [7, 9, 21], "search": 7, "page": [7, 21], "If": [8, 9, 19, 20, 21, 22, 23, 25, 33, 48, 118, 125, 126, 136, 164, 185, 191, 215], "would": [8, 20, 22, 23, 24], "project": [8, 9, 11, 21], "pleas": [8, 9, 16, 20, 21, 22, 215], "review": [8, 21, 22], "standard": [8, 9, 16, 20, 21], "gain": 8, "repositori": 8, "read": [8, 20, 21, 24, 48], "section": [8, 9, 16, 20, 24], "contact": 8, "u": [8, 22], "formal": 9, "permiss": 9, "cloud": 9, "relev": [9, 16], "ever": 9, "help": [9, 12, 22, 200], "offici": 9, "discord": 9, "channel": [9, 20, 23, 25, 72, 194], "discuss": [9, 16], "board": 9, "bounc": 9, "idea": [9, 16], "off": [9, 15, 20], "each": [9, 10, 12, 19, 20, 23, 24, 72, 137, 151, 152], "refer": [9, 10, 11, 12, 19, 20, 22, 24, 215], "conduct": 9, "interact": 9, "ensur": [10, 11, 16], "metalium": [10, 11], "sourc": [10, 11, 90, 200], "instruct": [10, 11, 16, 21, 200, 215], "readi": [10, 11, 16, 191], "come": [10, 21, 23], "typic": [10, 24, 72], "under": [10, 11, 16, 17, 22, 23, 200, 215], "your_model": 10, "perf_model": 10, "python_api_test": 10, "perf_your_model": 10, "perf_your_model_d": 10, "two": [10, 15, 19, 20, 24, 43, 118, 183, 191], "batch": [10, 19, 20, 23, 100, 118], "sec": 10, "g": [10, 20, 23], "throughput": 10, "inf": [10, 20], "vit": 10, "patch16": 10, "0623": 10, "4960": 10, "includ": [10, 13, 16], "without": [10, 17, 19, 20], "abovement": 10, "grayskul": [10, 13, 15, 21, 200, 201, 202, 203, 204, 205, 206, 207, 215], "sinc": [10, 17], "dure": 10, "pai": 10, "suggest": 10, "calcul": [10, 20, 23, 48], "maintain": [10, 22], "run_perform": [10, 16], "facilit": 10, "fastest": 10, "command": [10, 20, 23, 29, 33, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 171, 173, 215], "merg": [10, 22], "root": [11, 20, 187, 188], "virtual": 11, "which": [11, 12, 15, 19, 20, 23, 24, 48, 100, 118, 125, 126, 164], "ll": 11, "work": [11, 15, 16, 21, 200, 201, 202, 203, 204, 205, 206, 207, 215], "python_env_dir": 11, "variabl": [11, 20, 215], "create_venv": 11, "common": [11, 16, 20], "practic": 11, "export": [11, 20, 215], "pwd": 11, "split": [11, 20, 24, 191], "sub": [11, 12, 20], "md": [11, 16], "give": [11, 20, 23], "yet": 11, "entir": [11, 20, 72], "path_to_test_fil": 11, "test_in_fil": 11, "friendli": [11, 12, 21], "top": [11, 19, 200], "interfac": [12, 20], "design": 12, "familiar": 12, "trust": 12, "valuabl": 12, "your": [12, 16, 17, 20, 23, 200], "journei": 12, "advantag": 12, "stabl": [12, 20], "compat": 12, "some": [12, 13, 20, 215], "abil": [12, 20], "equival": [12, 20, 24, 33, 191], "meant": 13, "contributor": 13, "Not": [13, 15, 215], "mai": [13, 15, 20, 215], "wormhol": [13, 15, 200, 215], "tt_dnn": 13, "op_librari": 13, "new_oper": 13, "pragma": 13, "struct": [13, 20], "newoper": [13, 20], "bool": [13, 20, 25, 48, 49, 53, 58, 59, 61, 64, 70, 81, 84, 96, 100, 118, 119, 121, 122, 125, 126, 155, 172, 174, 187, 188, 195], "some_arg": 13, "These": [13, 16, 17, 20, 200, 215], "void": [13, 20], "const": [13, 20], "vector": [13, 19, 20, 118], "compute_output_shap": [13, 20], "create_output_tensor": [13, 20], "programwithcallback": [13, 20], "create_program": [13, 20], "static": [13, 20], "constexpr": [13, 20], "auto": [13, 20], "attribute_nam": [13, 20], "forward_as_tupl": [13, 20], "attribute_valu": [13, 20], "host_api": 13, "run_oper": 13, "output_shap": 13, "deviceoper": 13, "csrc": 13, "tt_lib_bindings_tensor": 13, "m_tensor": 13, "arg": [13, 19, 20, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 39, 40, 43, 45, 46, 47, 48, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 68, 70, 71, 72, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 98, 99, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 124, 125, 126, 128, 129, 130, 131, 132, 133, 137, 138, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 173, 176, 178, 179, 180, 182, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 196, 215], "noconvert": 13, "rang": [13, 19, 20], "w0": [13, 20], "z0": [13, 20], "y0": [13, 20], "x0": [13, 20], "ye": [13, 19, 20], "stuff": 13, "unit_test": 13, "ttl": [13, 19, 23], "test_": 13, "utils_for_test": [13, 15], "assert_with_pcc": [13, 15], "mark": [13, 15, 16], "parametr": [13, 15], "height": [13, 20, 23, 24, 43, 48, 72, 118, 183], "width": [13, 20, 23, 43, 48, 72, 118, 183, 189], "torch_output_tensor": [13, 215], "sweep_test": 13, "ttl_": 13, "tupl": [13, 20, 25, 48, 119, 121, 122, 137, 172, 174, 191, 194, 195], "check_with_pcc": 13, "4096": [13, 19], "basi": 15, "There": [15, 19, 20, 24], "approach": [15, 22, 165], "rewritten": 15, "For": [15, 16, 19, 20, 22, 23, 24, 118, 191], "bertintermedi": 15, "dens": 15, "intermediate_s": 15, "tdd": 15, "torch_bert": 15, "utility_funct": 15, "torch_random": 15, "test_bert_intermedi": 15, "golden": [15, 215], "convert_to_ttnn": [15, 125, 126], "keep": [15, 24], "bert_intermedi": 15, "dictionari": 15, "its": [15, 16, 19, 20, 22, 23, 24, 118, 215], "structur": 15, "turn": 15, "999": 15, "Then": [15, 191], "someth": 15, "isinst": 15, "ff1_weight": 15, "ff1_bia": 15, "local": [15, 16, 24], "manual": [15, 215], "grid": [15, 24, 100, 118], "possibl": [15, 20, 185], "addit": [15, 20], "integr": [15, 16, 17, 20], "incredibli": 16, "excit": 16, "exploratori": 16, "allow": [16, 19, 20, 22], "freedom": 16, "improv": [16, 165], "showcas": 16, "question": 16, "answer": 16, "befor": [16, 20, 24, 34, 137, 147, 165], "below": [16, 20, 23, 24], "highlight": [16, 24], "migrat": 16, "doe": [16, 20, 23, 43], "good": 16, "documen": 16, "within": [16, 19, 20, 24, 200], "describ": [16, 20], "credit": 16, "author": 16, "appropri": 16, "necessari": 16, "A": [16, 17, 19, 20, 22, 24, 118, 165], "error": [16, 20, 185], "encount": 16, "demonstr": [16, 23], "adequ": 16, "achiev": [16, 22], "accept": [16, 22], "pearson": 16, "correl": [16, 20], "coeffici": [16, 20, 140], "pcc": [16, 22], "ci": 16, "pipelin": [16, 23], "metric": 16, "meet": 16, "accuraci": [16, 20], "continu": [16, 22], "against": [16, 215], "upon": 16, "ongo": 16, "complianc": 16, "catch": 16, "regress": 16, "earli": 16, "limit": [16, 20], "usag": 16, "varieti": [16, 20], "condit": [16, 20, 196], "measur": 16, "updat": [16, 22, 91, 215], "special": [16, 20, 24], "run_device_perf_model": 16, "annot": 16, "models_device_performance_bare_met": 16, "schedul": 16, "appli": [16, 20, 25, 26, 27, 28, 29, 35, 36, 37, 39, 40, 46, 47, 50, 51, 53, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 118, 124, 128, 129, 130, 131, 133, 137, 143, 145, 149, 150, 151, 152, 155, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 171, 173, 176, 178, 179, 180, 190, 192, 193], "incorpor": 16, "autom": 16, "extern": [16, 22, 24], "servic": 16, "impact": 16, "either": [16, 20, 24, 43, 48, 118, 183, 200], "run_perf_models_oth": 16, "run_perf_models_llm_javelin": 16, "run_perf_models_cnn_javelin": 16, "models_performance_bare_met": 16, "purpos": [16, 22, 24, 118], "organ": [16, 24, 43, 183], "manag": [16, 117, 146, 147], "test_ttnn_functional_resnet50": 16, "resnet50testinfra": 16, "send": [17, 19, 20], "__name__": 17, "slot": 17, "tt_devic": [17, 19, 20], "createdevic": [17, 19], "py_tensor": [17, 19], "tt_tensor": [17, 19, 20], "tolist": [17, 19], "tt_relu_out": 17, "tt_output": [17, 19], "closedevic": 17, "previou": 17, "expon": [17, 20], "power": [17, 20], "scalar": [17, 20], "power_fp": 17, "float": [17, 19, 20, 29, 30, 31, 38, 41, 42, 56, 66, 67, 68, 74, 75, 77, 82, 84, 93, 94, 95, 97, 107, 108, 109, 111, 112, 113, 114, 116, 120, 123, 129, 130, 132, 137, 139, 140, 141, 154, 165, 166, 171, 173, 181, 197], "point": [17, 20, 23, 25, 132, 165], "posit": [17, 20], "But": 17, "suppli": [17, 19, 20], "lastli": 17, "fallback_op": [17, 20], "py_tensor_exp": 17, "py_relu_out": 17, "avail": [17, 19, 20, 194, 200, 215], "py_pow_out": 17, "tt_pow_out": 17, "behav": [17, 20], "regular": 17, "even": [17, 20, 118], "though": [17, 118], "hood": 17, "tt_silu_out": 17, "tt_exp_out": 17, "dimens": [17, 19, 20, 24, 33, 43, 45, 72, 118, 138, 152, 164, 183, 185, 189, 191], "must": [17, 19, 20, 24, 33, 118, 146, 147, 216], "setdefaultdevic": [17, 20], "leav": 17, "anyth": 17, "manipul": [19, 20], "sent": 19, "receiv": [19, 23], "ttdnn": 19, "w": [19, 20, 23, 194], "divis": [19, 20, 24], "construct": [19, 215], "nor": 19, "subsect": 19, "insid": [19, 215], "66": 19, "3968": 19, "3969": 19, "3970": 19, "4031": 19, "4032": 19, "4033": 19, "4034": 19, "4095": 19, "4097": 19, "4098": 19, "4159": 19, "4160": 19, "4161": 19, "6462": 19, "4223": 19, "8064": 19, "8065": 19, "8066": 19, "8127": 19, "8128": 19, "8129": 19, "8130": 19, "8191": 19, "95": 19, "1984": 19, "1985": 19, "2016": 19, "2047": 19, "2080": 19, "2081": 19, "2111": 19, "2144": 19, "2145": 19, "2175": 19, "4064": 19, "4065": 19, "fourth": [19, 20], "6111": 19, "6176": 19, "ownedstorag": [19, 20], "borrowedstorag": 19, "devicestorag": [19, 20], "correspond": [19, 20, 54], "itself": 19, "share": 19, "pointer": 19, "underli": 19, "well": [19, 22], "etc": 19, "reason": 19, "list": [19, 20, 29, 45, 48, 54, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 138, 140, 153, 171, 173], "bfloat4_b": [19, 20, 29, 56, 68, 75, 93, 94, 95, 107, 108, 109, 111, 114, 129, 130, 154, 171, 173, 183, 184], "No": [19, 20], "mem_config": [19, 184], "bank": [19, 20], "kwarg": [19, 20, 142, 146, 147, 153, 182, 215], "arg0": [19, 20], "arg1": [19, 20], "arg2": [19, 20], "arg3": [19, 20], "arg4": [19, 20], "divisbl": [19, 20], "arg5": [19, 20], "tensormemorylayout": [19, 20, 30, 31, 38, 41, 42, 69, 73, 77, 82, 92, 97, 112, 113, 116, 120, 123, 127, 139, 141, 148, 166, 175, 181, 197], "single_bank": 19, "ptr": 19, "np": 19, "owned_buffer_for_uint16_t": 19, "owned_buffer_for_int32_t": 19, "owned_buffer_for_uint32_t": 19, "owned_buffer_for_float32_t": 19, "owned_buffer_for_bfloat16_t": 19, "borrowed_buffer_for_uint16_t": 19, "borrowed_buffer_for_int32_t": 19, "borrowed_buffer_for_uint32_t": 19, "borrowed_buffer_for_float32_t": 19, "borrowed_buffer_for_bfloat16_t": 19, "indic": [19, 20, 33, 54], "everywher": [19, 20], "place": [19, 20, 24, 90, 91, 188], "along": [19, 20, 24, 164, 189], "output_tensor_shap": [19, 20], "input_tensor_shap": [19, 20], "input_tensor_start": [19, 20], "pad_valu": [19, 20], "inp": 19, "tt_tensor_pad": 19, "npad": 19, "right": [19, 20], "bottom": [19, 200], "storagetyp": 19, "memory_layout": [19, 20, 30, 31, 38, 41, 42, 69, 73, 77, 82, 92, 97, 112, 113, 116, 120, 123, 127, 139, 141, 148, 166, 175, 181, 197], "interleav": [19, 20, 24, 30, 31, 38, 41, 42, 69, 73, 77, 82, 92, 97, 112, 113, 116, 120, 123, 127, 139, 141, 148, 152, 166, 175, 181, 184, 191, 197], "buffer_typ": [19, 20, 30, 31, 38, 41, 42, 69, 73, 77, 82, 92, 97, 112, 113, 116, 120, 123, 127, 139, 141, 148, 166, 175, 181, 197], "buffertyp": [19, 20, 30, 31, 38, 41, 42, 69, 73, 77, 82, 92, 97, 112, 113, 116, 120, 123, 127, 139, 141, 148, 166, 175, 181, 197], "shard_spec": [19, 20, 30, 31, 38, 41, 42, 69, 73, 77, 82, 92, 97, 112, 113, 116, 120, 123, 127, 139, 141, 148, 166, 175, 181, 197], "nullopt": [19, 20, 30, 31, 33, 38, 41, 42, 69, 73, 77, 82, 92, 97, 112, 113, 116, 120, 123, 127, 139, 141, 148, 166, 175, 181, 197], "device_mesh": 19, "multi_devic": [19, 182], "devicemesh": [19, 182, 183], "target_layout": [19, 20], "worker": [19, 183], "target": [19, 20], "ti": 19, "inclus": [19, 20, 24], "output_tensor_end": [19, 20], "output_tensor_start": [19, 20], "tt_tensor_unpad": 19, "nunpad": 19, "align": [19, 20, 23], "left": [19, 20, 22], "apart": 19, "restrict": 19, "defin": [19, 20, 22, 24, 34], "eight": 19, "shardspec": 19, "across": [19, 20, 23, 24, 72], "select": [19, 20, 22, 196], "dram_channel": 19, "rememb": 19, "py_output": 19, "unifi": 20, "better": 20, "caller": 20, "launch": [20, 200], "plug": 20, "declar": 20, "some_memb": 20, "cref": 20, "optional_input_tensor": 20, "leverag": [20, 118], "validate_with_output_tensor": 20, "programwithoptionaloutputtensor": 20, "compute_output_tensor": 20, "box": 20, "preferred_nam": 20, "parallelization_strategi": 20, "get_parallelization_strategi": 20, "parallelizationstrategyenum": 20, "enqueu": 20, "wait": [20, 23, 177], "asynchron": 20, "complet": [20, 177], "reload": 20, "program_cach": 20, "disable_and_clear": 20, "entri": 20, "num_entri": 20, "cachabl": 20, "mandatori": 20, "override_runtime_args_callback": 20, "e": [20, 23, 118, 215], "unary_reader_kernel_id": 20, "unary_writer_kernel_id": 20, "input_buff": 20, "output_buff": 20, "src_dram_buff": 20, "dst_dram_buff": 20, "corecoord": 20, "runtime_arg": 20, "getruntimearg": 20, "address": 20, "tt_metal_logger_typ": [20, 215], "tt_metal_logger_level": [20, 215], "inform": 20, "1280": 20, "layoutconversiononhost": 20, "320": [20, 48], "miss": [20, 215], "eltwiseunari": 20, "op_typ": 20, "unaryoptyp": 20, "_tt": 20, "operation_history_csv": [20, 215], "csv_file_path": 20, "histori": 20, "autofunct": [20, 110], "ep": 20, "gamma": 20, "beta": [20, 165], "program_config": [20, 93, 100, 118, 187, 188], "union": [20, 25, 66, 67], "layernormdefaultprogramconfig": 20, "layernormshardedmulticoreprogramconfig": 20, "0x7f7e10cd07f0": 20, "compute_kernel_config": [20, 100, 118, 190], "grayskullcomputekernelconfig": 20, "wormholecomputekernelconfig": 20, "via": 20, "0x7f7e10cd1730": 20, "softmaxdefaultprogramconfig": [20, 187, 188], "softmaxshardedmulticoreprogramconfig": 20, "0x7f7e10cdd0f0": 20, "morehsoftmaxopparallelizationstrategi": 20, "output_grad_tensor": 20, "input_grad_tensor": 20, "morehsoftmaxbackwardopparallelizationstrategi": 20, "grad": 20, "softmin": 20, "logsoftmax": 20, "scale": [20, 78, 79, 165], "mask": [20, 187, 188], "0x7f7e10cc3530": 20, "is_causal_mask": 20, "output_grad": 20, "input_grad": 20, "num_group": [20, 74], "999999747378752e": 20, "are_required_output": 20, "rstd": 20, "mean_mem_config": 20, "rstd_mem_config": 20, "gamma_grad": 20, "beta_grad": 20, "input_grad_mem_config": 20, "gamma_grad_mem_config": 20, "beta_grad_mem_config": 20, "p": [20, 24, 118], "h": [20, 24, 194], "hw": 20, "input_a": [20, 84, 132], "input_b": [20, 84, 132], "accurate_mod": 20, "wise": [20, 26, 27, 28, 35, 36, 37, 39, 40, 46, 47, 50, 51, 53, 57, 58, 59, 60, 61, 62, 63, 70, 71, 76, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 96, 98, 99, 102, 103, 104, 105, 106, 115, 124, 128, 131, 133, 143, 145, 149, 150, 155, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 176, 178, 179, 180, 192, 193], "non": [20, 25, 118], "numer": [20, 165], "denomin": 20, "eltwis": 20, "fast_and_approx": 20, "gaussian": 20, "approx": 20, "accur": 20, "slow": 20, "rectifi": 20, "lower_limit": 20, "down": 20, "carri": 20, "minvalu": 20, "upper_limit": 20, "cap": 20, "exponenti": 20, "natur": 20, "logarithm": 20, "hyperbol": 20, "tangent": 20, "low": [20, 80], "high": [20, 80], "0f": 20, "equal": [20, 56, 68, 95, 130, 215], "coeff": [20, 140], "highest": 20, "degre": 20, "signum": 20, "absolut": 20, "negat": 20, "tensor1": [20, 29, 45, 56, 68, 75, 84, 94, 95, 107, 108, 109, 111, 114, 118, 129, 130, 171, 173], "tensor2": [20, 29, 45, 56, 68, 75, 84, 94, 95, 107, 108, 109, 111, 114, 118, 129, 130, 171, 173], "accumul": [20, 137], "float1": 20, "float2": 20, "input11": 20, "1666666716337204": 20, "shift": [20, 78, 79], "5f": 20, "slope": [20, 96], "leaki": [20, 96], "cosin": [20, 190], "sine": [20, 190], "arccosin": 20, "arcsin": 20, "alpha": [20, 53], "factor": 20, "shift_amt": 20, "bit": 20, "wormhole_b0": 20, "arctan": 20, "invers": 20, "immedi": 20, "logic": [20, 109, 111, 118, 125, 126], "xor": 20, "cq_id": 20, "queue": [20, 29, 33, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 171, 173], "id": [20, 23, 29, 33, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 171, 173], "integ": [20, 137], "boolean": 20, "finit": 20, "elsewher": 20, "infinit": 20, "infin": [20, 25], "clamp": 20, "greater": [20, 68, 75, 215], "AND": [20, 109], "multivari": 20, "mvlgamma": 20, "output_dtyp": 20, "queue_id": [20, 29, 33, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 171, 173], "uint8_t": 20, "rtol": [20, 84], "atol": [20, 84], "99999993922529e": 20, "equal_nan": [20, 84], "consid": 20, "1e": [20, 74, 84, 93, 154], "05f": 20, "08f": 20, "zeroth": 20, "bessel": 20, "kind": 20, "deriv": 20, "OR": [20, 111], "decim": 20, "less": [20, 23, 95, 114, 215], "predic": [20, 196], "true_valu": 20, "false_valu": 20, "third": 20, "three": 20, "replac": 20, "kernel_config": 20, "untilize_out": 20, "retain": 20, "dim0": 20, "dim1": 20, "swap": 20, "desir": [20, 138, 184, 185], "use_multicor": 20, "whether": [20, 100, 118, 125, 126, 191], "use_pack_until": 20, "pack": 20, "ofth": 20, "uint16": [20, 24, 29, 56, 68, 72, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 171, 173, 183, 184], "increment": [20, 32], "fill_valu": [20, 66, 67], "fill": [20, 23, 151], "assum": [20, 190, 194, 200], "diag": [20, 192, 193], "lower": 20, "triangular": 20, "rest": 20, "being": [20, 23, 24, 146, 147], "diagon": 20, "int32_t": 20, "upper": [20, 24], "math_op": 20, "w1": 20, "z1": 20, "y1": 20, "x1": 20, "hold": 20, "aggreg": [20, 23], "scaler": 20, "mathemat": 20, "ax": 20, "respect": [20, 24, 118], "subtrah": 20, "minuend": 20, "divid": [20, 187, 188], "ellipsi": 20, "output_layout": 20, "output_on_devic": 20, "fewer": 20, "2d": [20, 24, 25, 72, 118, 194], "over": [20, 25, 72, 74, 93, 154, 164], "compos": [20, 25, 72], "sever": [20, 25, 72], "four": 20, "space": [20, 24, 25], "connect": 20, "paper": 20, "frac": 20, "mathrm": [20, 26, 27, 28, 29, 35, 36, 37, 39, 40, 46, 47, 50, 51, 53, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 124, 128, 129, 130, 131, 132, 133, 140, 143, 145, 149, 150, 155, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 171, 173, 176, 178, 179, 180, 192, 193], "epsilon": [20, 74, 93, 154], "separ": 20, "stabil": [20, 22, 165], "normalized_shap": 20, "text": 20, "constant": [20, 137], "reflect": [20, 22], "replic": 20, "circular": 20, "scale_factor": [20, 194], "nearest": [20, 194], "align_corn": 20, "recompute_scale_factor": 20, "antialia": 20, "algorithm": [20, 194], "spatial": [20, 72, 194], "bilinear": 20, "bicub": 20, "trilinear": 20, "area": 20, "center": 20, "corner": 20, "pixel": 20, "recomput": [20, 125], "anti": 20, "alias": 20, "output_s": 20, "repetit": [20, 151, 152], "total": [20, 23], "axi": [20, 152], "concaten": [20, 45, 189, 191], "known": 20, "sigma": 20, "logist": 20, "x_": 20, "x_i": 20, "sum_j": 20, "x_j": 20, "lie": 20, "in_channel": 20, "out_channel": 20, "padding_mod": 20, "simplest": 20, "c_": 20, "h_": 20, "w_": 20, "precis": 20, "n_i": 20, "_j": 20, "sum_": 20, "star": 20, "cross": 20, "denot": 20, "convolv": 20, "learnabl": 20, "running_mean": 20, "running_var": 20, "num_batches_track": 20, "num_featur": 20, "momentum": 20, "affin": 20, "track_running_stat": 20, "4d": 20, "deep": 20, "network": 20, "intern": [20, 21], "covari": 20, "track": 20, "varianc": 20, "num_channel": 20, "lernabl": 20, "elementwise_affin": 20, "return_indic": 20, "ceil_mod": 20, "channels_last": [20, 23], "reshape_2d": 20, "kh": 20, "kw": 20, "begin": [20, 23], "c_j": 20, "max_": 20, "ldot": 20, "window": [20, 25], "implicit": [20, 25], "adapt": [20, 72], "smallest": 20, "largest": 20, "truncat": 20, "mod": 20, "dividend": 20, "bitwis": 20, "arithmet": 20, "operand": 20, "promot": 20, "behavior": [20, 118], "undefin": 20, "keepdim": [20, 119, 121, 122, 172, 174, 195], "unexpect": 20, "fusion": 20, "togeth": 20, "fused_op": 20, "in_featur": 20, "out_featur": 20, "num_dim": 20, "spec": [20, 48], "moment": 20, "add_and_norm": 20, "imaginari": 20, "complextensor": 20, "portion": 20, "conjug": 20, "cartesian": 20, "theta": 20, "flexibl": 20, "earlier": 20, "while": [20, 22], "cost": 20, "logsigmoid": 20, "1e6": 20, "ouptut": 20, "complementari": 20, "hone": 20, "wone": 20, "val_hi": 20, "val_lo": 20, "nchw": 20, "hfill": 20, "wfill": 20, "hi": 20, "lo": 20, "region": 20, "arg6": 20, "arg7": 20, "arg8": 20, "arg9": 20, "arg10": 20, "conv_param": 20, "group_siz": 20, "conv_weight_tensor": 20, "in1_block_h": 20, "in1_block_w": 20, "all_dimens": 20, "irrespect": 20, "ignor": 20, "deviat": 20, "gate": 20, "embeddings_typ": 20, "embeddingstyp": 20, "pad_token": [20, 54], "num_row": 20, "num_embed": 20, "num_column": 20, "uint32_t": 20, "toward": [20, 132], "exp_avg": 20, "exp_avg_sq": 20, "beta1": 20, "beta2": 20, "step_siz": 20, "weight_decai": 20, "accord": [20, 118, 151], "sfpu": 20, "shouldn": 20, "gradient": 20, "other_grad": 20, "input_a_grad": 20, "input_b_grad": 20, "round_mod": 20, "uniqu": 20, "nonzero": 20, "yield": 20, "subract": 20, "revers": 20, "hypotenus": 20, "approxim": [20, 58, 59, 61, 70, 155], "lambd": 20, "negative_slop": 20, "009999999776482582": 20, "is_complextensor": 20, "angl": 20, "selu": 20, "fmod": 20, "ramaind": 20, "taken": 20, "input_refer": 20, "input_predict": 20, "reduce_mod": 20, "lossreductionmod": 20, "ml": 21, "workload": 21, "guid": 21, "falcon": 21, "7b": 21, "navig": 21, "mistral": 21, "llama2": 21, "70b": 21, "soon": 21, "t3000": 21, "dive": 21, "deeper": 21, "intend": 22, "reliabl": 22, "simultan": 22, "fine": 22, "tune": 22, "themselv": [22, 24], "goal": 22, "ask": 22, "driven": 22, "popular": 22, "kent": 22, "beck": 22, "long": 22, "term": 22, "benefit": 22, "submit": 22, "label": [22, 24], "fulli": [22, 23], "branch": 22, "pattern": [22, 125], "brief": 22, "4730": 22, "rst": 22, "format": 22, "pull": 22, "verifi": 22, "codeown": 22, "pr": 22, "comparison": 22, "comment": 22, "test_perf_resnet": 23, "test_perf_bare_met": 23, "0185": 23, "consol": 23, "shorter": 23, "cli": 23, "explain": 23, "reset": 23, "tt_smi": 23, "tensix_reset": 23, "tensix": 23, "skew": 23, "timer": 23, "reboot": 23, "sudo": 23, "wh": 23, "popul": [23, 90, 125], "least": [23, 118], "twice": 23, "analyz": 23, "higher": [23, 24, 165], "fixtur": 23, "dumpdeviceprofil": 23, "avoid": [23, 125, 165], "drop": 23, "around": 23, "eighth": 23, "messag": 23, "mention": 23, "risc": 23, "those": 23, "analysi": 23, "affect": 23, "flow": 23, "level": 23, "tt_dnn_cpu": 23, "field": 23, "lofi": 23, "hifi2": 23, "hifi3": 23, "system": 23, "clock": 23, "stamp": 23, "end_t": 23, "start_t": 23, "fw": 23, "cycl": 23, "earliest": 23, "latest": 23, "core_frequ": 23, "marker": 23, "brisc": 23, "ncrisc": 23, "trisc0": 23, "trisc1": 23, "trisc2": 23, "cb": 23, "spent": 23, "cb_wait_front": 23, "reserv": 23, "cb_reserve_back": 23, "hash": [23, 125, 126], "datamov": 23, "templat": 23, "io": 23, "input_0_memori": 23, "dev_0_dram": 23, "dec_0_l1": 23, "tgz": 23, "timestamp": 23, "32x32": 24, "bracket": 24, "consecut": 24, "4x4": 24, "still": 24, "transit": 24, "2x2": 24, "illustr": 24, "byte": 24, "sizeof": 24, "shown": 24, "owned_host_storag": 24, "borrowed_host_storag": 24, "device_storag": 24, "distribut": [24, 48, 52, 100, 118], "ideal": 24, "abstract": 24, "awai": 24, "compress": 24, "remain": 24, "128x128": 24, "who": 24, "subset": 24, "orient": [24, 48], "know": 24, "understand": 24, "unshard": 24, "coordin": 24, "physic": 24, "pybind11_object": 24, "properti": 24, "_ttnn": [24, 153, 182], "input_height": 25, "input_width": 25, "parallel_config_overrid": 25, "deallocate_activ": 25, "implicitli": 25, "_tensor": [26, 27, 28, 29, 35, 36, 37, 39, 40, 46, 47, 50, 51, 53, 57, 58, 59, 60, 61, 62, 63, 70, 71, 72, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 96, 98, 99, 102, 103, 104, 105, 106, 115, 124, 128, 131, 132, 133, 140, 143, 145, 149, 150, 155, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 176, 178, 179, 180, 192, 193], "_i": [26, 27, 28, 29, 35, 36, 37, 39, 40, 46, 47, 50, 51, 53, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 124, 128, 129, 130, 131, 132, 133, 140, 143, 145, 149, 150, 155, 157, 158, 159, 160, 161, 162, 163, 165, 167, 169, 170, 171, 173, 176, 178, 179, 180, 192, 193], "keyword": [26, 27, 28, 29, 33, 35, 36, 37, 39, 40, 45, 46, 47, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 75, 76, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 118, 124, 128, 129, 130, 131, 132, 133, 140, 143, 145, 146, 147, 149, 150, 151, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 173, 176, 178, 179, 180, 187, 188, 189, 192, 193, 196], "min_rank": [26, 27, 29, 33, 35, 37, 46, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 74, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195], "max_rank": [26, 27, 29, 33, 35, 37, 46, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 74, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195], "can_be_on_devic": [26, 27, 29, 33, 35, 37, 46, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 74, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195], "can_be_on_cpu": [26, 27, 29, 33, 35, 37, 46, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 74, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195], "can_be_scalar": [26, 27, 29, 33, 35, 37, 46, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 74, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195], "is_opt": [26, 27, 29, 33, 35, 37, 46, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 74, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195], "_a": [29, 84, 132, 140], "_b": [29, 84, 132], "prealloc": [29, 33, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 171, 173], "uint8": [29, 33, 56, 68, 75, 94, 95, 107, 108, 109, 111, 114, 129, 130, 171, 173], "input_tensor1": [30, 31], "input_tensor2": [30, 31], "flatten": 33, "cache_file_nam": 34, "pathlib": 34, "serial": 34, "mesh_mapp": 34, "tensortomesh": 34, "use_device_til": 34, "30469": [34, 65], "714844": [34, 65], "761719": [34, 65], "53125": [34, 65], "652344": [34, 65], "parameter1": [42, 181], "parameter2": [42, 181], "datayp": 43, "becom": [43, 183], "tnn": 43, "corerang": 48, "shardstrategi": 48, "shardorient": 48, "halo": 48, "use_height_and_width_as_shard_shap": 48, "travers": 48, "overlap": 48, "forc": 49, "fast_and_approximate_mod": [53, 58, 59, 61, 70, 81, 96, 155], "inxput_tensor": 54, "retriev": 54, "word": 54, "106445": 54, "988281": 54, "59375": 54, "212891": 54, "199219": 54, "996094": 54, "78362e": 54, "89785e": 54, "04479e": 54, "25815e": 54, "71833e": 54, "59995e": 54, "60398e": 54, "83671e": 54, "22242e": 54, "88263e": 54, "35917e": 54, "49994e": 54, "batch_index": 90, "update_index": 91, "batch_offset": 91, "loss_mod": [92, 127], "residual_input_tensor": 93, "programconfig": 93, "mcompar": 95, "matmulprogramconfig": [100, 118], "use_1d_systolic_arrai": [100, 118], "devicecomputekernelconfig": [100, 118, 190], "systol": [100, 118], "arrai": [100, 118], "128": [100, 118], "input1": 116, "input2": 116, "context": [117, 146, 147], "product": 118, "prepend": 118, "j": 118, "n_size": 118, "k_size": 118, "stategi": 118, "m_size": 118, "dot": 118, "fix": 118, "upcom": 118, "releas": 118, "tensorensor": 118, "callabl": [125, 126], "parameterdict": [125, 126], "prefix": [125, 126], "invalid": [125, 126], "preprocessor": [125, 126], "submodul": [125, 126], "appear": [125, 126], "ttnn_module_arg": 125, "reader": 125, "fit": 152, "expand": 152, "torch_result": 152, "0310059": 164, "adjust": 165, "steep": 165, "steeper": 165, "whose": 183, "42188": 183, "398438": 183, "vice": 184, "versa": 184, "torch_rank": 185, "Will": 185, "squeez": 185, "reach": 185, "3008": 185, "8438": 185, "3242": 185, "9023": 185, "5820": 185, "5312": 185, "softmaxprogramconfig": [187, 188], "causal_mask": [187, 188], "causal": [187, 188], "cos_cach": 190, "sin_cach": 190, "token_index": 190, "rotari": 190, "token_idx": 190, "seq_len": 190, "head_dim": 190, "kv_input_tensor": 191, "num_kv_head": 191, "q1": 191, "k1": 191, "v1": 191, "qn": 191, "kn": 191, "vn": 191, "transpose_kei": 191, "num": 191, "form": 194, "ramp": 200, "skillset": 200, "tree": 200, "softwar": 200, "lab": 200, "port": 200, "8888": 200, "hint": 200, "Be": 200, "sure": [200, 215], "cell": 200, "snippet": 215, "architectur": 215, "exp_trac": 215, "ttnn_config_overrid": 215, "operation_histori": 215, "stdout": 215, "substitut": 215, "disk": 215, "implementaiton": 215, "addition": 215, "ttnn_config_path": 215, "app": 215, "pre_hook_to_print_args_and_kwarg": 215, "post_hook_to_print_output": 215, "query_registered_oper": 215, "slower": 215, "notifi": 215, "ttnn_throw_exception_on_fallback": 215, "ttnn_sweep": 216}, "objects": {"tt_lib.device": [[20, 0, 1, "", "Synchronize"]], "tt_lib.fallback_ops": [[20, 1, 1, "", "AdaptiveAvgPool2d"], [20, 1, 1, "", "BatchNorm2d"], [20, 1, 1, "", "Conv2d"], [20, 1, 1, "", "GroupNorm"], [20, 1, 1, "", "LayerNorm"], [20, 1, 1, "", "MaxPool2d"], [20, 1, 1, "", "binary_bitwise_and"], [20, 1, 1, "", "binary_bitwise_left_shift"], [20, 1, 1, "", "binary_bitwise_or"], [20, 1, 1, "", "binary_bitwise_right_shift"], [20, 1, 1, "", "binary_bitwise_xor"], [20, 1, 1, "", "binary_fmod"], [20, 1, 1, "", "bitwise_not"], [20, 1, 1, "", "ceil"], [20, 0, 1, "", "chunk"], [20, 0, 1, "", "concat"], [20, 0, 1, "", "conv2d"], [20, 1, 1, "", "floor"], [20, 0, 1, "", "full"], [20, 0, 1, "", "group_norm"], [20, 0, 1, "", "interpolate"], [20, 0, 1, "", "layer_norm"], [20, 0, 1, "", "pad"], [20, 0, 1, "", "repeat"], [20, 0, 1, "", "repeat_interleave"], [20, 0, 1, "", "reshape"], [20, 0, 1, "", "silu"], [20, 0, 1, "", "softmax"], [20, 0, 1, "", "tensor_slice"], [20, 1, 1, "", "torch_argmax"], [20, 1, 1, "", "torch_argmin"], [20, 1, 1, "", "trunc"], [20, 1, 1, "", "unary_bitwise_and"], [20, 1, 1, "", "unary_bitwise_left_shift"], [20, 1, 1, "", "unary_bitwise_or"], [20, 1, 1, "", "unary_bitwise_right_shift"], [20, 1, 1, "", "unary_bitwise_xor"], [20, 1, 1, "", "unary_fmod"]], "tt_lib.fused_ops.add_and_norm": [[20, 0, 1, "", "AddAndNorm"]], "tt_lib.fused_ops.layernorm": [[20, 0, 1, "", "Layernorm"]], "tt_lib.fused_ops.linear": [[20, 0, 1, "", "Linear"]], "tt_lib.fused_ops.softmax": [[20, 0, 1, "", "softmax"]], "tt_lib.operations.primary": [[20, 0, 1, "", "add_layernorm"], [20, 0, 1, "", "layernorm"], [20, 0, 1, "", "moreh_groupnorm"], [20, 0, 1, "", "moreh_groupnorm_backward"], [20, 0, 1, "", "moreh_logsoftmax"], [20, 0, 1, "", "moreh_logsoftmax_backward"], [20, 0, 1, "", "moreh_mean"], [20, 0, 1, "", "moreh_mean_backward"], [20, 0, 1, "", "moreh_norm"], [20, 0, 1, "", "moreh_norm_backward"], [20, 0, 1, "", "moreh_softmax"], [20, 0, 1, "", "moreh_softmax_backward"], [20, 0, 1, "", "moreh_softmin"], [20, 0, 1, "", "moreh_softmin_backward"], [20, 0, 1, "", "softmax_in_place"]], "tt_lib.operations.primary.transformers": [[20, 0, 1, "", "scale_mask_softmax_in_place"]], "tt_lib.tensor": [[20, 1, 1, "", "BcastOpDim"], [20, 1, 1, "", "BcastOpMath"], [19, 1, 1, "", "MemoryConfig"], [20, 1, 1, "", "ReduceOpDim"], [20, 1, 1, "", "ReduceOpMath"], [19, 1, 1, "", "Tensor"], [20, 0, 1, "", "abs"], [20, 0, 1, "", "abs_bw"], [20, 0, 1, "", "acos"], [20, 0, 1, "", "acos_bw"], [20, 0, 1, "", "acosh"], [20, 0, 1, "", "acosh_bw"], [20, 0, 1, "", "add1"], [20, 0, 1, "", "add_bw"], [20, 0, 1, "", "add_layernorm"], [20, 0, 1, "", "add_unary"], [20, 0, 1, "", "addalpha"], [20, 0, 1, "", "addalpha_bw"], [20, 0, 1, "", "addcdiv"], [20, 0, 1, "", "addcdiv_bw"], [20, 0, 1, "", "addcmul"], [20, 0, 1, "", "addcmul_bw"], [20, 0, 1, "", "angle_bw"], [20, 0, 1, "", "arange"], [20, 0, 1, "", "argmax"], [20, 0, 1, "", "argmin"], [20, 0, 1, "", "asin"], [20, 0, 1, "", "asin_bw"], [20, 0, 1, "", "asinh"], [20, 0, 1, "", "asinh_bw"], [20, 0, 1, "", "assign"], [20, 0, 1, "", "atan"], [20, 0, 1, "", "atan2"], [20, 0, 1, "", "atan2_bw"], [20, 0, 1, "", "atan_bw"], [20, 0, 1, "", "atanh"], [20, 0, 1, "", "atanh_bw"], [20, 0, 1, "", "bcast"], [20, 0, 1, "", "bias_gelu_bw"], [20, 0, 1, "", "bias_gelu_unary"], [20, 0, 1, "", "bias_gelu_unary_bw"], [20, 0, 1, "", "binary_assign_bw"], [20, 0, 1, "", "binary_eq_bw"], [20, 0, 1, "", "binary_ge_bw"], [20, 0, 1, "", "binary_gt_bw"], [20, 0, 1, "", "binary_le_bw"], [20, 0, 1, "", "binary_lt_bw"], [20, 0, 1, "", "binary_ne_bw"], [20, 0, 1, "", "bmm"], [20, 0, 1, "", "cbrt"], [20, 0, 1, "", "ceil_bw"], [20, 0, 1, "", "celu"], [20, 0, 1, "", "celu_bw"], [20, 0, 1, "", "clamp_bw"], [20, 0, 1, "", "clamp_max_bw"], [20, 0, 1, "", "clamp_min_bw"], [20, 0, 1, "", "clip"], [20, 0, 1, "", "clone"], [20, 0, 1, "", "complex_abs"], [20, 0, 1, "", "complex_abs_bw"], [20, 0, 1, "", "complex_add"], [20, 0, 1, "", "complex_add_bw"], [20, 0, 1, "", "complex_div"], [20, 0, 1, "", "complex_div_bw"], [20, 0, 1, "", "complex_mul"], [20, 0, 1, "", "complex_mul_bw"], [20, 0, 1, "", "complex_recip"], [20, 0, 1, "", "complex_recip_bw"], [20, 0, 1, "", "complex_sub"], [20, 0, 1, "", "complex_sub_bw"], [20, 0, 1, "", "concat"], [20, 0, 1, "", "concat_bw"], [20, 0, 1, "", "conj"], [20, 0, 1, "", "conj_bw"], [20, 0, 1, "", "conv"], [20, 0, 1, "", "convert_conv_weight_tensor_to_tiled_layout"], [20, 0, 1, "", "copy"], [20, 0, 1, "", "cos"], [20, 0, 1, "", "cos_bw"], [20, 0, 1, "", "cosh"], [20, 0, 1, "", "cosh_bw"], [20, 0, 1, "", "deg2rad"], [20, 0, 1, "", "deg2rad_bw"], [20, 0, 1, "", "digamma"], [20, 0, 1, "", "digamma_bw"], [20, 0, 1, "", "div"], [20, 0, 1, "", "div_bw"], [20, 0, 1, "", "div_no_nan"], [20, 0, 1, "", "div_unary"], [20, 0, 1, "", "elu"], [20, 0, 1, "", "elu_bw"], [20, 0, 1, "", "embedding_bw"], [20, 0, 1, "", "embeddings"], [20, 0, 1, "", "empty"], [20, 0, 1, "", "eqz"], [20, 0, 1, "", "erf"], [20, 0, 1, "", "erf_bw"], [20, 0, 1, "", "erfc"], [20, 0, 1, "", "erfc_bw"], [20, 0, 1, "", "erfinv"], [20, 0, 1, "", "erfinv_bw"], [20, 0, 1, "", "exp"], [20, 0, 1, "", "exp2"], [20, 0, 1, "", "exp2_bw"], [20, 0, 1, "", "exp_bw"], [20, 0, 1, "", "expm1"], [20, 0, 1, "", "expm1_bw"], [20, 0, 1, "", "fill_bw"], [20, 0, 1, "", "fill_ones_rm"], [20, 0, 1, "", "fill_rm"], [20, 0, 1, "", "fill_zero_bw"], [20, 0, 1, "", "floor"], [20, 0, 1, "", "floor_bw"], [20, 0, 1, "", "floor_div"], [20, 0, 1, "", "frac_bw"], [20, 0, 1, "", "full"], [20, 0, 1, "", "full_like"], [20, 0, 1, "", "ge_bw"], [20, 0, 1, "", "geglu"], [20, 0, 1, "", "gelu"], [20, 0, 1, "", "gelu_bw"], [20, 0, 1, "", "gez"], [20, 0, 1, "", "global_max"], [20, 0, 1, "", "global_mean"], [20, 0, 1, "", "global_min"], [20, 0, 1, "", "global_sum"], [20, 0, 1, "", "glu"], [20, 0, 1, "", "groupnorm"], [20, 0, 1, "", "gt_bw"], [20, 0, 1, "", "gtz"], [20, 0, 1, "", "hardshrink"], [20, 0, 1, "", "hardshrink_bw"], [20, 0, 1, "", "hardsigmoid"], [20, 0, 1, "", "hardsigmoid_bw"], [20, 0, 1, "", "hardswish"], [20, 0, 1, "", "hardswish_bw"], [20, 0, 1, "", "hardtanh"], [20, 0, 1, "", "hardtanh_bw"], [20, 0, 1, "", "heaviside"], [20, 0, 1, "", "hypot"], [20, 0, 1, "", "hypot_bw"], [20, 0, 1, "", "i0"], [20, 0, 1, "", "i0_bw"], [20, 0, 1, "", "identity"], [20, 0, 1, "", "imag"], [20, 0, 1, "", "imag_bw"], [20, 0, 1, "", "isclose"], [20, 0, 1, "", "isfinite"], [20, 0, 1, "", "isinf"], [20, 0, 1, "", "isnan"], [20, 0, 1, "", "isneginf"], [20, 0, 1, "", "isposinf"], [20, 0, 1, "", "lamb_optimizer"], [20, 0, 1, "", "layernorm"], [20, 0, 1, "", "ldexp_bw"], [20, 0, 1, "", "le_bw"], [20, 0, 1, "", "leaky_relu"], [20, 0, 1, "", "leaky_relu_bw"], [20, 0, 1, "", "left_shift"], [20, 0, 1, "", "lerp"], [20, 0, 1, "", "lerp_bw"], [20, 0, 1, "", "lez"], [20, 0, 1, "", "lgamma"], [20, 0, 1, "", "lgamma_bw"], [20, 0, 1, "", "log"], [20, 0, 1, "", "log10"], [20, 0, 1, "", "log10_bw"], [20, 0, 1, "", "log1p"], [20, 0, 1, "", "log1p_bw"], [20, 0, 1, "", "log2"], [20, 0, 1, "", "log2_bw"], [20, 0, 1, "", "log_bw"], [20, 0, 1, "", "log_sigmoid"], [20, 0, 1, "", "log_sigmoid_bw"], [20, 0, 1, "", "logaddexp2_bw"], [20, 0, 1, "", "logaddexp_bw"], [20, 0, 1, "", "logical_andi"], [20, 0, 1, "", "logical_not_unary"], [20, 0, 1, "", "logical_noti"], [20, 0, 1, "", "logical_ori"], [20, 0, 1, "", "logical_xor"], [20, 0, 1, "", "logical_xori"], [20, 0, 1, "", "logit"], [20, 0, 1, "", "logit_bw"], [20, 0, 1, "", "logiteps_bw"], [20, 0, 1, "", "lt_bw"], [20, 0, 1, "", "ltz"], [20, 0, 1, "", "mac"], [20, 0, 1, "", "maeloss"], [20, 0, 1, "", "matmul"], [20, 0, 1, "", "max_bw"], [20, 0, 1, "", "mean_hw"], [20, 0, 1, "", "min_bw"], [20, 0, 1, "", "mish"], [20, 0, 1, "", "mseloss"], [20, 0, 1, "", "mul_bw"], [20, 0, 1, "", "mul_unary"], [20, 0, 1, "", "multigammaln"], [20, 0, 1, "", "multigammaln_bw"], [20, 0, 1, "", "ne_bw"], [20, 0, 1, "", "neg"], [20, 0, 1, "", "neg_bw"], [20, 0, 1, "", "nextafter"], [20, 0, 1, "", "nez"], [20, 0, 1, "", "normalize_global"], [20, 0, 1, "", "normalize_hw"], [20, 0, 1, "", "ones"], [20, 0, 1, "", "ones_like"], [20, 0, 1, "", "pad"], [20, 0, 1, "", "permute"], [20, 0, 1, "", "polar"], [20, 0, 1, "", "polar_bw"], [20, 0, 1, "", "polygamma"], [20, 0, 1, "", "polygamma_bw"], [20, 0, 1, "", "polyval"], [20, 0, 1, "", "pow"], [20, 0, 1, "", "prod"], [20, 0, 1, "", "prod_bw"], [20, 0, 1, "", "rad2deg"], [20, 0, 1, "", "rad2deg_bw"], [20, 0, 1, "", "rdiv"], [20, 0, 1, "", "rdiv_bw"], [20, 0, 1, "", "real"], [20, 0, 1, "", "real_bw"], [20, 0, 1, "", "recip"], [20, 0, 1, "", "reciprocal_bw"], [20, 0, 1, "", "reduce"], [20, 0, 1, "", "reglu"], [20, 0, 1, "", "relu"], [20, 0, 1, "", "relu6"], [20, 0, 1, "", "relu6_bw"], [20, 0, 1, "", "relu_bw"], [20, 0, 1, "", "relu_max"], [20, 0, 1, "", "relu_min"], [20, 0, 1, "", "repeat"], [20, 0, 1, "", "repeat_bw"], [20, 0, 1, "", "repeat_interleave"], [20, 0, 1, "", "reshape"], [20, 0, 1, "", "right_shift"], [20, 0, 1, "", "rmsnorm"], [20, 0, 1, "", "round"], [20, 0, 1, "", "round_bw"], [20, 0, 1, "", "rpow"], [20, 0, 1, "", "rpow_bw"], [20, 0, 1, "", "rsqrt"], [20, 0, 1, "", "rsqrt_bw"], [20, 0, 1, "", "rsub"], [20, 0, 1, "", "rsub_bw"], [20, 0, 1, "", "selu_bw"], [20, 0, 1, "", "sigmoid"], [20, 0, 1, "", "sigmoid_accurate"], [20, 0, 1, "", "sign"], [20, 0, 1, "", "sign_bw"], [20, 0, 1, "", "signbit"], [20, 0, 1, "", "silu"], [20, 0, 1, "", "silu_bw"], [20, 0, 1, "", "sin"], [20, 0, 1, "", "sin_bw"], [20, 0, 1, "", "sinh"], [20, 0, 1, "", "sinh_bw"], [20, 0, 1, "", "softplus"], [20, 0, 1, "", "softplus_bw"], [20, 0, 1, "", "softshrink"], [20, 0, 1, "", "softshrink_bw"], [20, 0, 1, "", "softsign"], [20, 0, 1, "", "softsign_bw"], [20, 0, 1, "", "split_last_dim_two_chunks_tiled"], [20, 0, 1, "", "sqrt"], [20, 0, 1, "", "sqrt_bw"], [20, 0, 1, "", "square"], [20, 0, 1, "", "square_bw"], [20, 0, 1, "", "squared_difference_bw"], [20, 0, 1, "", "std_hw"], [20, 0, 1, "", "sub_bw"], [20, 0, 1, "", "sub_unary"], [20, 0, 1, "", "subalpha"], [20, 0, 1, "", "subalpha_bw"], [20, 0, 1, "", "sum"], [20, 0, 1, "", "swiglu"], [20, 0, 1, "", "swish"], [20, 0, 1, "", "tan"], [20, 0, 1, "", "tan_bw"], [20, 0, 1, "", "tanh"], [20, 0, 1, "", "tanh_bw"], [20, 0, 1, "", "tanhshrink"], [20, 0, 1, "", "tanhshrink_bw"], [20, 0, 1, "", "threshold"], [20, 0, 1, "", "threshold_bw"], [20, 0, 1, "", "tiled_prod"], [20, 0, 1, "", "tilize"], [20, 0, 1, "", "tilize_with_val_padding"], [20, 0, 1, "", "tilize_with_zero_padding"], [20, 0, 1, "", "transpose"], [20, 0, 1, "", "tril"], [20, 0, 1, "", "triu"], [20, 0, 1, "", "trunc"], [20, 0, 1, "", "trunc_bw"], [20, 0, 1, "", "typecast"], [20, 0, 1, "", "unary_add_bw"], [20, 0, 1, "", "unary_assign_bw"], [20, 0, 1, "", "unary_div_bw"], [20, 0, 1, "", "unary_div_no_nan_bw"], [20, 0, 1, "", "unary_eq_bw"], [20, 0, 1, "", "unary_fmod_bw"], [20, 0, 1, "", "unary_gt"], [20, 0, 1, "", "unary_lt"], [20, 0, 1, "", "unary_mul_bw"], [20, 0, 1, "", "unary_ne"], [20, 0, 1, "", "unary_pow_bw"], [20, 0, 1, "", "unary_remainder_bw"], [20, 0, 1, "", "unary_sub_bw"], [20, 0, 1, "", "unpad"], [20, 0, 1, "", "untilize"], [20, 0, 1, "", "untilize_with_unpadding"], [20, 0, 1, "", "var_hw"], [20, 0, 1, "", "where"], [20, 0, 1, "", "where_bw"], [20, 0, 1, "", "xlogy"], [20, 0, 1, "", "xlogy_bw"], [20, 0, 1, "", "zeros"], [20, 0, 1, "", "zeros_like"]], "tt_lib.tensor.MemoryConfig": [[19, 2, 1, "", "__init__"]], "tt_lib.tensor.Tensor": [[19, 2, 1, "", "__init__"], [19, 2, 1, "", "buffer"], [20, 0, 1, "", "cpu"], [19, 2, 1, "", "device"], [19, 2, 1, "", "get_dtype"], [19, 2, 1, "", "get_layout"], [19, 2, 1, "", "get_legacy_shape"], [19, 2, 1, "", "pad"], [19, 2, 1, "", "pad_to_tile"], [19, 2, 1, "", "storage_type"], [19, 2, 1, "", "to"], [19, 2, 1, "", "unpad"], [19, 2, 1, "", "unpad_from_tile"]], "ttnn": [[25, 1, 1, "", "MaxPool2d"], [24, 1, 1, "", "Shape"], [26, 0, 1, "", "abs"], [27, 0, 1, "", "acos"], [28, 0, 1, "", "acosh"], [29, 0, 1, "", "add"], [30, 0, 1, "", "addcdiv"], [31, 0, 1, "", "addcmul"], [32, 0, 1, "", "arange"], [33, 0, 1, "", "argmax"], [34, 0, 1, "", "as_tensor"], [35, 0, 1, "", "asin"], [36, 0, 1, "", "asinh"], [37, 0, 1, "", "atan"], [38, 0, 1, "", "atan2"], [39, 0, 1, "", "atanh"], [40, 0, 1, "", "cbrt"], [41, 0, 1, "", "celu"], [42, 0, 1, "", "clip"], [43, 0, 1, "", "clone"], [44, 0, 1, "", "close_device"], [45, 0, 1, "", "concat"], [46, 0, 1, "", "cos"], [47, 0, 1, "", "cosh"], [48, 0, 1, "", "create_sharded_memory_config"], [49, 0, 1, "", "deallocate"], [50, 0, 1, "", "deg2rad"], [51, 0, 1, "", "digamma"], [52, 0, 1, "", "dump_tensor"], [53, 0, 1, "", "elu"], [54, 0, 1, "", "embedding"], [55, 0, 1, "", "empty"], [56, 0, 1, "", "eq"], [57, 0, 1, "", "eqz"], [58, 0, 1, "", "erf"], [59, 0, 1, "", "erfc"], [60, 0, 1, "", "erfinv"], [61, 0, 1, "", "exp"], [62, 0, 1, "", "exp2"], [63, 0, 1, "", "expm1"], [64, 0, 1, "", "from_device"], [65, 0, 1, "", "from_torch"], [66, 0, 1, "", "full"], [67, 0, 1, "", "full_like"], [68, 0, 1, "", "ge"], [69, 0, 1, "", "geglu"], [70, 0, 1, "", "gelu"], [71, 0, 1, "", "gez"], [72, 0, 1, "", "global_avg_pool2d"], [73, 0, 1, "", "glu"], [74, 0, 1, "", "group_norm"], [75, 0, 1, "", "gt"], [76, 0, 1, "", "gtz"], [77, 0, 1, "", "hardshrink"], [78, 0, 1, "", "hardsigmoid"], [79, 0, 1, "", "hardswish"], [80, 0, 1, "", "hardtanh"], [81, 0, 1, "", "heaviside"], [82, 0, 1, "", "hypot"], [83, 0, 1, "", "i0"], [84, 0, 1, "", "isclose"], [85, 0, 1, "", "isfinite"], [86, 0, 1, "", "isinf"], [87, 0, 1, "", "isnan"], [88, 0, 1, "", "isneginf"], [89, 0, 1, "", "isposinf"], [92, 0, 1, "", "l1_loss"], [93, 0, 1, "", "layer_norm"], [94, 0, 1, "", "ldexp"], [95, 0, 1, "", "le"], [96, 0, 1, "", "leaky_relu"], [97, 0, 1, "", "lerp"], [98, 0, 1, "", "lez"], [99, 0, 1, "", "lgamma"], [100, 0, 1, "", "linear"], [101, 0, 1, "", "load_tensor"], [102, 0, 1, "", "log"], [103, 0, 1, "", "log10"], [104, 0, 1, "", "log1p"], [105, 0, 1, "", "log2"], [106, 0, 1, "", "log_sigmoid"], [107, 0, 1, "", "logaddexp"], [108, 0, 1, "", "logaddexp2"], [109, 0, 1, "", "logical_and"], [111, 0, 1, "", "logical_or"], [112, 0, 1, "", "logical_xor"], [113, 0, 1, "", "logit"], [114, 0, 1, "", "lt"], [115, 0, 1, "", "ltz"], [116, 0, 1, "", "mac"], [117, 0, 1, "", "manage_device"], [118, 0, 1, "", "matmul"], [119, 0, 1, "", "max"], [120, 0, 1, "", "maximum"], [121, 0, 1, "", "mean"], [122, 0, 1, "", "min"], [123, 0, 1, "", "minimum"], [124, 0, 1, "", "mish"], [127, 0, 1, "", "mse_loss"], [128, 0, 1, "", "multigammaln"], [129, 0, 1, "", "multiply"], [130, 0, 1, "", "ne"], [131, 0, 1, "", "neg"], [132, 0, 1, "", "nextafter"], [133, 0, 1, "", "nez"], [134, 0, 1, "", "ones"], [135, 0, 1, "", "ones_like"], [136, 0, 1, "", "open_device"], [137, 0, 1, "", "pad"], [138, 0, 1, "", "permute"], [139, 0, 1, "", "polygamma"], [140, 0, 1, "", "polyval"], [141, 0, 1, "", "pow"], [142, 0, 1, "", "prelu"], [143, 0, 1, "", "rad2deg"], [144, 0, 1, "", "reallocate"], [145, 0, 1, "", "reciprocal"], [146, 0, 1, "", "register_post_operation_hook"], [147, 0, 1, "", "register_pre_operation_hook"], [148, 0, 1, "", "reglu"], [149, 0, 1, "", "relu"], [150, 0, 1, "", "relu6"], [151, 0, 1, "", "repeat"], [152, 0, 1, "", "repeat_interleave"], [153, 0, 1, "", "reshape"], [154, 0, 1, "", "rms_norm"], [155, 0, 1, "", "rsqrt"], [156, 0, 1, "", "set_printoptions"], [157, 0, 1, "", "sigmoid"], [158, 0, 1, "", "sigmoid_accurate"], [159, 0, 1, "", "sign"], [160, 0, 1, "", "signbit"], [161, 0, 1, "", "silu"], [162, 0, 1, "", "sin"], [163, 0, 1, "", "sinh"], [164, 0, 1, "", "softmax"], [165, 0, 1, "", "softplus"], [166, 0, 1, "", "softshrink"], [167, 0, 1, "", "softsign"], [169, 0, 1, "", "sqrt"], [170, 0, 1, "", "square"], [171, 0, 1, "", "squared_difference"], [172, 0, 1, "", "std"], [173, 0, 1, "", "subtract"], [174, 0, 1, "", "sum"], [175, 0, 1, "", "swiglu"], [176, 0, 1, "", "swish"], [177, 0, 1, "", "synchronize_device"], [178, 0, 1, "", "tan"], [179, 0, 1, "", "tanh"], [180, 0, 1, "", "tanhshrink"], [181, 0, 1, "", "threshold"], [182, 0, 1, "", "to_device"], [183, 0, 1, "", "to_layout"], [184, 0, 1, "", "to_memory_config"], [185, 0, 1, "", "to_torch"], [192, 0, 1, "", "tril"], [193, 0, 1, "", "triu"], [194, 0, 1, "", "upsample"], [195, 0, 1, "", "var"], [196, 0, 1, "", "where"], [197, 0, 1, "", "xlogy"], [198, 0, 1, "", "zeros"], [199, 0, 1, "", "zeros_like"]], "ttnn.Shape": [[24, 3, 1, "", "rank"], [24, 2, 1, "", "with_tile_padding"]], "ttnn.kv_cache": [[90, 0, 1, "", "fill_cache_for_user_"], [91, 0, 1, "", "update_cache_for_token_"]], "ttnn.model_preprocessing": [[125, 0, 1, "", "preprocess_model"], [126, 0, 1, "", "preprocess_model_parameters"]], "ttnn.transformer": [[187, 0, 1, "", "attention_softmax"], [188, 0, 1, "", "attention_softmax_"], [189, 0, 1, "", "concatenate_heads"], [190, 0, 1, "", "rotary_embedding"], [191, 0, 1, "", "split_query_key_value_and_split_heads"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method", "3": "py:property"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"]}, "titleterms": {"tensor": [0, 1, 14, 17, 19, 20, 24, 26, 27, 29, 33, 35, 37, 46, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 74, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195, 206, 208, 209, 215], "add": [0, 13, 29, 206, 208], "oper": [0, 3, 4, 13, 14, 15, 20, 23, 202, 206, 208, 211, 212, 215], "creat": [0, 5, 208, 213], "host": [0, 20, 208], "storag": [0, 19, 24, 208], "borrow": [0, 208], "v": [0, 208], "own": [0, 208], "data": [0, 14, 24, 208], "type": [0, 20, 24, 208], "layout": [0, 1, 24, 208, 209], "devic": [0, 1, 2, 14, 17, 20, 208, 209, 210, 215], "open": [0, 208], "initi": [0, 1, 2, 208, 209, 210], "b": [0, 1, 208, 209], "random": [0, 1, 208, 209], "valu": [0, 1, 208, 209], "us": [0, 1, 2, 3, 17, 208, 209, 210, 211, 215], "torch": [0, 1, 2, 3, 5, 15, 201, 208, 209, 210, 211, 213, 215], "inspect": [0, 1, 208, 209], "output": [0, 1, 2, 20, 208, 209, 210], "ttnn": [0, 2, 3, 4, 5, 7, 12, 13, 15, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 204, 207, 208, 210, 211, 212, 213, 215], "convert": [0, 2, 15, 19, 208, 210, 215], "attribut": [0, 208], "close": [0, 1, 2, 208, 209, 210], "matrix": [1, 14, 20, 209], "multipl": [1, 14, 24, 209], "enabl": [1, 2, 209, 210, 215], "program": [1, 2, 20, 209, 210, 215], "cach": [1, 2, 14, 20, 209, 210, 215], "configur": [1, 2, 209, 210], "multipli": [1, 129, 209], "result": [1, 209], "more": [1, 15, 209], "perform": [1, 10, 209], "config": [1, 14, 24, 209], "multi": [2, 21, 203, 210], "head": [2, 21, 203, 210], "attent": [2, 21, 203, 210], "write": [2, 210], "activ": [2, 210], "weight": [2, 210], "run": [2, 5, 10, 11, 17, 210, 213, 215], "first": [2, 210], "iter": [2, 210], "subsequ": [2, 210], "optim": [2, 15, 21, 210], "version": [2, 5, 210, 213], "pre": [2, 6, 210, 214, 215], "process": [2, 210], "paramet": [2, 5, 210, 213], "model": [2, 3, 6, 7, 11, 14, 15, 21, 210, 211, 214], "check": [2, 210], "match": [2, 210], "origin": [2, 210], "implement": [2, 5, 13, 210, 213], "trace": [3, 5, 211, 213, 215], "modul": [3, 5, 211, 213], "function": [3, 20, 22, 211], "written": [3, 211], "profil": [4, 20, 23, 204, 212], "resnet": [5, 205, 213], "block": [5, 205, 213], "from": [5, 6, 17, 20, 21, 213, 214, 215], "torchvis": [5, 213], "preprocess": [5, 213], "get": [5, 11, 21, 213], "displai": [5, 6, 213, 214], "graph": [5, 6, 20, 201, 213, 214, 215], "pass": [5, 213], "constructor": [5, 213], "build": [6, 16, 21, 214], "pytorch": [6, 17, 19, 214], "base": [6, 214], "clone": [6, 43, 214], "librari": [6, 20, 214], "http": [6, 214], "github": [6, 214], "com": [6, 214], "facebookresearch": [6, 214], "dit": [6, 214], "git": [6, 214], "download": [6, 214], "xl": [6, 214], "2": [6, 15, 20, 21, 93, 190, 214, 215], "sampl": [6, 214], "train": [6, 214], "welcom": 7, "tt": [7, 17, 19, 20, 21], "nn": [7, 21], "document": 7, "resourc": 7, "indic": 7, "tabl": 7, "contribut": 8, "develop": 8, "support": [9, 215], "report": [9, 14, 23], "bug": 9, "featur": [9, 12], "propos": 9, "request": 9, "troubleshoot": 9, "debug": [9, 215], "tip": 9, "commun": 9, "prerequisit": [10, 11], "perf": [10, 23], "file": 10, "all": [10, 215], "start": [11, 21], "an": [11, 215], "exampl": [11, 15, 17, 19, 215], "next": 11, "step": [11, 15], "what": 12, "i": 12, "kei": 12, "ad": 13, "new": [13, 20, 22], "c": 13, "pybind": 13, "unit": 13, "test": 13, "sweep": 13, "api": [14, 19, 20, 24], "memori": [14, 24], "core": 14, "creation": [14, 20], "pointwis": 14, "unari": 14, "binari": 14, "ternari": [14, 20], "loss": [14, 20], "reduct": 14, "movement": 14, "normal": 14, "transform": [14, 187, 188, 189, 190, 191], "embed": [14, 54], "pool": 14, "vision": 14, "kv": 14, "convers": 14, "hook": [14, 215], "1": [15, 21, 29, 54, 56, 68, 75, 93, 94, 95, 107, 108, 109, 111, 114, 129, 130, 154, 171, 173, 187, 188, 190, 215], "rewrit": 15, "switch": 15, "3": [15, 21, 93, 215], "uplift": 16, "demo": [16, 21], "lib": [17, 20], "one": 17, "op": 17, "acceler": 17, "odd": 17, "size": 17, "last": 17, "dim": 17, "depend": 18, "overview": [19, 20], "memoryconfig": 19, "between": 19, "infrastructur": 20, "member": 20, "option": 20, "input": [20, 26, 27, 29, 33, 35, 37, 46, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 74, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195], "fast": 20, "dispatch": 20, "log": [20, 102, 215], "through": 20, "tt_lib": [20, 215], "primari": 20, "enum": 20, "elementwis": 20, "relat": 20, "math": 20, "broadcast": 20, "reduc": 20, "fallback": [20, 215], "experiment": 20, "fuse": 20, "mini": 20, "complex": 20, "other": 20, "backward": 20, "instal": 21, "explor": 21, "our": 21, "tutori": [21, 200], "simpl": 21, "4": [21, 215], "where": [21, 196], "go": 21, "here": 21, "onboard": 22, "header": 23, "profile_thi": 23, "descript": 23, "shape": 24, "requir": 24, "width": 24, "shard": 24, "maxpool2d": 25, "ab": 26, "0": [26, 27, 29, 33, 35, 37, 46, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 68, 70, 71, 72, 74, 75, 76, 81, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 98, 102, 103, 105, 106, 107, 108, 109, 111, 114, 115, 119, 121, 122, 129, 130, 131, 133, 145, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 164, 165, 169, 170, 171, 172, 173, 174, 178, 179, 183, 184, 187, 188, 189, 190, 194, 195], "aco": 27, "acosh": 28, "addcdiv": 30, "addcmul": 31, "arang": 32, "argmax": 33, "as_tensor": 34, "asin": 35, "asinh": 36, "atan": 37, "atan2": 38, "atanh": 39, "cbrt": 40, "celu": 41, "clip": 42, "close_devic": 44, "concat": 45, "co": 46, "cosh": 47, "create_sharded_memory_config": 48, "dealloc": 49, "deg2rad": 50, "digamma": 51, "dump_tensor": 52, "elu": 53, "empti": 55, "eq": 56, "eqz": 57, "erf": 58, "erfc": 59, "erfinv": 60, "exp": 61, "exp2": 62, "expm1": 63, "from_devic": 64, "from_torch": 65, "full": 66, "full_lik": 67, "ge": 68, "geglu": 69, "gelu": 70, "gez": 71, "global_avg_pool2d": 72, "glu": 73, "group_norm": 74, "gt": 75, "gtz": 76, "hardshrink": 77, "hardsigmoid": 78, "hardswish": 79, "hardtanh": 80, "heavisid": 81, "hypot": 82, "i0": 83, "isclos": 84, "isfinit": 85, "isinf": 86, "isnan": 87, "isneginf": 88, "isposinf": 89, "kv_cach": [90, 91], "fill_cache_for_user_": 90, "update_cache_for_token_": 91, "l1_loss": 92, "layer_norm": 93, "ldexp": 94, "le": 95, "leaky_relu": 96, "lerp": 97, "lez": 98, "lgamma": 99, "linear": 100, "load_tensor": 101, "log10": 103, "log1p": 104, "log2": 105, "log_sigmoid": 106, "logaddexp": 107, "logaddexp2": 108, "logical_and": 109, "logical_not": 110, "logical_or": 111, "logical_xor": 112, "logit": 113, "lt": 114, "ltz": 115, "mac": 116, "manage_devic": 117, "matmul": [118, 202], "max": 119, "maximum": 120, "mean": 121, "min": 122, "minimum": 123, "mish": 124, "model_preprocess": [125, 126], "preprocess_model": 125, "preprocess_model_paramet": 126, "mse_loss": 127, "multigammaln": 128, "ne": 130, "neg": 131, "nextaft": 132, "nez": 133, "ones": 134, "ones_lik": 135, "open_devic": 136, "pad": 137, "permut": 138, "polygamma": 139, "polyv": 140, "pow": 141, "prelu": 142, "rad2deg": 143, "realloc": 144, "reciproc": 145, "register_post_operation_hook": 146, "register_pre_operation_hook": 147, "reglu": 148, "relu": 149, "relu6": 150, "repeat": 151, "repeat_interleav": 152, "reshap": 153, "rms_norm": 154, "rsqrt": 155, "set_printopt": 156, "sigmoid": 157, "sigmoid_accur": 158, "sign": 159, "signbit": 160, "silu": 161, "sin": 162, "sinh": 163, "softmax": 164, "softplu": 165, "softshrink": 166, "softsign": 167, "split": 168, "sqrt": 169, "squar": 170, "squared_differ": 171, "std": 172, "subtract": 173, "sum": 174, "swiglu": 175, "swish": 176, "synchronize_devic": 177, "tan": 178, "tanh": 179, "tanhshrink": 180, "threshold": 181, "to_devic": 182, "to_layout": 183, "to_memory_config": 184, "to_torch": 185, "topk": 186, "attention_softmax": 187, "attention_softmax_": 188, "concatenate_head": 189, "rotary_embed": 190, "split_query_key_value_and_split_head": 191, "tril": 192, "triu": 193, "upsampl": 194, "var": 195, "xlogi": 197, "zero": 198, "zeros_lik": 199, "dit_xl_2": 201, "With": 201, "basic": [205, 215], "tracer": 207, "__getitem__": 215, "slice": 215, "5": 215, "intermedi": 215, "6": 215, "7": 215, "8": 215, "9": 215, "python": 215, "10": 215, "chang": 215, "string": 215, "represent": 215, "11": 215, "visual": 215, "web": 215, "browser": 215, "12": 215, "regist": 215, "post": 215, "13": 215, "queri": 215, "14": 215, "disabl": 215, "placehold": 216, "titl": 216}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 58}, "alltitles": {"Contributing as a developer": [[8, "contributing-as-a-developer"]], "Support": [[9, "support"]], "Reporting bugs, feature proposals, or support requests": [[9, "reporting-bugs-feature-proposals-or-support-requests"]], "Troubleshooting and debugging tips": [[9, "troubleshooting-and-debugging-tips"]], "Community": [[9, "community"]], "Performance": [[10, "performance"]], "Prerequisites": [[10, "prerequisites"], [11, "prerequisites"]], "Running a perf file": [[10, "running-a-perf-file"]], "Running all the perf files": [[10, "running-all-the-perf-files"]], "Getting Started": [[11, "getting-started"], [21, "getting-started"]], "Running an example model": [[11, "running-an-example-model"]], "Next steps": [[11, "next-steps"]], "What is ttnn?": [[12, "what-is-ttnn"]], "Key features of ttnn": [[12, "key-features-of-ttnn"]], "Adding New ttnn Operation": [[13, "adding-new-ttnn-operation"]], "C++ Implementation": [[13, "c-implementation"]], "Add pybindings": [[13, "add-pybindings"]], "Adding a unit test": [[13, "adding-a-unit-test"]], "Adding a sweep test": [[13, "adding-a-sweep-test"]], "APIs": [[14, "apis"], [24, "apis"]], "Device": [[14, "device"]], "Memory Config": [[14, "memory-config"], [24, "memory-config"]], "Operations": [[14, "operations"]], "Core": [[14, "core"]], "Tensor Creation": [[14, "tensor-creation"]], "Matrix Multiplication": [[14, "matrix-multiplication"], [209, "Matrix-Multiplication"], [1, "Matrix-Multiplication"]], "Pointwise Unary": [[14, "pointwise-unary"]], "Pointwise Binary": [[14, "pointwise-binary"]], "Pointwise Ternary": [[14, "pointwise-ternary"]], "Losses": [[14, "losses"]], "Reduction": [[14, "reduction"]], "Data Movement": [[14, "data-movement"]], "Normalization": [[14, "normalization"]], "Transformer": [[14, "transformer"]], "Embedding": [[14, "embedding"]], "Pooling": [[14, "pooling"]], "Vision": [[14, "vision"]], "KV Cache": [[14, "kv-cache"]], "Model Conversion": [[14, "model-conversion"]], "Reports": [[14, "reports"]], "Operation Hooks": [[14, "operation-hooks"]], "Converting torch Model to ttnn": [[15, "converting-torch-model-to-ttnn"]], "Step 1 - Rewriting the Model": [[15, "step-1-rewriting-the-model"]], "Step 2 - Switching to ttnn Operations": [[15, "step-2-switching-to-ttnn-operations"]], "Step 3 - Optimizing the Model": [[15, "step-3-optimizing-the-model"]], "More examples": [[15, "more-examples"]], "Building and Uplifting Demos": [[16, "building-and-uplifting-demos"]], "Examples of Tensor and TT-LIB Use": [[17, "examples-of-tensor-and-tt-lib-use"]], "Run one OP from TT-LIB on TT Accelerator device": [[17, "run-one-op-from-tt-lib-on-tt-accelerator-device"]], "Run TT-LIB and PyTorch OPs": [[17, "run-tt-lib-and-pytorch-ops"]], "Tensors with odd size of last dim": [[17, "tensors-with-odd-size-of-last-dim"]], "Dependencies": [[18, "dependencies"]], "Tensor": [[19, "tensor"], [24, "tensor"]], "Overview": [[19, "overview"], [20, "overview"]], "Tensor Storage": [[19, "tensor-storage"]], "Tensor API": [[19, "tensor-api"]], "MemoryConfig": [[19, "memoryconfig"]], "Examples of converting between PyTorch Tensor and TT Tensor": [[19, "examples-of-converting-between-pytorch-tensor-and-tt-tensor"]], "Converting a PyTorch Tensor to a TT Tensor": [[19, "converting-a-pytorch-tensor-to-a-tt-tensor"]], "Converting a TT Tensor to a PyTorch Tensor": [[19, "converting-a-tt-tensor-to-a-pytorch-tensor"]], "1. Install and Build": [[21, "install-and-build"]], "2. Explore our model demos": [[21, "explore-our-model-demos"]], "3. TT-NN Tutorial: Multi-Head Attention (Simple)": [[21, "tt-nn-tutorial-multi-head-attention-simple"]], "4. TT-NN Tutorial: Multi-Head Attention (Optimized)": [[21, "tt-nn-tutorial-multi-head-attention-optimized"]], "Where to go from here": [[21, "where-to-go-from-here"]], "Onboarding New Functionality": [[22, "onboarding-new-functionality"]], "Profiling ttnn Operations": [[23, "profiling-ttnn-operations"]], "Perf Report Headers": [[23, "perf-report-headers"]], "profile_this description": [[23, "profile-this-description"]], "Shape": [[24, "shape"]], "Layout": [[24, "layout"], [208, "Layout"], [0, "Layout"]], "Data Type": [[24, "data-type"], [208, "Data-Type"], [0, "Data-Type"]], "Required Width Multiples for Data Types": [[24, "id5"]], "Storage": [[24, "storage"]], "Tensor Sharding": [[24, "tensor-sharding"]], "ttnn.MaxPool2d": [[25, "ttnn-maxpool2d"]], "ttnn.abs": [[26, "ttnn-abs"]], "Input Tensor 0": [[26, "id2"], [27, "id2"], [29, "id2"], [33, "id2"], [35, "id2"], [37, "id2"], [46, "id2"], [53, "id2"], [54, "id2"], [56, "id2"], [57, "id2"], [58, "id2"], [59, "id2"], [60, "id2"], [61, "id2"], [62, "id2"], [63, "id2"], [68, "id2"], [70, "id2"], [71, "id2"], [72, "id2"], [74, "id2"], [75, "id2"], [76, "id2"], [81, "id2"], [83, "id2"], [85, "id2"], [86, "id2"], [87, "id2"], [88, "id2"], [89, "id2"], [93, "id2"], [94, "id2"], [95, "id2"], [96, "id2"], [98, "id2"], [102, "id2"], [103, "id2"], [105, "id2"], [106, "id2"], [107, "id2"], [108, "id2"], [109, "id2"], [111, "id2"], [114, "id2"], [115, "id2"], [119, "id2"], [121, "id2"], [122, "id2"], [129, "id2"], [130, "id2"], [131, "id2"], [133, "id2"], [145, "id2"], [149, "id2"], [150, "id2"], [151, "id2"], [152, "id2"], [154, "id2"], [155, "id2"], [157, "id2"], [159, "id2"], [160, "id2"], [161, "id2"], [162, "id2"], [164, "id2"], [165, "id2"], [169, "id2"], [170, "id2"], [171, "id2"], [172, "id2"], [173, "id2"], [174, "id2"], [178, "id2"], [179, "id2"], [183, "id2"], [184, "id2"], [187, "id2"], [188, "id2"], [189, "id2"], [190, "id2"], [194, "id2"], [195, "id2"]], "ttnn.acos": [[27, "ttnn-acos"]], "ttnn.acosh": [[28, "ttnn-acosh"]], "ttnn.add": [[29, "ttnn-add"]], "Input Tensor 1": [[29, "id3"], [54, "id3"], [56, "id3"], [68, "id3"], [75, "id3"], [93, "id3"], [94, "id3"], [95, "id3"], [107, "id3"], [108, "id3"], [109, "id3"], [111, "id3"], [114, "id3"], [129, "id3"], [130, "id3"], [154, "id3"], [171, "id3"], [173, "id3"], [187, "id3"], [188, "id3"], [190, "id3"]], "ttnn.addcdiv": [[30, "ttnn-addcdiv"]], "ttnn.addcmul": [[31, "ttnn-addcmul"]], "ttnn.arange": [[32, "ttnn-arange"]], "ttnn.argmax": [[33, "ttnn-argmax"]], "ttnn.as_tensor": [[34, "ttnn-as-tensor"]], "ttnn.asin": [[35, "ttnn-asin"]], "ttnn.asinh": [[36, "ttnn-asinh"]], "ttnn.atan": [[37, "ttnn-atan"]], "ttnn.atan2": [[38, "ttnn-atan2"]], "ttnn.atanh": [[39, "ttnn-atanh"]], "ttnn.cbrt": [[40, "ttnn-cbrt"]], "ttnn.celu": [[41, "ttnn-celu"]], "ttnn.clip": [[42, "ttnn-clip"]], "ttnn.clone": [[43, "ttnn-clone"]], "ttnn.close_device": [[44, "ttnn-close-device"]], "ttnn.concat": [[45, "ttnn-concat"]], "ttnn.cos": [[46, "ttnn-cos"]], "ttnn.cosh": [[47, "ttnn-cosh"]], "ttnn.create_sharded_memory_config": [[48, "ttnn-create-sharded-memory-config"]], "ttnn.deallocate": [[49, "ttnn-deallocate"]], "ttnn.deg2rad": [[50, "ttnn-deg2rad"]], "ttnn.digamma": [[51, "ttnn-digamma"]], "ttnn.dump_tensor": [[52, "ttnn-dump-tensor"]], "ttnn.elu": [[53, "ttnn-elu"]], "ttnn.embedding": [[54, "ttnn-embedding"]], "ttnn.empty": [[55, "ttnn-empty"]], "ttnn.eq": [[56, "ttnn-eq"]], "ttnn.eqz": [[57, "ttnn-eqz"]], "ttnn.erf": [[58, "ttnn-erf"]], "ttnn.erfc": [[59, "ttnn-erfc"]], "ttnn.erfinv": [[60, "ttnn-erfinv"]], "ttnn.exp": [[61, "ttnn-exp"]], "ttnn.exp2": [[62, "ttnn-exp2"]], "ttnn.expm1": [[63, "ttnn-expm1"]], "ttnn.from_device": [[64, "ttnn-from-device"]], "ttnn.from_torch": [[65, "ttnn-from-torch"]], "ttnn.full": [[66, "ttnn-full"]], "ttnn.full_like": [[67, "ttnn-full-like"]], "ttnn.ge": [[68, "ttnn-ge"]], "ttnn.geglu": [[69, "ttnn-geglu"]], "ttnn.gelu": [[70, "ttnn-gelu"]], "ttnn.gez": [[71, "ttnn-gez"]], "ttnn.global_avg_pool2d": [[72, "ttnn-global-avg-pool2d"]], "ttnn.glu": [[73, "ttnn-glu"]], "ttnn.group_norm": [[74, "ttnn-group-norm"]], "ttnn.gt": [[75, "ttnn-gt"]], "ttnn.gtz": [[76, "ttnn-gtz"]], "ttnn.hardshrink": [[77, "ttnn-hardshrink"]], "ttnn.hardsigmoid": [[78, "ttnn-hardsigmoid"]], "ttnn.hardswish": [[79, "ttnn-hardswish"]], "ttnn.hardtanh": [[80, "ttnn-hardtanh"]], "ttnn.heaviside": [[81, "ttnn-heaviside"]], "ttnn.hypot": [[82, "ttnn-hypot"]], "ttnn.i0": [[83, "ttnn-i0"]], "ttnn.isclose": [[84, "ttnn-isclose"]], "ttnn.isfinite": [[85, "ttnn-isfinite"]], "ttnn.isinf": [[86, "ttnn-isinf"]], "ttnn.isnan": [[87, "ttnn-isnan"]], "ttnn.isneginf": [[88, "ttnn-isneginf"]], "ttnn.isposinf": [[89, "ttnn-isposinf"]], "ttnn.kv_cache.fill_cache_for_user_": [[90, "ttnn-kv-cache-fill-cache-for-user"]], "ttnn.kv_cache.update_cache_for_token_": [[91, "ttnn-kv-cache-update-cache-for-token"]], "ttnn.l1_loss": [[92, "ttnn-l1-loss"]], "ttnn.layer_norm": [[93, "ttnn-layer-norm"]], "Input Tensor 2": [[93, "id4"], [190, "id4"]], "Input Tensor 3": [[93, "id5"]], "ttnn.ldexp": [[94, "ttnn-ldexp"]], "ttnn.le": [[95, "ttnn-le"]], "ttnn.leaky_relu": [[96, "ttnn-leaky-relu"]], "ttnn.lerp": [[97, "ttnn-lerp"]], "ttnn.lez": [[98, "ttnn-lez"]], "ttnn.lgamma": [[99, "ttnn-lgamma"]], "ttnn.linear": [[100, "ttnn-linear"]], "ttnn.load_tensor": [[101, "ttnn-load-tensor"]], "ttnn.log": [[102, "ttnn-log"]], "ttnn.log10": [[103, "ttnn-log10"]], "ttnn.log1p": [[104, "ttnn-log1p"]], "ttnn.log2": [[105, "ttnn-log2"]], "ttnn.log_sigmoid": [[106, "ttnn-log-sigmoid"]], "ttnn.logaddexp": [[107, "ttnn-logaddexp"]], "ttnn.logaddexp2": [[108, "ttnn-logaddexp2"]], "ttnn.logical_and": [[109, "ttnn-logical-and"]], "ttnn.logical_not": [[110, "ttnn-logical-not"]], "ttnn.logical_or": [[111, "ttnn-logical-or"]], "ttnn.logical_xor": [[112, "ttnn-logical-xor"]], "ttnn.logit": [[113, "ttnn-logit"]], "ttnn.lt": [[114, "ttnn-lt"]], "ttnn.ltz": [[115, "ttnn-ltz"]], "ttnn.mac": [[116, "ttnn-mac"]], "ttnn.manage_device": [[117, "ttnn-manage-device"]], "ttnn.matmul": [[118, "ttnn-matmul"]], "ttnn.max": [[119, "ttnn-max"]], "ttnn.maximum": [[120, "ttnn-maximum"]], "ttnn.mean": [[121, "ttnn-mean"]], "ttnn.min": [[122, "ttnn-min"]], "ttnn.minimum": [[123, "ttnn-minimum"]], "ttnn.mish": [[124, "ttnn-mish"]], "ttnn.model_preprocessing.preprocess_model": [[125, "ttnn-model-preprocessing-preprocess-model"]], "ttnn.model_preprocessing.preprocess_model_parameters": [[126, "ttnn-model-preprocessing-preprocess-model-parameters"]], "ttnn.mse_loss": [[127, "ttnn-mse-loss"]], "ttnn.multigammaln": [[128, "ttnn-multigammaln"]], "ttnn.multiply": [[129, "ttnn-multiply"]], "ttnn.ne": [[130, "ttnn-ne"]], "ttnn.neg": [[131, "ttnn-neg"]], "ttnn.nextafter": [[132, "ttnn-nextafter"]], "ttnn.nez": [[133, "ttnn-nez"]], "ttnn.ones": [[134, "ttnn-ones"]], "ttnn.ones_like": [[135, "ttnn-ones-like"]], "ttnn.open_device": [[136, "ttnn-open-device"]], "ttnn.pad": [[137, "ttnn-pad"]], "ttnn.permute": [[138, "ttnn-permute"]], "ttnn.polygamma": [[139, "ttnn-polygamma"]], "ttnn.polyval": [[140, "ttnn-polyval"]], "ttnn.pow": [[141, "ttnn-pow"]], "ttnn.prelu": [[142, "ttnn-prelu"]], "ttnn.rad2deg": [[143, "ttnn-rad2deg"]], "ttnn.reallocate": [[144, "ttnn-reallocate"]], "ttnn.reciprocal": [[145, "ttnn-reciprocal"]], "ttnn.register_post_operation_hook": [[146, "ttnn-register-post-operation-hook"]], "ttnn.register_pre_operation_hook": [[147, "ttnn-register-pre-operation-hook"]], "ttnn.reglu": [[148, "ttnn-reglu"]], "ttnn.relu": [[149, "ttnn-relu"]], "ttnn.relu6": [[150, "ttnn-relu6"]], "ttnn.repeat": [[151, "ttnn-repeat"]], "ttnn.repeat_interleave": [[152, "ttnn-repeat-interleave"]], "ttnn.reshape": [[153, "ttnn-reshape"]], "ttnn.rms_norm": [[154, "ttnn-rms-norm"]], "ttnn.rsqrt": [[155, "ttnn-rsqrt"]], "ttnn.set_printoptions": [[156, "ttnn-set-printoptions"]], "ttnn.sigmoid": [[157, "ttnn-sigmoid"]], "ttnn.sigmoid_accurate": [[158, "ttnn-sigmoid-accurate"]], "ttnn.sign": [[159, "ttnn-sign"]], "ttnn.signbit": [[160, "ttnn-signbit"]], "ttnn.silu": [[161, "ttnn-silu"]], "ttnn.sin": [[162, "ttnn-sin"]], "ttnn.sinh": [[163, "ttnn-sinh"]], "ttnn.softmax": [[164, "ttnn-softmax"]], "ttnn.softplus": [[165, "ttnn-softplus"]], "ttnn.softshrink": [[166, "ttnn-softshrink"]], "ttnn.softsign": [[167, "ttnn-softsign"]], "ttnn.sqrt": [[169, "ttnn-sqrt"]], "ttnn.square": [[170, "ttnn-square"]], "ttnn.squared_difference": [[171, "ttnn-squared-difference"]], "ttnn.std": [[172, "ttnn-std"]], "ttnn.subtract": [[173, "ttnn-subtract"]], "ttnn.sum": [[174, "ttnn-sum"]], "ttnn.swiglu": [[175, "ttnn-swiglu"]], "ttnn.swish": [[176, "ttnn-swish"]], "ttnn.synchronize_device": [[177, "ttnn-synchronize-device"]], "ttnn.tan": [[178, "ttnn-tan"]], "ttnn.tanh": [[179, "ttnn-tanh"]], "ttnn.tanhshrink": [[180, "ttnn-tanhshrink"]], "ttnn.threshold": [[181, "ttnn-threshold"]], "ttnn.to_device": [[182, "ttnn-to-device"]], "ttnn.to_layout": [[183, "ttnn-to-layout"]], "ttnn.to_memory_config": [[184, "ttnn-to-memory-config"]], "ttnn.to_torch": [[185, "ttnn-to-torch"]], "ttnn.transformer.attention_softmax": [[187, "ttnn-transformer-attention-softmax"]], "ttnn.transformer.attention_softmax_": [[188, "ttnn-transformer-attention-softmax"]], "ttnn.transformer.concatenate_heads": [[189, "ttnn-transformer-concatenate-heads"]], "ttnn.transformer.rotary_embedding": [[190, "ttnn-transformer-rotary-embedding"]], "ttnn.transformer.split_query_key_value_and_split_heads": [[191, "ttnn-transformer-split-query-key-value-and-split-heads"]], "ttnn.tril": [[192, "ttnn-tril"]], "ttnn.triu": [[193, "ttnn-triu"]], "ttnn.upsample": [[194, "ttnn-upsample"]], "ttnn.var": [[195, "ttnn-var"]], "ttnn.where": [[196, "ttnn-where"]], "ttnn.xlogy": [[197, "ttnn-xlogy"]], "ttnn.zeros": [[198, "ttnn-zeros"]], "ttnn.zeros_like": [[199, "ttnn-zeros-like"]], "Tutorials": [[200, "id1"]], "Graphing Torch DiT_XL_2 With TTNN": [[201, "graphing-torch-dit-xl-2-with-ttnn"]], "Matmul Operation": [[202, "matmul-operation"]], "Multi-Head Attention": [[203, "multi-head-attention"], [210, "Multi-Head-Attention"], [2, "Multi-Head-Attention"]], "ttnn Profiling": [[204, "ttnn-profiling"]], "Resnet Basic Block": [[205, "resnet-basic-block"]], "Tensor and Add Operation": [[206, "tensor-and-add-operation"], [208, "Tensor-and-Add-Operation"], [0, "Tensor-and-Add-Operation"]], "ttnn Tracer": [[207, "ttnn-tracer"]], "Creating a tensor": [[208, "Creating-a-tensor"], [0, "Creating-a-tensor"]], "Host Storage: Borrowed vs Owned": [[208, "Host-Storage:-Borrowed-vs-Owned"], [0, "Host-Storage:-Borrowed-vs-Owned"]], "Device storage": [[208, "Device-storage"], [0, "Device-storage"]], "Open the device": [[208, "Open-the-device"], [0, "Open-the-device"]], "Initialize tensors a and b with random values using torch": [[208, "Initialize-tensors-a-and-b-with-random-values-using-torch"], [209, "Initialize-tensors-a-and-b-with-random-values-using-torch"], [0, "Initialize-tensors-a-and-b-with-random-values-using-torch"], [1, "Initialize-tensors-a-and-b-with-random-values-using-torch"]], "Add tensor a and b": [[208, "Add-tensor-a-and-b"], [0, "Add-tensor-a-and-b"]], "Inspect the output tensor of the add in ttnn": [[208, "Inspect-the-output-tensor-of-the-add-in-ttnn"], [0, "Inspect-the-output-tensor-of-the-add-in-ttnn"]], "Convert to torch and inspect the attributes of the torch tensor": [[208, "Convert-to-torch-and-inspect-the-attributes-of-the-torch-tensor"], [0, "Convert-to-torch-and-inspect-the-attributes-of-the-torch-tensor"]], "Close the device": [[208, "Close-the-device"], [209, "Close-the-device"], [210, "Close-the-device"], [0, "Close-the-device"], [1, "Close-the-device"], [2, "Close-the-device"]], "Enable program cache": [[209, "Enable-program-cache"], [210, "Enable-program-cache"], [1, "Enable-program-cache"], [2, "Enable-program-cache"]], "Configuration": [[209, "Configuration"], [210, "Configuration"], [1, "Configuration"], [2, "Configuration"]], "Matrix multiply tensor a and b": [[209, "Matrix-multiply-tensor-a-and-b"], [1, "Matrix-multiply-tensor-a-and-b"]], "Inspect the layout of matrix multiplication output": [[209, "Inspect-the-layout-of-matrix-multiplication-output"], [1, "Inspect-the-layout-of-matrix-multiplication-output"]], "Inspect the result of the matrix multiplication": [[209, "Inspect-the-result-of-the-matrix-multiplication"], [1, "Inspect-the-result-of-the-matrix-multiplication"]], "Matrix multiply tensor a and b by using more performant config": [[209, "Matrix-multiply-tensor-a-and-b-by-using-more-performant-config"], [1, "Matrix-multiply-tensor-a-and-b-by-using-more-performant-config"]], "Write Multi-Head Attention using ttnn": [[210, "Write-Multi-Head-Attention-using-ttnn"], [2, "Write-Multi-Head-Attention-using-ttnn"]], "Initialize activations and weights using torch": [[210, "Initialize-activations-and-weights-using-torch"], [2, "Initialize-activations-and-weights-using-torch"]], "Convert activations and weights to ttnn": [[210, "Convert-activations-and-weights-to-ttnn"], [2, "Convert-activations-and-weights-to-ttnn"]], "Run the first iteration of Multi-Head Attention": [[210, "Run-the-first-iteration-of-Multi-Head-Attention"], [2, "Run-the-first-iteration-of-Multi-Head-Attention"]], "Run a subsequent iteration of Multi-Head Attention": [[210, "Run-a-subsequent-iteration-of-Multi-Head-Attention"], [2, "Run-a-subsequent-iteration-of-Multi-Head-Attention"]], "Write optimized version of Multi-Head Attention": [[210, "Write-optimized-version-of-Multi-Head-Attention"], [2, "Write-optimized-version-of-Multi-Head-Attention"]], "Pre-process the parameters of the optimized model": [[210, "Pre-process-the-parameters-of-the-optimized-model"], [2, "Pre-process-the-parameters-of-the-optimized-model"]], "Run the first iteration of the optimized Multi-Head Attention": [[210, "Run-the-first-iteration-of-the-optimized-Multi-Head-Attention"], [2, "Run-the-first-iteration-of-the-optimized-Multi-Head-Attention"]], "Run a subsequent iteration of the optimized Multi-Head Attention": [[210, "Run-a-subsequent-iteration-of-the-optimized-Multi-Head-Attention"], [2, "Run-a-subsequent-iteration-of-the-optimized-Multi-Head-Attention"]], "Check that the output of the optimized version matches the output of the original implementation": [[210, "Check-that-the-output-of-the-optimized-version-matches-the-output-of-the-original-implementation"], [2, "Check-that-the-output-of-the-optimized-version-matches-the-output-of-the-original-implementation"]], "Tracing ttnn operations and torch modules/functions": [[211, "Tracing-ttnn-operations-and-torch-modules/functions"], [3, "Tracing-ttnn-operations-and-torch-modules/functions"]], "Trace torch functions": [[211, "Trace-torch-functions"], [3, "Trace-torch-functions"]], "Trace torch functions and ttnn operations": [[211, "Trace-torch-functions-and-ttnn-operations"], [3, "Trace-torch-functions-and-ttnn-operations"]], "Trace torch functions, torch modules and ttnn operations": [[211, "Trace-torch-functions,-torch-modules-and-ttnn-operations"], [3, "Trace-torch-functions,-torch-modules-and-ttnn-operations"]], "Trace models written using ttnn": [[211, "Trace-models-written-using-ttnn"], [3, "Trace-models-written-using-ttnn"]], "Profiling ttnn operations": [[212, "Profiling-ttnn-operations"], [4, "Profiling-ttnn-operations"]], "Resnet Block": [[213, "Resnet-Block"], [5, "Resnet-Block"]], "Torch Module (from torchvision)": [[213, "Torch-Module-(from-torchvision)"], [5, "Torch-Module-(from-torchvision)"]], "Create torch module and preprocess it to get ttnn parameters": [[213, "Create-torch-module-and-preprocess-it-to-get-ttnn-parameters"], [5, "Create-torch-module-and-preprocess-it-to-get-ttnn-parameters"]], "Display the parameters of the module": [[213, "Display-the-parameters-of-the-module"], [5, "Display-the-parameters-of-the-module"]], "Display the traced torch graph": [[213, "Display-the-traced-torch-graph"], [5, "Display-the-traced-torch-graph"]], "Implement ttnn version of the module. Pass in the parameters into the constructor.": [[213, "Implement-ttnn-version-of-the-module.-Pass-in-the-parameters-into-the-constructor."], [5, "Implement-ttnn-version-of-the-module.-Pass-in-the-parameters-into-the-constructor."]], "Run ttnn module and display the traced graph": [[213, "Run-ttnn-module-and-display-the-traced-graph"], [5, "Run-ttnn-module-and-display-the-traced-graph"]], "Build a graph of a pytorch based model": [[214, "Build-a-graph-of-a-pytorch-based-model"], [6, "Build-a-graph-of-a-pytorch-based-model"]], "Clone the library from https://github.com/facebookresearch/DiT.git": [[214, "Clone-the-library-from-https://github.com/facebookresearch/DiT.git"], [6, "Clone-the-library-from-https://github.com/facebookresearch/DiT.git"]], "Download DiT-XL/2 Models": [[214, "Download-DiT-XL/2-Models"], [6, "Download-DiT-XL/2-Models"]], "Sample from Pre-trained DiT Models and build the graph": [[214, "Sample-from-Pre-trained-DiT-Models-and-build-the-graph"], [6, "Sample-from-Pre-trained-DiT-Models-and-build-the-graph"]], "Display the graph": [[214, "Display-the-graph"], [6, "Display-the-graph"]], "Placeholder title": [[216, "placeholder-title"]], "Welcome to TT-NN documentation!": [[7, "welcome-to-tt-nn-documentation"]], "TTNN": [[7, null]], "Models": [[7, null]], "Resources": [[7, null]], "Indices and tables": [[7, "indices-and-tables"]], "TT-LIB": [[20, "tt-lib"]], "Operation Infrastructure": [[20, "operation-infrastructure"]], "New Device Operation": [[20, "new-device-operation"]], "New Device Operation with a member": [[20, "new-device-operation-with-a-member"]], "New Device Operation with Optional Input Tensors": [[20, "new-device-operation-with-optional-input-tensors"]], "New Device Operation with Optional Output Tensors": [[20, "new-device-operation-with-optional-output-tensors"]], "New Host Operation": [[20, "new-host-operation"]], "Profiler": [[20, "profiler"]], "Fast Dispatch": [[20, "fast-dispatch"]], "Program Caching": [[20, "program-caching"]], "Logs": [[20, "logs"]], "TT-LIB API through tt_lib": [[20, "tt-lib-api-through-tt-lib"]], "Primary Operations": [[20, "primary-operations"]], "Enums": [[20, "enums"]], "Tensor elementwise operations": [[20, "tensor-elementwise-operations"]], "Tensor relational operations": [[20, "tensor-relational-operations"]], "Tensor ternary operations": [[20, "tensor-ternary-operations"]], "Tensor matrix math operations": [[20, "tensor-matrix-math-operations"]], "Tensor creation operations": [[20, "tensor-creation-operations"]], "Broadcast and Reduce": [[20, "broadcast-and-reduce"]], "Fallback Operations": [[20, "fallback-operations"]], "Experimental Operations": [[20, "experimental-operations"]], "Fused Operations from tt_lib Mini-Graph Library": [[20, "fused-operations-from-tt-lib-mini-graph-library"]], "Complex Operations": [[20, "complex-operations"]], "Complex Operations (Type 2)": [[20, "complex-operations-type-2"]], "Other Operations": [[20, "other-operations"]], "Backward Operations": [[20, "backward-operations"]], "Loss Functions": [[20, "loss-functions"]], "ttnn.split": [[168, "ttnn-split"]], "ttnn.topk": [[186, "ttnn-topk"]], "Using ttnn": [[215, "using-ttnn"]], "Basic Examples": [[215, "basic-examples"]], "1. Converting from and to torch tensor": [[215, "converting-from-and-to-torch-tensor"]], "2. Running an operation on the device": [[215, "running-an-operation-on-the-device"]], "3. Using __getitem__ to slice the tensor": [[215, "using-getitem-to-slice-the-tensor"]], "4. Enabling program cache": [[215, "enabling-program-cache"]], "5. Debugging intermediate tensors": [[215, "debugging-intermediate-tensors"]], "6. Tracing the graph of operations": [[215, "tracing-the-graph-of-operations"]], "7. Using tt_lib operation in ttnn": [[215, "using-tt-lib-operation-in-ttnn"]], "8. Enabling Logging": [[215, "enabling-logging"]], "9. Supported Python Operators": [[215, "supported-python-operators"]], "10. Changing the string representation of the tensor": [[215, "changing-the-string-representation-of-the-tensor"]], "11. Visualize using Web Browser": [[215, "visualize-using-web-browser"]], "12. Register pre- and/or post-operation hooks": [[215, "register-pre-and-or-post-operation-hooks"]], "13. Query all operations": [[215, "query-all-operations"]], "14. Disable Fallbacks": [[215, "disable-fallbacks"]]}, "indexentries": {"memoryconfig (class in tt_lib.tensor)": [[19, "tt_lib.tensor.MemoryConfig"]], "tensor (class in tt_lib.tensor)": [[19, "tt_lib.tensor.Tensor"]], "__init__() (tt_lib.tensor.memoryconfig method)": [[19, "tt_lib.tensor.MemoryConfig.__init__"]], "__init__() (tt_lib.tensor.tensor method)": [[19, "tt_lib.tensor.Tensor.__init__"]], "buffer() (tt_lib.tensor.tensor method)": [[19, "tt_lib.tensor.Tensor.buffer"]], "device() (tt_lib.tensor.tensor method)": [[19, "tt_lib.tensor.Tensor.device"]], "get_dtype() (tt_lib.tensor.tensor method)": [[19, "tt_lib.tensor.Tensor.get_dtype"]], "get_layout() (tt_lib.tensor.tensor method)": [[19, "tt_lib.tensor.Tensor.get_layout"]], "get_legacy_shape() (tt_lib.tensor.tensor method)": [[19, "tt_lib.tensor.Tensor.get_legacy_shape"]], "pad() (tt_lib.tensor.tensor method)": [[19, "tt_lib.tensor.Tensor.pad"]], "pad_to_tile() (tt_lib.tensor.tensor method)": [[19, "tt_lib.tensor.Tensor.pad_to_tile"]], "storage_type() (tt_lib.tensor.tensor method)": [[19, "tt_lib.tensor.Tensor.storage_type"]], "to() (tt_lib.tensor.tensor method)": [[19, "tt_lib.tensor.Tensor.to"]], "unpad() (tt_lib.tensor.tensor method)": [[19, "tt_lib.tensor.Tensor.unpad"]], "unpad_from_tile() (tt_lib.tensor.tensor method)": [[19, "tt_lib.tensor.Tensor.unpad_from_tile"]], "adaptiveavgpool2d (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.AdaptiveAvgPool2d"]], "addandnorm() (in module tt_lib.fused_ops.add_and_norm)": [[20, "tt_lib.fused_ops.add_and_norm.AddAndNorm"]], "batchnorm2d (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.BatchNorm2d"]], "bcastopdim (class in tt_lib.tensor)": [[20, "tt_lib.tensor.BcastOpDim"]], "bcastopmath (class in tt_lib.tensor)": [[20, "tt_lib.tensor.BcastOpMath"]], "conv2d (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.Conv2d"]], "groupnorm (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.GroupNorm"]], "layernorm (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.LayerNorm"]], "layernorm() (in module tt_lib.fused_ops.layernorm)": [[20, "tt_lib.fused_ops.layernorm.Layernorm"]], "linear() (in module tt_lib.fused_ops.linear)": [[20, "tt_lib.fused_ops.linear.Linear"]], "maxpool2d (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.MaxPool2d"]], "reduceopdim (class in tt_lib.tensor)": [[20, "tt_lib.tensor.ReduceOpDim"]], "reduceopmath (class in tt_lib.tensor)": [[20, "tt_lib.tensor.ReduceOpMath"]], "synchronize() (in module tt_lib.device)": [[20, "tt_lib.device.Synchronize"]], "abs() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.abs"]], "abs_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.abs_bw"]], "acos() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.acos"]], "acos_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.acos_bw"]], "acosh() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.acosh"]], "acosh_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.acosh_bw"]], "add1() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.add1"]], "add_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.add_bw"]], "add_layernorm() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.add_layernorm"]], "add_layernorm() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.add_layernorm"]], "add_unary() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.add_unary"]], "addalpha() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.addalpha"]], "addalpha_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.addalpha_bw"]], "addcdiv() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.addcdiv"]], "addcdiv_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.addcdiv_bw"]], "addcmul() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.addcmul"]], "addcmul_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.addcmul_bw"]], "angle_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.angle_bw"]], "arange() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.arange"]], "argmax() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.argmax"]], "argmin() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.argmin"]], "asin() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.asin"]], "asin_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.asin_bw"]], "asinh() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.asinh"]], "asinh_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.asinh_bw"]], "assign() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.assign"]], "atan() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.atan"]], "atan2() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.atan2"]], "atan2_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.atan2_bw"]], "atan_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.atan_bw"]], "atanh() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.atanh"]], "atanh_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.atanh_bw"]], "bcast() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.bcast"]], "bias_gelu_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.bias_gelu_bw"]], "bias_gelu_unary() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.bias_gelu_unary"]], "bias_gelu_unary_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.bias_gelu_unary_bw"]], "binary_assign_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.binary_assign_bw"]], "binary_bitwise_and (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.binary_bitwise_and"]], "binary_bitwise_left_shift (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.binary_bitwise_left_shift"]], "binary_bitwise_or (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.binary_bitwise_or"]], "binary_bitwise_right_shift (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.binary_bitwise_right_shift"]], "binary_bitwise_xor (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.binary_bitwise_xor"]], "binary_eq_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.binary_eq_bw"]], "binary_fmod (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.binary_fmod"]], "binary_ge_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.binary_ge_bw"]], "binary_gt_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.binary_gt_bw"]], "binary_le_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.binary_le_bw"]], "binary_lt_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.binary_lt_bw"]], "binary_ne_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.binary_ne_bw"]], "bitwise_not (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.bitwise_not"]], "bmm() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.bmm"]], "cbrt() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.cbrt"]], "ceil (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.ceil"]], "ceil_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.ceil_bw"]], "celu() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.celu"]], "celu_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.celu_bw"]], "chunk() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.chunk"]], "clamp_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.clamp_bw"]], "clamp_max_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.clamp_max_bw"]], "clamp_min_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.clamp_min_bw"]], "clip() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.clip"]], "clone() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.clone"]], "complex_abs() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.complex_abs"]], "complex_abs_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.complex_abs_bw"]], "complex_add() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.complex_add"]], "complex_add_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.complex_add_bw"]], "complex_div() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.complex_div"]], "complex_div_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.complex_div_bw"]], "complex_mul() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.complex_mul"]], "complex_mul_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.complex_mul_bw"]], "complex_recip() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.complex_recip"]], "complex_recip_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.complex_recip_bw"]], "complex_sub() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.complex_sub"]], "complex_sub_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.complex_sub_bw"]], "concat() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.concat"]], "concat() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.concat"]], "concat_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.concat_bw"]], "conj() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.conj"]], "conj_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.conj_bw"]], "conv() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.conv"]], "conv2d() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.conv2d"]], "convert_conv_weight_tensor_to_tiled_layout() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.convert_conv_weight_tensor_to_tiled_layout"]], "copy() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.copy"]], "cos() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.cos"]], "cos_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.cos_bw"]], "cosh() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.cosh"]], "cosh_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.cosh_bw"]], "cpu() (in module tt_lib.tensor.tensor)": [[20, "tt_lib.tensor.Tensor.cpu"]], "deg2rad() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.deg2rad"]], "deg2rad_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.deg2rad_bw"]], "digamma() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.digamma"]], "digamma_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.digamma_bw"]], "div() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.div"]], "div_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.div_bw"]], "div_no_nan() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.div_no_nan"]], "div_unary() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.div_unary"]], "elu() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.elu"]], "elu_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.elu_bw"]], "embedding_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.embedding_bw"]], "embeddings() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.embeddings"]], "empty() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.empty"]], "eqz() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.eqz"]], "erf() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.erf"]], "erf_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.erf_bw"]], "erfc() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.erfc"]], "erfc_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.erfc_bw"]], "erfinv() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.erfinv"]], "erfinv_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.erfinv_bw"]], "exp() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.exp"]], "exp2() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.exp2"]], "exp2_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.exp2_bw"]], "exp_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.exp_bw"]], "expm1() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.expm1"]], "expm1_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.expm1_bw"]], "fill_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.fill_bw"]], "fill_ones_rm() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.fill_ones_rm"]], "fill_rm() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.fill_rm"]], "fill_zero_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.fill_zero_bw"]], "floor (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.floor"]], "floor() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.floor"]], "floor_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.floor_bw"]], "floor_div() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.floor_div"]], "frac_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.frac_bw"]], "full() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.full"]], "full() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.full"]], "full_like() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.full_like"]], "ge_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.ge_bw"]], "geglu() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.geglu"]], "gelu() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.gelu"]], "gelu_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.gelu_bw"]], "gez() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.gez"]], "global_max() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.global_max"]], "global_mean() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.global_mean"]], "global_min() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.global_min"]], "global_sum() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.global_sum"]], "glu() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.glu"]], "group_norm() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.group_norm"]], "groupnorm() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.groupnorm"]], "gt_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.gt_bw"]], "gtz() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.gtz"]], "hardshrink() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.hardshrink"]], "hardshrink_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.hardshrink_bw"]], "hardsigmoid() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.hardsigmoid"]], "hardsigmoid_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.hardsigmoid_bw"]], "hardswish() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.hardswish"]], "hardswish_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.hardswish_bw"]], "hardtanh() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.hardtanh"]], "hardtanh_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.hardtanh_bw"]], "heaviside() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.heaviside"]], "hypot() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.hypot"]], "hypot_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.hypot_bw"]], "i0() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.i0"]], "i0_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.i0_bw"]], "identity() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.identity"]], "imag() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.imag"]], "imag_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.imag_bw"]], "interpolate() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.interpolate"]], "isclose() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.isclose"]], "isfinite() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.isfinite"]], "isinf() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.isinf"]], "isnan() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.isnan"]], "isneginf() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.isneginf"]], "isposinf() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.isposinf"]], "lamb_optimizer() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.lamb_optimizer"]], "layer_norm() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.layer_norm"]], "layernorm() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.layernorm"]], "layernorm() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.layernorm"]], "ldexp_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.ldexp_bw"]], "le_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.le_bw"]], "leaky_relu() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.leaky_relu"]], "leaky_relu_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.leaky_relu_bw"]], "left_shift() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.left_shift"]], "lerp() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.lerp"]], "lerp_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.lerp_bw"]], "lez() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.lez"]], "lgamma() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.lgamma"]], "lgamma_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.lgamma_bw"]], "log() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.log"]], "log10() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.log10"]], "log10_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.log10_bw"]], "log1p() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.log1p"]], "log1p_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.log1p_bw"]], "log2() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.log2"]], "log2_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.log2_bw"]], "log_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.log_bw"]], "log_sigmoid() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.log_sigmoid"]], "log_sigmoid_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.log_sigmoid_bw"]], "logaddexp2_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.logaddexp2_bw"]], "logaddexp_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.logaddexp_bw"]], "logical_andi() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.logical_andi"]], "logical_not_unary() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.logical_not_unary"]], "logical_noti() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.logical_noti"]], "logical_ori() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.logical_ori"]], "logical_xor() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.logical_xor"]], "logical_xori() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.logical_xori"]], "logit() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.logit"]], "logit_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.logit_bw"]], "logiteps_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.logiteps_bw"]], "lt_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.lt_bw"]], "ltz() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.ltz"]], "mac() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.mac"]], "maeloss() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.maeloss"]], "matmul() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.matmul"]], "max_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.max_bw"]], "mean_hw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.mean_hw"]], "min_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.min_bw"]], "mish() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.mish"]], "moreh_groupnorm() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.moreh_groupnorm"]], "moreh_groupnorm_backward() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.moreh_groupnorm_backward"]], "moreh_logsoftmax() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.moreh_logsoftmax"]], "moreh_logsoftmax_backward() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.moreh_logsoftmax_backward"]], "moreh_mean() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.moreh_mean"]], "moreh_mean_backward() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.moreh_mean_backward"]], "moreh_norm() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.moreh_norm"]], "moreh_norm_backward() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.moreh_norm_backward"]], "moreh_softmax() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.moreh_softmax"]], "moreh_softmax_backward() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.moreh_softmax_backward"]], "moreh_softmin() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.moreh_softmin"]], "moreh_softmin_backward() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.moreh_softmin_backward"]], "mseloss() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.mseloss"]], "mul_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.mul_bw"]], "mul_unary() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.mul_unary"]], "multigammaln() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.multigammaln"]], "multigammaln_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.multigammaln_bw"]], "ne_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.ne_bw"]], "neg() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.neg"]], "neg_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.neg_bw"]], "nextafter() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.nextafter"]], "nez() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.nez"]], "normalize_global() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.normalize_global"]], "normalize_hw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.normalize_hw"]], "ones() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.ones"]], "ones_like() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.ones_like"]], "pad() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.pad"]], "pad() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.pad"]], "permute() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.permute"]], "polar() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.polar"]], "polar_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.polar_bw"]], "polygamma() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.polygamma"]], "polygamma_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.polygamma_bw"]], "polyval() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.polyval"]], "pow() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.pow"]], "prod() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.prod"]], "prod_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.prod_bw"]], "rad2deg() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.rad2deg"]], "rad2deg_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.rad2deg_bw"]], "rdiv() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.rdiv"]], "rdiv_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.rdiv_bw"]], "real() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.real"]], "real_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.real_bw"]], "recip() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.recip"]], "reciprocal_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.reciprocal_bw"]], "reduce() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.reduce"]], "reglu() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.reglu"]], "relu() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.relu"]], "relu6() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.relu6"]], "relu6_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.relu6_bw"]], "relu_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.relu_bw"]], "relu_max() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.relu_max"]], "relu_min() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.relu_min"]], "repeat() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.repeat"]], "repeat() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.repeat"]], "repeat_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.repeat_bw"]], "repeat_interleave() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.repeat_interleave"]], "repeat_interleave() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.repeat_interleave"]], "reshape() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.reshape"]], "reshape() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.reshape"]], "right_shift() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.right_shift"]], "rmsnorm() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.rmsnorm"]], "round() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.round"]], "round_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.round_bw"]], "rpow() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.rpow"]], "rpow_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.rpow_bw"]], "rsqrt() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.rsqrt"]], "rsqrt_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.rsqrt_bw"]], "rsub() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.rsub"]], "rsub_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.rsub_bw"]], "scale_mask_softmax_in_place() (in module tt_lib.operations.primary.transformers)": [[20, "tt_lib.operations.primary.transformers.scale_mask_softmax_in_place"]], "selu_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.selu_bw"]], "sigmoid() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.sigmoid"]], "sigmoid_accurate() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.sigmoid_accurate"]], "sign() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.sign"]], "sign_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.sign_bw"]], "signbit() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.signbit"]], "silu() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.silu"]], "silu() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.silu"]], "silu_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.silu_bw"]], "sin() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.sin"]], "sin_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.sin_bw"]], "sinh() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.sinh"]], "sinh_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.sinh_bw"]], "softmax() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.softmax"]], "softmax() (in module tt_lib.fused_ops.softmax)": [[20, "tt_lib.fused_ops.softmax.softmax"]], "softmax_in_place() (in module tt_lib.operations.primary)": [[20, "tt_lib.operations.primary.softmax_in_place"]], "softplus() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.softplus"]], "softplus_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.softplus_bw"]], "softshrink() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.softshrink"]], "softshrink_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.softshrink_bw"]], "softsign() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.softsign"]], "softsign_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.softsign_bw"]], "split_last_dim_two_chunks_tiled() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.split_last_dim_two_chunks_tiled"]], "sqrt() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.sqrt"]], "sqrt_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.sqrt_bw"]], "square() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.square"]], "square_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.square_bw"]], "squared_difference_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.squared_difference_bw"]], "std_hw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.std_hw"]], "sub_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.sub_bw"]], "sub_unary() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.sub_unary"]], "subalpha() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.subalpha"]], "subalpha_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.subalpha_bw"]], "sum() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.sum"]], "swiglu() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.swiglu"]], "swish() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.swish"]], "tan() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.tan"]], "tan_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.tan_bw"]], "tanh() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.tanh"]], "tanh_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.tanh_bw"]], "tanhshrink() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.tanhshrink"]], "tanhshrink_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.tanhshrink_bw"]], "tensor_slice() (in module tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.tensor_slice"]], "threshold() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.threshold"]], "threshold_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.threshold_bw"]], "tiled_prod() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.tiled_prod"]], "tilize() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.tilize"]], "tilize_with_val_padding() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.tilize_with_val_padding"]], "tilize_with_zero_padding() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.tilize_with_zero_padding"]], "torch_argmax (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.torch_argmax"]], "torch_argmin (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.torch_argmin"]], "transpose() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.transpose"]], "tril() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.tril"]], "triu() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.triu"]], "trunc (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.trunc"]], "trunc() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.trunc"]], "trunc_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.trunc_bw"]], "typecast() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.typecast"]], "unary_add_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unary_add_bw"]], "unary_assign_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unary_assign_bw"]], "unary_bitwise_and (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.unary_bitwise_and"]], "unary_bitwise_left_shift (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.unary_bitwise_left_shift"]], "unary_bitwise_or (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.unary_bitwise_or"]], "unary_bitwise_right_shift (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.unary_bitwise_right_shift"]], "unary_bitwise_xor (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.unary_bitwise_xor"]], "unary_div_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unary_div_bw"]], "unary_div_no_nan_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unary_div_no_nan_bw"]], "unary_eq_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unary_eq_bw"]], "unary_fmod (class in tt_lib.fallback_ops)": [[20, "tt_lib.fallback_ops.unary_fmod"]], "unary_fmod_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unary_fmod_bw"]], "unary_gt() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unary_gt"]], "unary_lt() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unary_lt"]], "unary_mul_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unary_mul_bw"]], "unary_ne() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unary_ne"]], "unary_pow_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unary_pow_bw"]], "unary_remainder_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unary_remainder_bw"]], "unary_sub_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unary_sub_bw"]], "unpad() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.unpad"]], "untilize() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.untilize"]], "untilize_with_unpadding() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.untilize_with_unpadding"]], "var_hw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.var_hw"]], "where() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.where"]], "where_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.where_bw"]], "xlogy() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.xlogy"]], "xlogy_bw() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.xlogy_bw"]], "zeros() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.zeros"]], "zeros_like() (in module tt_lib.tensor)": [[20, "tt_lib.tensor.zeros_like"]], "shape (class in ttnn)": [[24, "ttnn.Shape"]], "rank (ttnn.shape property)": [[24, "ttnn.Shape.rank"]], "with_tile_padding() (ttnn.shape method)": [[24, "ttnn.Shape.with_tile_padding"]], "maxpool2d (class in ttnn)": [[25, "ttnn.MaxPool2d"]], "abs() (in module ttnn)": [[26, "ttnn.abs"]], "acos() (in module ttnn)": [[27, "ttnn.acos"]], "acosh() (in module ttnn)": [[28, "ttnn.acosh"]], "add() (in module ttnn)": [[29, "ttnn.add"]], "addcdiv() (in module ttnn)": [[30, "ttnn.addcdiv"]], "addcmul() (in module ttnn)": [[31, "ttnn.addcmul"]], "arange() (in module ttnn)": [[32, "ttnn.arange"]], "argmax() (in module ttnn)": [[33, "ttnn.argmax"]], "as_tensor() (in module ttnn)": [[34, "ttnn.as_tensor"]], "asin() (in module ttnn)": [[35, "ttnn.asin"]], "asinh() (in module ttnn)": [[36, "ttnn.asinh"]], "atan() (in module ttnn)": [[37, "ttnn.atan"]], "atan2() (in module ttnn)": [[38, "ttnn.atan2"]], "atanh() (in module ttnn)": [[39, "ttnn.atanh"]], "cbrt() (in module ttnn)": [[40, "ttnn.cbrt"]], "celu() (in module ttnn)": [[41, "ttnn.celu"]], "clip() (in module ttnn)": [[42, "ttnn.clip"]], "clone() (in module ttnn)": [[43, "ttnn.clone"]], "close_device() (in module ttnn)": [[44, "ttnn.close_device"]], "concat() (in module ttnn)": [[45, "ttnn.concat"]], "cos() (in module ttnn)": [[46, "ttnn.cos"]], "cosh() (in module ttnn)": [[47, "ttnn.cosh"]], "create_sharded_memory_config() (in module ttnn)": [[48, "ttnn.create_sharded_memory_config"]], "deallocate() (in module ttnn)": [[49, "ttnn.deallocate"]], "deg2rad() (in module ttnn)": [[50, "ttnn.deg2rad"]], "digamma() (in module ttnn)": [[51, "ttnn.digamma"]], "dump_tensor() (in module ttnn)": [[52, "ttnn.dump_tensor"]], "elu() (in module ttnn)": [[53, "ttnn.elu"]], "embedding() (in module ttnn)": [[54, "ttnn.embedding"]], "empty() (in module ttnn)": [[55, "ttnn.empty"]], "eq() (in module ttnn)": [[56, "ttnn.eq"]], "eqz() (in module ttnn)": [[57, "ttnn.eqz"]], "erf() (in module ttnn)": [[58, "ttnn.erf"]], "erfc() (in module ttnn)": [[59, "ttnn.erfc"]], "erfinv() (in module ttnn)": [[60, "ttnn.erfinv"]], "exp() (in module ttnn)": [[61, "ttnn.exp"]], "exp2() (in module ttnn)": [[62, "ttnn.exp2"]], "expm1() (in module ttnn)": [[63, "ttnn.expm1"]], "from_device() (in module ttnn)": [[64, "ttnn.from_device"]], "from_torch() (in module ttnn)": [[65, "ttnn.from_torch"]], "full() (in module ttnn)": [[66, "ttnn.full"]], "full_like() (in module ttnn)": [[67, "ttnn.full_like"]], "ge() (in module ttnn)": [[68, "ttnn.ge"]], "geglu() (in module ttnn)": [[69, "ttnn.geglu"]], "gelu() (in module ttnn)": [[70, "ttnn.gelu"]], "gez() (in module ttnn)": [[71, "ttnn.gez"]], "global_avg_pool2d() (in module ttnn)": [[72, "ttnn.global_avg_pool2d"]], "glu() (in module ttnn)": [[73, "ttnn.glu"]], "group_norm() (in module ttnn)": [[74, "ttnn.group_norm"]], "gt() (in module ttnn)": [[75, "ttnn.gt"]], "gtz() (in module ttnn)": [[76, "ttnn.gtz"]], "hardshrink() (in module ttnn)": [[77, "ttnn.hardshrink"]], "hardsigmoid() (in module ttnn)": [[78, "ttnn.hardsigmoid"]], "hardswish() (in module ttnn)": [[79, "ttnn.hardswish"]], "hardtanh() (in module ttnn)": [[80, "ttnn.hardtanh"]], "heaviside() (in module ttnn)": [[81, "ttnn.heaviside"]], "hypot() (in module ttnn)": [[82, "ttnn.hypot"]], "i0() (in module ttnn)": [[83, "ttnn.i0"]], "isclose() (in module ttnn)": [[84, "ttnn.isclose"]], "isfinite() (in module ttnn)": [[85, "ttnn.isfinite"]], "isinf() (in module ttnn)": [[86, "ttnn.isinf"]], "isnan() (in module ttnn)": [[87, "ttnn.isnan"]], "isneginf() (in module ttnn)": [[88, "ttnn.isneginf"]], "isposinf() (in module ttnn)": [[89, "ttnn.isposinf"]], "fill_cache_for_user_() (in module ttnn.kv_cache)": [[90, "ttnn.kv_cache.fill_cache_for_user_"]], "update_cache_for_token_() (in module ttnn.kv_cache)": [[91, "ttnn.kv_cache.update_cache_for_token_"]], "l1_loss() (in module ttnn)": [[92, "ttnn.l1_loss"]], "layer_norm() (in module ttnn)": [[93, "ttnn.layer_norm"]], "ldexp() (in module ttnn)": [[94, "ttnn.ldexp"]], "le() (in module ttnn)": [[95, "ttnn.le"]], "leaky_relu() (in module ttnn)": [[96, "ttnn.leaky_relu"]], "lerp() (in module ttnn)": [[97, "ttnn.lerp"]], "lez() (in module ttnn)": [[98, "ttnn.lez"]], "lgamma() (in module ttnn)": [[99, "ttnn.lgamma"]], "linear() (in module ttnn)": [[100, "ttnn.linear"]], "load_tensor() (in module ttnn)": [[101, "ttnn.load_tensor"]], "log() (in module ttnn)": [[102, "ttnn.log"]], "log10() (in module ttnn)": [[103, "ttnn.log10"]], "log1p() (in module ttnn)": [[104, "ttnn.log1p"]], "log2() (in module ttnn)": [[105, "ttnn.log2"]], "log_sigmoid() (in module ttnn)": [[106, "ttnn.log_sigmoid"]], "logaddexp() (in module ttnn)": [[107, "ttnn.logaddexp"]], "logaddexp2() (in module ttnn)": [[108, "ttnn.logaddexp2"]], "logical_and() (in module ttnn)": [[109, "ttnn.logical_and"]], "logical_or() (in module ttnn)": [[111, "ttnn.logical_or"]], "logical_xor() (in module ttnn)": [[112, "ttnn.logical_xor"]], "logit() (in module ttnn)": [[113, "ttnn.logit"]], "lt() (in module ttnn)": [[114, "ttnn.lt"]], "ltz() (in module ttnn)": [[115, "ttnn.ltz"]], "mac() (in module ttnn)": [[116, "ttnn.mac"]], "manage_device() (in module ttnn)": [[117, "ttnn.manage_device"]], "matmul() (in module ttnn)": [[118, "ttnn.matmul"]], "max() (in module ttnn)": [[119, "ttnn.max"]], "maximum() (in module ttnn)": [[120, "ttnn.maximum"]], "mean() (in module ttnn)": [[121, "ttnn.mean"]], "min() (in module ttnn)": [[122, "ttnn.min"]], "minimum() (in module ttnn)": [[123, "ttnn.minimum"]], "mish() (in module ttnn)": [[124, "ttnn.mish"]], "preprocess_model() (in module ttnn.model_preprocessing)": [[125, "ttnn.model_preprocessing.preprocess_model"]], "preprocess_model_parameters() (in module ttnn.model_preprocessing)": [[126, "ttnn.model_preprocessing.preprocess_model_parameters"]], "mse_loss() (in module ttnn)": [[127, "ttnn.mse_loss"]], "multigammaln() (in module ttnn)": [[128, "ttnn.multigammaln"]], "multiply() (in module ttnn)": [[129, "ttnn.multiply"]], "ne() (in module ttnn)": [[130, "ttnn.ne"]], "neg() (in module ttnn)": [[131, "ttnn.neg"]], "nextafter() (in module ttnn)": [[132, "ttnn.nextafter"]], "nez() (in module ttnn)": [[133, "ttnn.nez"]], "ones() (in module ttnn)": [[134, "ttnn.ones"]], "ones_like() (in module ttnn)": [[135, "ttnn.ones_like"]], "open_device() (in module ttnn)": [[136, "ttnn.open_device"]], "pad() (in module ttnn)": [[137, "ttnn.pad"]], "permute() (in module ttnn)": [[138, "ttnn.permute"]], "polygamma() (in module ttnn)": [[139, "ttnn.polygamma"]], "polyval() (in module ttnn)": [[140, "ttnn.polyval"]], "pow() (in module ttnn)": [[141, "ttnn.pow"]], "prelu() (in module ttnn)": [[142, "ttnn.prelu"]], "rad2deg() (in module ttnn)": [[143, "ttnn.rad2deg"]], "reallocate() (in module ttnn)": [[144, "ttnn.reallocate"]], "reciprocal() (in module ttnn)": [[145, "ttnn.reciprocal"]], "register_post_operation_hook() (in module ttnn)": [[146, "ttnn.register_post_operation_hook"]], "register_pre_operation_hook() (in module ttnn)": [[147, "ttnn.register_pre_operation_hook"]], "reglu() (in module ttnn)": [[148, "ttnn.reglu"]], "relu() (in module ttnn)": [[149, "ttnn.relu"]], "relu6() (in module ttnn)": [[150, "ttnn.relu6"]], "repeat() (in module ttnn)": [[151, "ttnn.repeat"]], "repeat_interleave() (in module ttnn)": [[152, "ttnn.repeat_interleave"]], "reshape() (in module ttnn)": [[153, "ttnn.reshape"]], "rms_norm() (in module ttnn)": [[154, "ttnn.rms_norm"]], "rsqrt() (in module ttnn)": [[155, "ttnn.rsqrt"]], "set_printoptions() (in module ttnn)": [[156, "ttnn.set_printoptions"]], "sigmoid() (in module ttnn)": [[157, "ttnn.sigmoid"]], "sigmoid_accurate() (in module ttnn)": [[158, "ttnn.sigmoid_accurate"]], "sign() (in module ttnn)": [[159, "ttnn.sign"]], "signbit() (in module ttnn)": [[160, "ttnn.signbit"]], "silu() (in module ttnn)": [[161, "ttnn.silu"]], "sin() (in module ttnn)": [[162, "ttnn.sin"]], "sinh() (in module ttnn)": [[163, "ttnn.sinh"]], "softmax() (in module ttnn)": [[164, "ttnn.softmax"]], "softplus() (in module ttnn)": [[165, "ttnn.softplus"]], "softshrink() (in module ttnn)": [[166, "ttnn.softshrink"]], "softsign() (in module ttnn)": [[167, "ttnn.softsign"]], "sqrt() (in module ttnn)": [[169, "ttnn.sqrt"]], "square() (in module ttnn)": [[170, "ttnn.square"]], "squared_difference() (in module ttnn)": [[171, "ttnn.squared_difference"]], "std() (in module ttnn)": [[172, "ttnn.std"]], "subtract() (in module ttnn)": [[173, "ttnn.subtract"]], "sum() (in module ttnn)": [[174, "ttnn.sum"]], "swiglu() (in module ttnn)": [[175, "ttnn.swiglu"]], "swish() (in module ttnn)": [[176, "ttnn.swish"]], "synchronize_device() (in module ttnn)": [[177, "ttnn.synchronize_device"]], "tan() (in module ttnn)": [[178, "ttnn.tan"]], "tanh() (in module ttnn)": [[179, "ttnn.tanh"]], "tanhshrink() (in module ttnn)": [[180, "ttnn.tanhshrink"]], "threshold() (in module ttnn)": [[181, "ttnn.threshold"]], "to_device() (in module ttnn)": [[182, "ttnn.to_device"]], "to_layout() (in module ttnn)": [[183, "ttnn.to_layout"]], "to_memory_config() (in module ttnn)": [[184, "ttnn.to_memory_config"]], "to_torch() (in module ttnn)": [[185, "ttnn.to_torch"]], "attention_softmax() (in module ttnn.transformer)": [[187, "ttnn.transformer.attention_softmax"]], "attention_softmax_() (in module ttnn.transformer)": [[188, "ttnn.transformer.attention_softmax_"]], "concatenate_heads() (in module ttnn.transformer)": [[189, "ttnn.transformer.concatenate_heads"]], "rotary_embedding() (in module ttnn.transformer)": [[190, "ttnn.transformer.rotary_embedding"]], "split_query_key_value_and_split_heads() (in module ttnn.transformer)": [[191, "ttnn.transformer.split_query_key_value_and_split_heads"]], "tril() (in module ttnn)": [[192, "ttnn.tril"]], "triu() (in module ttnn)": [[193, "ttnn.triu"]], "upsample() (in module ttnn)": [[194, "ttnn.upsample"]], "var() (in module ttnn)": [[195, "ttnn.var"]], "where() (in module ttnn)": [[196, "ttnn.where"]], "xlogy() (in module ttnn)": [[197, "ttnn.xlogy"]], "zeros() (in module ttnn)": [[198, "ttnn.zeros"]], "zeros_like() (in module ttnn)": [[199, "ttnn.zeros_like"]]}})