<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>TT-LIB &mdash; TT-NN  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/tt_theme.css?v=ea036265" />

  
    <link rel="shortcut icon" href="../../_static/cropped-favicon-32x32.png"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=b3ba4146"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Tensor" href="tensor.html" />
    <link rel="prev" title="Dependencies" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >



<a href="https://tenstorrent.github.io/docs-test/core/latest/">
    <img src="../../_static/tt_logo.svg" class="logo" alt="Logo"/>
</a>

<a href="../../index.html">
    TT-NN
</a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">TTNN</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../about.html">What is ttnn?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage.html">Using ttnn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onboarding.html">Onboarding New Functionality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../converting_torch_model_to_ttnn.html">Converting torch Model to ttnn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../adding_new_ttnn_operation.html">Adding New ttnn Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../profiling_ttnn_operations.html">Profiling ttnn Operations</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Dependencies</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">TT-LIB</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#operation-infrastructure">Operation Infrastructure</a></li>
<li class="toctree-l4"><a class="reference internal" href="#profiler">Profiler</a></li>
<li class="toctree-l4"><a class="reference internal" href="#fast-dispatch">Fast Dispatch</a></li>
<li class="toctree-l4"><a class="reference internal" href="#program-caching">Program Caching</a></li>
<li class="toctree-l4"><a class="reference internal" href="#logs">Logs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tt-lib-api-through-tt-lib">TT-LIB API through <code class="docutils literal notranslate"><span class="pre">tt_lib</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#primary-operations">Primary Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#enums">Enums</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensor-elementwise-operations">Tensor elementwise operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensor-relational-operations">Tensor relational operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensor-ternary-operations">Tensor ternary operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensor-matrix-math-operations">Tensor matrix math operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensor-creation-operations">Tensor creation operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#broadcast-and-reduce">Broadcast and Reduce</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#fallback-operations">Fallback Operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.full"><code class="docutils literal notranslate"><span class="pre">full()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.tensor_slice"><code class="docutils literal notranslate"><span class="pre">tensor_slice()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.reshape"><code class="docutils literal notranslate"><span class="pre">reshape()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.chunk"><code class="docutils literal notranslate"><span class="pre">chunk()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.conv2d"><code class="docutils literal notranslate"><span class="pre">conv2d()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.group_norm"><code class="docutils literal notranslate"><span class="pre">group_norm()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.layer_norm"><code class="docutils literal notranslate"><span class="pre">layer_norm()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.pad"><code class="docutils literal notranslate"><span class="pre">pad()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.interpolate"><code class="docutils literal notranslate"><span class="pre">interpolate()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.repeat"><code class="docutils literal notranslate"><span class="pre">repeat()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.repeat_interleave"><code class="docutils literal notranslate"><span class="pre">repeat_interleave()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.concat"><code class="docutils literal notranslate"><span class="pre">concat()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.silu"><code class="docutils literal notranslate"><span class="pre">silu()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.softmax"><code class="docutils literal notranslate"><span class="pre">softmax()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.Conv2d"><code class="docutils literal notranslate"><span class="pre">Conv2d</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.BatchNorm2d"><code class="docutils literal notranslate"><span class="pre">BatchNorm2d</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.GroupNorm"><code class="docutils literal notranslate"><span class="pre">GroupNorm</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.LayerNorm"><code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.MaxPool2d"><code class="docutils literal notranslate"><span class="pre">MaxPool2d</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.AdaptiveAvgPool2d"><code class="docutils literal notranslate"><span class="pre">AdaptiveAvgPool2d</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.ceil"><code class="docutils literal notranslate"><span class="pre">ceil</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.floor"><code class="docutils literal notranslate"><span class="pre">floor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.trunc"><code class="docutils literal notranslate"><span class="pre">trunc</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.unary_fmod"><code class="docutils literal notranslate"><span class="pre">unary_fmod</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.binary_fmod"><code class="docutils literal notranslate"><span class="pre">binary_fmod</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.bitwise_not"><code class="docutils literal notranslate"><span class="pre">bitwise_not</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.unary_bitwise_or"><code class="docutils literal notranslate"><span class="pre">unary_bitwise_or</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.unary_bitwise_and"><code class="docutils literal notranslate"><span class="pre">unary_bitwise_and</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.unary_bitwise_xor"><code class="docutils literal notranslate"><span class="pre">unary_bitwise_xor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.binary_bitwise_or"><code class="docutils literal notranslate"><span class="pre">binary_bitwise_or</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.binary_bitwise_and"><code class="docutils literal notranslate"><span class="pre">binary_bitwise_and</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.binary_bitwise_xor"><code class="docutils literal notranslate"><span class="pre">binary_bitwise_xor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.unary_bitwise_left_shift"><code class="docutils literal notranslate"><span class="pre">unary_bitwise_left_shift</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.unary_bitwise_right_shift"><code class="docutils literal notranslate"><span class="pre">unary_bitwise_right_shift</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.binary_bitwise_left_shift"><code class="docutils literal notranslate"><span class="pre">binary_bitwise_left_shift</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.binary_bitwise_right_shift"><code class="docutils literal notranslate"><span class="pre">binary_bitwise_right_shift</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.torch_argmax"><code class="docutils literal notranslate"><span class="pre">torch_argmax</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tt_lib.fallback_ops.torch_argmin"><code class="docutils literal notranslate"><span class="pre">torch_argmin</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#experimental-operations">Experimental Operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#fused-operations-from-tt-lib-mini-graph-library">Fused Operations from <code class="docutils literal notranslate"><span class="pre">tt_lib</span></code> Mini-Graph Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="#complex-operations">Complex Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#complex-operations-type-2">Complex Operations (Type 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#other-operations">Other Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#backward-operations">Backward Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#loss-functions">Loss Functions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples.html">Examples of Tensor and TT-LIB Use</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../demos.html">Building and Uplifting Demos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ttnn_sweeps/index.html">Placeholder title</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tt_metal_models/get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tt_metal_models/get_performance.html">Performance</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../resources/support.html">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources/contributing.html">Contributing as a developer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">TT-NN</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Dependencies</a></li>
      <li class="breadcrumb-item active">TT-LIB</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/ttnn/dependencies/tt_lib.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="tt-lib">
<span id="id1"></span><h1>TT-LIB<a class="headerlink" href="#tt-lib" title="Permalink to this heading"></a>
</h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this heading"></a>
</h2>
<p>The <code class="docutils literal notranslate"><span class="pre">tt_lib</span></code> Python module is a
unified Python interface to the Tensor library located within <code class="docutils literal notranslate"><span class="pre">tt_eager</span></code>. This library currently only supports 4 dimensional tensors with shape <code class="docutils literal notranslate"><span class="pre">[W,</span> <span class="pre">Z,</span> <span class="pre">Y,</span> <span class="pre">X]</span></code>, in ROW_MAJOR layout, and with BFLOAT16 data type.</p>
<p>Some OPs in this library might change layout of input tensors and pad them to better match expectations of execution kernels on TT Accelerator device.
These OPs will unpad the result tensor before it is returned to caller.</p>
<p>There is a limitation that tensor in ROW_MAJOR layout on TT Accelerator device must have the size of last dimension <code class="docutils literal notranslate"><span class="pre">X</span></code> be divisible by 2.
You can’t create these type of tensors on TT Accelerator device or send them to TT Accelerator device with <code class="docutils literal notranslate"><span class="pre">`tt_lib.tensor.Tensor.to()</span></code>.
However, you can supply these type of tensors to OPs from TT-LIB library as they can automatically pad the last dimension before moving the tensor
to TT Accelerator device. To use this functionality, you must call <cite>tt_lib.device.SetDefaultDevice(tt_device)</cite> to set your TT Accelerator device
as the default device that will be used to execute operations on tensors that are on host machine.</p>
<section id="operation-infrastructure">
<h3>Operation Infrastructure<a class="headerlink" href="#operation-infrastructure" title="Permalink to this heading"></a>
</h3>
<p>TT-LIB has operation infrastructure which is used to launch, profile and cache operations generically.</p>
<p>To add a new operation that can plug in to the infrastructure, all that’s needed is a struct that implements methods needed by operation interface.
Below, is an example of how to declare a new on-device operation with all of the methods required by the interface.</p>
<section id="new-device-operation">
<h4>New Device Operation<a class="headerlink" href="#new-device-operation" title="Permalink to this heading"></a>
</h4>
<div class="highlight-cpp notranslate">
<div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="o">&lt;</span><span class="n">NewOperation</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">validate</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Shape</span><span class="o">&gt;</span><span class="w"> </span><span class="n">compute_output_shapes</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">create_output_tensors</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">    </span><span class="n">operation</span><span class="o">::</span><span class="n">ProgramWithCallbacks</span><span class="w"> </span><span class="nf">create_program</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">input_tensors</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>

<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">attribute_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">forward_as_tuple</span><span class="p">();</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">attribute_values</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">forward_as_tuple</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
<section id="new-device-operation-with-a-member">
<h4>New Device Operation with a member<a class="headerlink" href="#new-device-operation-with-a-member" title="Permalink to this heading"></a>
</h4>
<div class="highlight-cpp notranslate">
<div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="o">&lt;</span><span class="n">NewOperation</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">some_member</span>

<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="n">validate</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Shape</span><span class="o">&gt;</span><span class="w"> </span><span class="n">compute_output_shapes</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">create_output_tensors</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">    </span><span class="n">operation</span><span class="o">::</span><span class="n">ProgramWithCallbacks</span><span class="w"> </span><span class="nf">create_program</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">input_tensors</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>

<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">attribute_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">forward_as_tuple</span><span class="p">(</span><span class="s">"some_member"</span><span class="p">);</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">attribute_values</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">forward_as_tuple</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">cref</span><span class="p">(</span><span class="n">some_member</span><span class="p">));</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
<section id="new-device-operation-with-optional-input-tensors">
<h4>New Device Operation with Optional Input Tensors<a class="headerlink" href="#new-device-operation-with-optional-input-tensors" title="Permalink to this heading"></a>
</h4>
<div class="highlight-cpp notranslate">
<div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="o">&lt;</span><span class="n">NewOperation</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">validate</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">,</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&gt;&gt;&amp;</span><span class="w"> </span><span class="n">optional_input_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Shape</span><span class="o">&gt;</span><span class="w"> </span><span class="n">compute_output_shapes</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">create_output_tensors</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">    </span><span class="n">operation</span><span class="o">::</span><span class="n">ProgramWithCallbacks</span><span class="w"> </span><span class="nf">create_program</span><span class="p">(</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">input_tensors</span><span class="p">,</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&gt;&gt;&amp;</span><span class="w"> </span><span class="n">optional_input_tensors</span><span class="p">,</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>

<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">attribute_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">forward_as_tuple</span><span class="p">();</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">attribute_values</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">forward_as_tuple</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
<section id="new-device-operation-with-optional-output-tensors">
<h4>New Device Operation with Optional Output Tensors<a class="headerlink" href="#new-device-operation-with-optional-output-tensors" title="Permalink to this heading"></a>
</h4>
<p>If an operation is expected to leverage optional output tensors, please use instead the validate_with_output_tensors
and create_output_tensors with the additional parameter for the output_tensors.</p>
<div class="highlight-cpp notranslate">
<div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="o">&lt;</span><span class="n">NewOperation</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">validate_with_output_tensors</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;&gt;&amp;</span><span class="w"> </span><span class="n">output_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Shape</span><span class="o">&gt;</span><span class="w"> </span><span class="n">compute_output_shapes</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">create_output_tensors</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;&gt;&amp;</span><span class="w"> </span><span class="n">output_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">    </span><span class="n">operation</span><span class="o">::</span><span class="n">ProgramWithOptionalOutputTensors</span><span class="w"> </span><span class="nf">create_program</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">input_tensors</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>

<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">attribute_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">forward_as_tuple</span><span class="p">();</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">attribute_values</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">forward_as_tuple</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
<section id="new-host-operation">
<h4>New Host Operation<a class="headerlink" href="#new-host-operation" title="Permalink to this heading"></a>
</h4>
<p>And below, is an example of how to declare a new on-host operation with all of the methods required by the interface.</p>
<div class="highlight-default notranslate">
<div class="highlight"><pre><span></span><span class="n">struct</span> <span class="o">&lt;</span><span class="n">NewOperation</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">void</span> <span class="n">validate</span><span class="p">(</span><span class="n">const</span> <span class="n">std</span><span class="p">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">)</span> <span class="n">const</span><span class="p">;</span>
    <span class="n">std</span><span class="p">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Shape</span><span class="o">&gt;</span> <span class="n">compute_output_shapes</span><span class="p">(</span><span class="n">const</span> <span class="n">std</span><span class="p">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">)</span> <span class="n">const</span><span class="p">;</span>
    <span class="n">std</span><span class="p">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="n">compute_output_tensors</span><span class="p">(</span><span class="n">const</span> <span class="n">std</span><span class="p">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">)</span> <span class="n">const</span><span class="p">;</span>

    <span class="n">static</span> <span class="n">constexpr</span> <span class="n">auto</span> <span class="n">attribute_names</span> <span class="o">=</span> <span class="n">std</span><span class="p">::</span><span class="n">forward_as_tuple</span><span class="p">();</span>
    <span class="n">const</span> <span class="n">auto</span> <span class="n">attribute_values</span><span class="p">()</span> <span class="n">const</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">std</span><span class="p">::</span><span class="n">forward_as_tuple</span><span class="p">();</span>
    <span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
</section>
</section>
<section id="profiler">
<h3>Profiler<a class="headerlink" href="#profiler" title="Permalink to this heading"></a>
</h3>
<p>Profiler is supported out of the box for any op.</p>
<p>And there are 2 special methods that can be optionally implemented to set the preferred_name and parallelization_strategy.</p>
<div class="highlight-default notranslate">
<div class="highlight"><pre><span></span>// Implement `get_parallelization_strategy` to set the parallelization strategy on the profiler
struct &lt;NewOperation&gt; {
    &lt;ParallelizationStrategyEnum&gt; get_parallelization_strategy(const std::vector&lt;Tensor&gt; &amp;input_tensors) const;
};
</pre></div>
</div>
</section>
<section id="fast-dispatch">
<h3>Fast Dispatch<a class="headerlink" href="#fast-dispatch" title="Permalink to this heading"></a>
</h3>
<p>Fast dispatch allows programs/kernels to be enqueued to run, so host code does not have to wait for ops/programs to finish running.
The enqueued programs run asynchronously to the host code.
To wait for kernels to complete, either read a tensor from device to host with:</p>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.Tensor.cpu">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.Tensor.</span></span><span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">blocking</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.Tensor.cpu" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Move TT Tensor from TT accelerator device to host device.</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="n">tt_tensor</span> <span class="o">=</span> <span class="n">tt_tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</pre></div>
</div>
</dd>
</dl>

<p>or to perform only a wait, use:</p>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.device.Synchronize">
<span class="sig-prename descclassname"><span class="pre">tt_lib.device.</span></span><span class="sig-name descname"><span class="pre">Synchronize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tt_lib.device.Device</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#tt_lib.device.Synchronize" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Wait for all kernels on TT device to complete.</p>
</dd>
</dl>

</section>
<section id="program-caching">
<h3>Program Caching<a class="headerlink" href="#program-caching" title="Permalink to this heading"></a>
</h3>
<p>Program caching provides an ability for an operation to cache the program and simply reload it the next time the same operation is used.</p>
<p>It can be enabled by running:</p>
<div class="highlight-default notranslate">
<div class="highlight"><pre><span></span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">program_cache</span><span class="p">::</span><span class="n">enable</span><span class="p">()</span>
</pre></div>
</div>
<p>And it can be disabled by running:</p>
<div class="highlight-default notranslate">
<div class="highlight"><pre><span></span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">program_cache</span><span class="p">::</span><span class="n">disable_and_clear</span><span class="p">()</span>
</pre></div>
</div>
<p>Number of entries can be queried using:</p>
<div class="highlight-default notranslate">
<div class="highlight"><pre><span></span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">program_cache</span><span class="p">::</span><span class="n">num_entries</span><span class="p">()</span>
</pre></div>
</div>
<p>In order for an op to be cachable, it needs to implement the following:</p>
<div class="highlight-default notranslate">
<div class="highlight"><pre><span></span>struct &lt;NewOperation&gt; {
   // Mandatory methods

    // Return type of `create_program` needs to implement override_runtime_args_callback
    // i.e.:
    operation::ProgramWithCallbacks create_program(const std::vector&lt;Tensor&gt; &amp;input_tensors) const {

        Program program{};

        // ...

        auto override_runtime_args_callback = [unary_reader_kernel_id, unary_writer_kernel_id](
            const Program &amp;program,
            const std::vector&lt;Buffer*&gt;&amp; input_buffers,
            const std::vector&lt;Buffer*&gt;&amp; output_buffers
        ) {

            auto src_dram_buffer = input_buffers.at(0);
            auto dst_dram_buffer = output_buffers.at(0);

            CoreCoord core = {0, 0};

            {
                auto &amp;runtime_args = GetRuntimeArgs(program, unary_reader_kernel_id, core);
                runtime_args[0] = src_dram_buffer-&gt;address();
            }

            {
                auto &amp;runtime_args = GetRuntimeArgs(program, unary_writer_kernel_id, core);
                runtime_args[0] = dst_dram_buffer-&gt;address();
            }
        };

        return {std::move(program), override_runtime_args_callback};
    }
};
</pre></div>
</div>
</section>
<section id="logs">
<h3>Logs<a class="headerlink" href="#logs" title="Permalink to this heading"></a>
</h3>
<p>To see logs related to operation infrastructure, use the following environment variables:</p>
<div class="highlight-default notranslate">
<div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">TT_METAL_LOGGER_TYPES</span><span class="o">=</span><span class="n">Op</span>
<span class="n">export</span> <span class="n">TT_METAL_LOGGER_LEVEL</span><span class="o">=</span><span class="n">Debug</span>
</pre></div>
</div>
<p>The logs will print currently running op and information related to program caching. i.e.:</p>
<div class="highlight-default notranslate">
<div class="highlight"><pre><span></span><span class="n">Op</span> <span class="o">|</span> <span class="n">DEBUG</span>    <span class="o">|</span> <span class="n">Operation</span> <span class="n">Type</span><span class="p">:</span> <span class="n">silu</span> <span class="p">(</span><span class="n">fallback</span> <span class="n">operation</span><span class="p">)</span>
<span class="n">Op</span> <span class="o">|</span> <span class="n">DEBUG</span>    <span class="o">|</span> <span class="n">Operation</span> <span class="n">Attributes</span><span class="p">:</span> <span class="p">()</span>
<span class="n">Op</span> <span class="o">|</span> <span class="n">DEBUG</span>    <span class="o">|</span> <span class="n">Input</span> <span class="n">Tensors</span><span class="p">:</span> <span class="p">{</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">Tensor</span><span class="p">(</span><span class="n">storage</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">DeviceStorage</span><span class="p">(</span><span class="n">memory_config</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">MemoryConfig</span><span class="p">(</span><span class="n">memory_layout</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">TensorMemoryLayout</span><span class="p">::</span><span class="n">INTERLEAVED</span><span class="p">,</span> <span class="n">buffer_type</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">BufferType</span><span class="p">::</span><span class="n">DRAM</span><span class="p">)),</span> <span class="n">shape</span><span class="o">=</span><span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1280</span><span class="p">},</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">DataType</span><span class="p">::</span><span class="n">BFLOAT16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">Layout</span><span class="p">::</span><span class="n">ROW_MAJOR</span><span class="p">)}</span>
<span class="n">Op</span> <span class="o">|</span> <span class="n">DEBUG</span>    <span class="o">|</span> <span class="n">Operation</span> <span class="n">Type</span><span class="p">:</span> <span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">LayoutConversionOnHost</span>
<span class="n">Op</span> <span class="o">|</span> <span class="n">DEBUG</span>    <span class="o">|</span> <span class="n">Operation</span> <span class="n">Attributes</span><span class="p">:</span> <span class="p">(</span><span class="n">target_layout</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">Layout</span><span class="p">::</span><span class="n">TILE</span><span class="p">)</span>
<span class="n">Op</span> <span class="o">|</span> <span class="n">DEBUG</span>    <span class="o">|</span> <span class="n">Input</span> <span class="n">Tensors</span><span class="p">:</span> <span class="p">{</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">Tensor</span><span class="p">(</span><span class="n">storage</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">OwnedStorage</span><span class="p">(),</span> <span class="n">shape</span><span class="o">=</span><span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">320</span><span class="p">,</span> <span class="mi">1280</span><span class="p">},</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">DataType</span><span class="p">::</span><span class="n">BFLOAT16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">Layout</span><span class="p">::</span><span class="n">ROW_MAJOR</span><span class="p">)}</span>
<span class="o">...</span>
<span class="n">Op</span> <span class="o">|</span> <span class="n">DEBUG</span>    <span class="o">|</span> <span class="n">Program</span> <span class="n">Cache</span><span class="p">:</span> <span class="n">MISS</span> <span class="o">-</span> <span class="n">Compiling</span> <span class="n">new</span> <span class="n">program</span> <span class="s2">"tt::tt_metal::EltwiseUnary(op_type=tt::tt_metal::UnaryOpType::Enum::GELU, param=1)_tt::tt_metal::Tensor(storage=tt::tt_metal::DeviceStorage(memory_config=tt::tt_metal::MemoryConfig(memory_layout=tt::tt_metal::TensorMemoryLayout::INTERLEAVED, buffer_type=tt::tt_metal::BufferType::DRAM)), shape={1, 1, 32, 32}, dtype=tt::tt_metal::DataType::BFLOAT16, layout=tt::tt_metal::Layout::TILE)"</span>
<span class="n">Op</span> <span class="o">|</span> <span class="n">DEBUG</span>    <span class="o">|</span> <span class="n">Operation</span> <span class="n">Name</span><span class="p">:</span> <span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">EltwiseUnary</span>
<span class="n">Op</span> <span class="o">|</span> <span class="n">DEBUG</span>    <span class="o">|</span> <span class="n">Operation</span> <span class="n">Attributes</span><span class="p">:</span> <span class="p">(</span><span class="n">op_type</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">UnaryOpType</span><span class="p">::</span><span class="n">Enum</span><span class="p">::</span><span class="n">GELU</span><span class="p">,</span> <span class="n">param</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Op</span> <span class="o">|</span> <span class="n">DEBUG</span>    <span class="o">|</span> <span class="n">Input</span> <span class="n">Tensors</span><span class="p">:</span> <span class="p">{</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">Tensor</span><span class="p">(</span><span class="n">storage</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">DeviceStorage</span><span class="p">(</span><span class="n">memory_config</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">MemoryConfig</span><span class="p">(</span><span class="n">memory_layout</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">TensorMemoryLayout</span><span class="p">::</span><span class="n">INTERLEAVED</span><span class="p">,</span> <span class="n">buffer_type</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">BufferType</span><span class="p">::</span><span class="n">DRAM</span><span class="p">)),</span> <span class="n">shape</span><span class="o">=</span><span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">},</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">DataType</span><span class="p">::</span><span class="n">BFLOAT16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">tt</span><span class="p">::</span><span class="n">tt_metal</span><span class="p">::</span><span class="n">Layout</span><span class="p">::</span><span class="n">TILE</span><span class="p">)}</span>
</pre></div>
</div>
<p>If <cite>OPERATION_HISTORY_CSV=&lt;csv_file_path&gt;</cite> environment variable is set, then the history of all executed operations will be dumped into <cite>&lt;csv_file_path&gt;</cite></p>
</section>
</section>
<section id="tt-lib-api-through-tt-lib">
<h2>TT-LIB API through <code class="docutils literal notranslate"><span class="pre">tt_lib</span></code><a class="headerlink" href="#tt-lib-api-through-tt-lib" title="Permalink to this heading"></a>
</h2>
<section id="primary-operations">
<h3>Primary Operations<a class="headerlink" href="#primary-operations" title="Permalink to this heading"></a>
</h3>
<p>autofunction:: tt_lib.operations.primary.matmul</p>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.layernorm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">layernorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">program_config:</span> <span class="pre">Union[tt_lib.operations.primary.LayerNormDefaultProgramConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.operations.primary.LayerNormShardedMultiCoreProgramConfig]</span> <span class="pre">=</span> <span class="pre">&lt;tt_lib.operations.primary.LayerNormDefaultProgramConfig</span> <span class="pre">object</span> <span class="pre">at</span> <span class="pre">0x7f7e10cd07f0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.layernorm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a layernorm operation on the last tensor dimension with optional fused with post-multiplication and addition via W-bcast.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.add_layernorm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">add_layernorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">program_config:</span> <span class="pre">Union[tt_lib.operations.primary.LayerNormDefaultProgramConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.operations.primary.LayerNormShardedMultiCoreProgramConfig]</span> <span class="pre">=</span> <span class="pre">&lt;tt_lib.operations.primary.LayerNormDefaultProgramConfig</span> <span class="pre">object</span> <span class="pre">at</span> <span class="pre">0x7f7e10cd1730&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.add_layernorm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a layernorm(a+b)*gamma + beta operation.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.softmax_in_place">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">softmax_in_place</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">program_config:</span> <span class="pre">Union[tt_lib.operations.primary.transformers.SoftmaxDefaultProgramConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.operations.primary.transformers.SoftmaxShardedMultiCoreProgramConfig]</span> <span class="pre">=</span> <span class="pre">&lt;tt_lib.operations.primary.transformers.SoftmaxDefaultProgramConfig</span> <span class="pre">object</span> <span class="pre">at</span> <span class="pre">0x7f7e10cdd0f0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.softmax_in_place" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a softmax operation on the last tensor dimension. Returns a reference to the input tensor modified in place.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.moreh_softmax">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">moreh_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tensor:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy:</span> <span class="pre">tt_lib.operations.primary.MorehSoftmaxOpParallelizationStrategy</span> <span class="pre">=</span> <span class="pre">&lt;MorehSoftmaxOpParallelizationStrategy.NONE:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.moreh_softmax" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a softmax operation. Returns an output tensor.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.moreh_softmax_backward">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">moreh_softmax_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_tensor:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_grad_tensor:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_grad_tensor:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy:</span> <span class="pre">tt_lib.operations.primary.MorehSoftmaxBackwardOpParallelizationStrategy</span> <span class="pre">=</span> <span class="pre">&lt;MorehSoftmaxBackwardOpParallelizationStrategy.NONE:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.moreh_softmax_backward" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a softmax backward operation. Returns an input grad tensor.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.moreh_softmin">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">moreh_softmin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tensor:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy:</span> <span class="pre">tt_lib.operations.primary.MorehSoftmaxOpParallelizationStrategy</span> <span class="pre">=</span> <span class="pre">&lt;MorehSoftmaxOpParallelizationStrategy.NONE:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.moreh_softmin" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a softmin operation. Returns an output tensor.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.moreh_softmin_backward">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">moreh_softmin_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_tensor:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_grad_tensor:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_grad_tensor:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy:</span> <span class="pre">tt_lib.operations.primary.MorehSoftmaxBackwardOpParallelizationStrategy</span> <span class="pre">=</span> <span class="pre">&lt;MorehSoftmaxBackwardOpParallelizationStrategy.NONE:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.moreh_softmin_backward" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a softmin backward operation. Returns an input grad tensor.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.moreh_logsoftmax">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">moreh_logsoftmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tensor:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy:</span> <span class="pre">tt_lib.operations.primary.MorehSoftmaxOpParallelizationStrategy</span> <span class="pre">=</span> <span class="pre">&lt;MorehSoftmaxOpParallelizationStrategy.NONE:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.moreh_logsoftmax" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a logsoftmax operation. Returns an output tensor.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.moreh_logsoftmax_backward">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">moreh_logsoftmax_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_tensor:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_grad_tensor:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_grad_tensor:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy:</span> <span class="pre">tt_lib.operations.primary.MorehSoftmaxBackwardOpParallelizationStrategy</span> <span class="pre">=</span> <span class="pre">&lt;MorehSoftmaxBackwardOpParallelizationStrategy.NONE:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.moreh_logsoftmax_backward" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a logsoftmax backward operation. Returns an input grad tensor.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.transformers.scale_mask_softmax_in_place">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.transformers.</span></span><span class="sig-name descname"><span class="pre">scale_mask_softmax_in_place</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale:</span> <span class="pre">Optional[float]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">program_config:</span> <span class="pre">Union[tt_lib.operations.primary.transformers.SoftmaxDefaultProgramConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.operations.primary.transformers.SoftmaxShardedMultiCoreProgramConfig]</span> <span class="pre">=</span> <span class="pre">&lt;tt_lib.operations.primary.transformers.SoftmaxDefaultProgramConfig</span> <span class="pre">object</span> <span class="pre">at</span> <span class="pre">0x7f7e10cc3530&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_causal_mask:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.transformers.scale_mask_softmax_in_place" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a fused scale-&gt;attention_mask-&gt;softmax operation. Returns a reference to the input tensor modified in place.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.moreh_mean">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">moreh_mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dims:</span> <span class="pre">List[int]</span> <span class="pre">=</span> <span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.moreh_mean" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs mean operation. Returns an output tensor.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.moreh_mean_backward">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">moreh_mean_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.moreh_mean_backward" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs mean backward operation. Returns an input_grad tensor.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.moreh_groupnorm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">moreh_groupnorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor,</span> <span class="pre">num_groups:</span> <span class="pre">int,</span> <span class="pre">eps:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">9.999999747378752e-06,</span> <span class="pre">gamma:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">beta:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">*,</span> <span class="pre">are_required_outputs:</span> <span class="pre">List[bool]</span> <span class="pre">=</span> <span class="pre">[True,</span> <span class="pre">False,</span> <span class="pre">False],</span> <span class="pre">output:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">mean:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">rstd:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt),</span> <span class="pre">mean_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt),</span> <span class="pre">rstd_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#tt_lib.operations.primary.moreh_groupnorm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a moreh_groupnorm operation.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.moreh_groupnorm_backward">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">moreh_groupnorm_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">output_grad:</span> <span class="pre">tt_lib.tensor.Tensor,</span> <span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor,</span> <span class="pre">mean:</span> <span class="pre">tt_lib.tensor.Tensor,</span> <span class="pre">rstd:</span> <span class="pre">tt_lib.tensor.Tensor,</span> <span class="pre">num_groups:</span> <span class="pre">int,</span> <span class="pre">*,</span> <span class="pre">are_required_outputs:</span> <span class="pre">List[bool]</span> <span class="pre">=</span> <span class="pre">[True,</span> <span class="pre">True,</span> <span class="pre">True],</span> <span class="pre">gamma:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">input_grad:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">gamma_grad:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">beta_grad:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">input_grad_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt),</span> <span class="pre">gamma_grad_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt),</span> <span class="pre">beta_grad_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#tt_lib.operations.primary.moreh_groupnorm_backward" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a moreh_groupnorm_backward operation.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.moreh_norm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">moreh_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">Optional[Union[int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">List[int]]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.moreh_norm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a moreh_norm operation.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.operations.primary.moreh_norm_backward">
<span class="sig-prename descclassname"><span class="pre">tt_lib.operations.primary.</span></span><span class="sig-name descname"><span class="pre">moreh_norm_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_grad:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_grad:</span> <span class="pre">Optional[tt_lib.tensor.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_grad_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.operations.primary.moreh_norm_backward" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs a moreh_norm_backward operation.</p>
</dd>
</dl>

</section>
<section id="enums">
<h3>Enums<a class="headerlink" href="#enums" title="Permalink to this heading"></a>
</h3>
<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.tensor.BcastOpMath">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">BcastOpMath</span></span><a class="headerlink" href="#tt_lib.tensor.BcastOpMath" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Members:</p>
<p>ADD</p>
<p>SUB</p>
<p>MUL</p>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.tensor.BcastOpDim">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">BcastOpDim</span></span><a class="headerlink" href="#tt_lib.tensor.BcastOpDim" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Members:</p>
<p>H</p>
<p>W</p>
<p>HW</p>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.tensor.ReduceOpMath">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">ReduceOpMath</span></span><a class="headerlink" href="#tt_lib.tensor.ReduceOpMath" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Members:</p>
<p>SUM</p>
<p>MAX</p>
<p>MIN</p>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.tensor.ReduceOpDim">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">ReduceOpDim</span></span><a class="headerlink" href="#tt_lib.tensor.ReduceOpDim" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Members:</p>
<p>H</p>
<p>W</p>
<p>HW</p>
</dd>
</dl>

</section>
<section id="tensor-elementwise-operations">
<h3>Tensor elementwise operations<a class="headerlink" href="#tensor-elementwise-operations" title="Permalink to this heading"></a>
</h3>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.div">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">div</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accurate_mode:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.div" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs the element-wise division of <code class="docutils literal notranslate"><span class="pre">input_a</span></code> by <code class="docutils literal notranslate"><span class="pre">input_b</span></code>.
If input_b is a non-zero tensor, then <code class="docutils literal notranslate"><span class="pre">accurate_mode</span></code> can be <code class="docutils literal notranslate"><span class="pre">false</span></code>,else set <code class="docutils literal notranslate"><span class="pre">accurate_mode</span></code> to <code class="docutils literal notranslate"><span class="pre">true</span></code></p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>Numerator Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Denominator Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>accurate_mode</p></td>
<td><p>Mode of Implementation</p></td>
<td><p>bool</p></td>
<td><p>default to false</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.div_no_nan">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">div_no_nan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.div_no_nan" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>div_no_nan(input_a: tt::tt_metal::Tensor, input_b: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Performs the element-wise div_no_nan on two tensors <code class="docutils literal notranslate"><span class="pre">input_a</span></code> and <code class="docutils literal notranslate"><span class="pre">input_b</span></code>, which returns 0 if <code class="docutils literal notranslate"><span class="pre">input_b</span></code> (denominator) is zero.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>Numerator Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Denominator Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>div_no_nan(input_a: tt::tt_metal::Tensor, value: float, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Performs the element-wise div_no_nan on  a tensor <code class="docutils literal notranslate"><span class="pre">input_a</span></code> and  a scalar <code class="docutils literal notranslate"><span class="pre">value</span></code>, which returns 0 if <code class="docutils literal notranslate"><span class="pre">value</span></code> (denominator) is zero.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>Numerator Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>value</p></td>
<td><p>Denominator value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.add_unary">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">add_unary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.add_unary" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>add_unary(scalar: float, input: tt_lib.tensor.Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt_lib.tensor.Tensor</p>
<blockquote>
<div>
<p>Perform an eltwise-binary add on one tensor and one scalar.</p>
<p>Both inputs, the tensor and scalar, must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>scalar</p></td>
<td><p>Scalar</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor to add</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>add_unary(input: tt_lib.tensor.Tensor, scalar: float, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt_lib.tensor.Tensor</p>
<blockquote>
<div>
<p>Perform an eltwise-binary add on one tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> and one scalar <code class="docutils literal notranslate"><span class="pre">scalar</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor add_unary is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>scalar</p></td>
<td><p>Scalar</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.sub_unary">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">sub_unary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.sub_unary" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>sub_unary(scalar: float, input: tt_lib.tensor.Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt_lib.tensor.Tensor</p>
<blockquote>
<div>
<p>Perform an eltwise-binary sub on one tensor and one scalar.</p>
<p>Both inputs, the tensor and scalar, must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>scalar</p></td>
<td><p>Scalar</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor to sub</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>sub_unary(input: tt_lib.tensor.Tensor, scalar: float, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt_lib.tensor.Tensor</p>
<blockquote>
<div>
<p>Perform an eltwise-binary sub on one tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> and one scalar <code class="docutils literal notranslate"><span class="pre">scalar</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor sub_unary is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>scalar</p></td>
<td><p>Scalar</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.mul_unary">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">mul_unary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.mul_unary" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>mul_unary(scalar: float, input: tt_lib.tensor.Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt_lib.tensor.Tensor</p>
<blockquote>
<div>
<p>Perform an eltwise-binary mul on one tensor and one scalar.</p>
<p>Both inputs, the tensor and scalar, must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>scalar</p></td>
<td><p>Scalar</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor to mul</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>mul_unary(input: tt_lib.tensor.Tensor, scalar: float, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt_lib.tensor.Tensor</p>
<blockquote>
<div>
<p>Perform an eltwise-binary mul on one tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> and one scalar <code class="docutils literal notranslate"><span class="pre">scalar</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor mul_unary is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>scalar</p></td>
<td><p>Scalar</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.div_unary">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">div_unary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.div_unary" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>div_unary(scalar: float, input: tt_lib.tensor.Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt_lib.tensor.Tensor</p>
<blockquote>
<div>
<p>Perform an eltwise-binary div on one tensor and one scalar.</p>
<p>Both inputs, the tensor and scalar, must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>scalar</p></td>
<td><p>Scalar</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor to div</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>div_unary(input: tt_lib.tensor.Tensor, scalar: float, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt_lib.tensor.Tensor</p>
<blockquote>
<div>
<p>Perform an eltwise-binary div on one tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> and one scalar <code class="docutils literal notranslate"><span class="pre">scalar</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor div_unary is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>scalar</p></td>
<td><p>Scalar</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.gelu">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">gelu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fast_and_approx:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.gelu" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the Gaussian Error Linear Units (GELU) function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor gelu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>fast_and_approx</p></td>
<td><p>Indicate true for approx and fast mode; false for accurate and slow mode</p></td>
<td><p>bool</p></td>
<td><p>default of true</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.relu">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">relu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.relu" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the rectified linear unit (ReLU) function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor relu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.relu6">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">relu6</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.relu6" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the relu6 activation on elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor relu6 is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.relu_min">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">relu_min</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lower_limit:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.relu_min" title="Permalink to this definition"></a>
</dt>
<dd>
<dl class="simple">
<dt>Returns tensor with the relu min of all of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>. This is equivalent</dt>
<dd>
<p>to relu_min[x] = max(x, <code class="docutils literal notranslate"><span class="pre">lower_limit</span></code>). It moves relu function down to carry out operation at minvalue
instead of the standard 0.</p>
</dd>
</dl>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor relu_min is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>lower_limit</p></td>
<td><p>min value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.relu_max">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">relu_max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper_limit:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.relu_max" title="Permalink to this definition"></a>
</dt>
<dd>
<dl class="simple">
<dt>Returns tensor with the relu max of all of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>. This is equivalent</dt>
<dd>
<p>to relu_max[x] = relu(min(x, <code class="docutils literal notranslate"><span class="pre">upper_limit</span></code>)). It caps off the input to a max value and a min value of 0.</p>
</dd>
</dl>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor relu_max is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>upper_limit</p></td>
<td><p>max value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.exp">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">exp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fast_and_approx:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.exp" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the exponential of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor exp is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>fast_and_approx</p></td>
<td><p>Indicate true for approx and fast mode; false for accurate and slow mode</p></td>
<td><p>bool</p></td>
<td><p>default of false</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.recip">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">recip</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.recip" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the reciprocal of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">recip</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor recip is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.sqrt">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">sqrt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.sqrt" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the square-root of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor sqrt is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.log">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.log" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the natural logarithm of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor log is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.log2">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">log2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.log2" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the base 2 logarithm of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor log2 is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.log10">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">log10</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.log10" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the base 10 logarithm of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor log10 is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.log1p">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">log1p</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.log1p" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the natural log of 1 added to all of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor log1p is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.tanh">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">tanh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.tanh" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the hyperbolic tangent of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor tanh is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.clip">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">clip</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.clip" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the clip function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> between limits <code class="docutils literal notranslate"><span class="pre">low</span></code> low and
the <code class="docutils literal notranslate"><span class="pre">high</span></code> high limits.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor hardtanh is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>low</p></td>
<td><p>Low value)</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>high</p></td>
<td><p>High value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.hardtanh">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">hardtanh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">-1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.hardtanh" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the hard tanh function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor hardtanh is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>low</p></td>
<td><p>Low value (PyTorch default)</p></td>
<td><p>float</p></td>
<td><p>default to -1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>high</p></td>
<td><p>High value (PyTorch default)</p></td>
<td><p>float</p></td>
<td><p>default to +1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.deg2rad">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">deg2rad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.deg2rad" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the deg2rad conversion of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor deg2rad is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.rad2deg">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">rad2deg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.rad2deg" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the rad2deg conversion of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor rad2deg is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.cbrt">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">cbrt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.cbrt" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the cbrt activation of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor cbrt is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.hypot">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">hypot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.hypot" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the hypot activation on elements of the input tensors <code class="docutils literal notranslate"><span class="pre">input_a</span></code> and <code class="docutils literal notranslate"><span class="pre">input_b</span></code>.</p>
<p>Both input tensors must be of equal shape.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>First tensor to hypot</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Second tensor to hypot</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.softplus">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">softplus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">20.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.softplus" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the softplus activation of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">{0}</span></code>.
If <code class="docutils literal notranslate"><span class="pre">input</span> <span class="pre">*</span> <span class="pre">beta</span></code> &gt; <code class="docutils literal notranslate"><span class="pre">threshold</span></code> returns input</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>Tensor softplus is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>beta</p></td>
<td><p>Beta value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>threshold</p></td>
<td><p>Threshold value</p></td>
<td><p>float</p></td>
<td><p>default to 20.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.mish">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">mish</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.mish" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the mish activation of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor mish is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.polyval">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">polyval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor,</span> <span class="pre">coeffs:</span> <span class="pre">List[float],</span> <span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.polyval" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the polyval of all of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> with coefficients <code class="docutils literal notranslate"><span class="pre">coeffs</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor polyval is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>coeffs</p></td>
<td><p>coefficients value with highest degree first</p></td>
<td><p>List of float</p></td>
<td><p>List size &gt; 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.sign">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">sign</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.sign" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the elementwise signum of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor sign is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.abs">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">abs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.abs" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with elementwise absolute value of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor abs is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.silu">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">silu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.silu" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the silu all of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor silu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.square">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">square</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.square" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the square of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor square is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.neg">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">neg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.neg" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the negate all of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor neg is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.add1">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">add1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.add1" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the addition of one with input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor add1 is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.mac">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">mac</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.mac" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>mac(input: tt::tt_metal::Tensor, tensor1: tt::tt_metal::Tensor, tensor2: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Returns tensor with the multiply and accumulation of all of elements of the input tensors <code class="docutils literal notranslate"><span class="pre">input,</span> <span class="pre">tensor1,</span> <span class="pre">tensor2</span></code>.
Output is <code class="docutils literal notranslate"><span class="pre">input</span> <span class="pre">x</span> <span class="pre">tensor1</span> <span class="pre">+</span> <span class="pre">tensor2</span></code> elementwise operator.
Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor mac is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>tensor1</p></td>
<td><p>Tensor to be multiplied</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>tensor2</p></td>
<td><p>Tensor to be added</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>mac(input: tt::tt_metal::Tensor, float1: float, float2: float, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Returns tensor with the multiply and accumulation of all of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input11</span> <span class="pre">with``float1,</span> <span class="pre">float2</span></code>.
Output is <code class="docutils literal notranslate"><span class="pre">tensor1</span> <span class="pre">x</span> <span class="pre">float1</span> <span class="pre">+</span> <span class="pre">float2</span></code> elementwise operator.
Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor mac is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>float1</p></td>
<td><p>Value to be multiplied</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>float2</p></td>
<td><p>Value to be added</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.sigmoid">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">sigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.sigmoid" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the sigmoid function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor sigmoid is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.sigmoid_accurate">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">sigmoid_accurate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.sigmoid_accurate" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the sigmoid_accurate function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor sigmoid_accurate is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.hardsigmoid">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">hardsigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.1666666716337204</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shift:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.hardsigmoid" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the hardsigmoid function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor hardsigmoid is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>scale</p></td>
<td><p>Scale value (PyTorch default)</p></td>
<td><p>float</p></td>
<td><p>default to 1.0/6.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>shift</p></td>
<td><p>Shift value (PyTorch default)</p></td>
<td><p>float</p></td>
<td><p>default to 0.5f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.swish">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">swish</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.swish" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the swish all of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor swish is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.hardswish">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">hardswish</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.1666666716337204</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shift:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.hardswish" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the hard swish function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor hardswish is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>scale</p></td>
<td><p>Scale value (PyTorch default)</p></td>
<td><p>float</p></td>
<td><p>default to 1.0/6.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>shift</p></td>
<td><p>Shift value (PyTorch default)</p></td>
<td><p>float</p></td>
<td><p>default to 0.5f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.leaky_relu">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">leaky_relu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slope:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.leaky_relu" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the leaky relu of all of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> with negative slope as <code class="docutils literal notranslate"><span class="pre">slope</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor leaky_relu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>slope</p></td>
<td><p>slope value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.softsign">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">softsign</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.softsign" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the softsign function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor softsign is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.softshrink">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">softshrink</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.softshrink" title="Permalink to this definition"></a>
</dt>
<dd>
<dl class="simple">
<dt>Applies the softshrink function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> between limits <code class="docutils literal notranslate"><span class="pre">-lambda</span></code> low and</dt>
<dd>
<p>the <code class="docutils literal notranslate"><span class="pre">+lambda</span></code> high limits.</p>
</dd>
</dl>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor softshrink is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>lambda</p></td>
<td><p>value limits (-lambda to +lambda)</p></td>
<td><p>float</p></td>
<td><p>&gt;= 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.hardshrink">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">hardshrink</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.hardshrink" title="Permalink to this definition"></a>
</dt>
<dd>
<dl class="simple">
<dt>Applies the hardshrink function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> between limits <code class="docutils literal notranslate"><span class="pre">-lambda</span></code> low and</dt>
<dd>
<p>the <code class="docutils literal notranslate"><span class="pre">+lambda</span></code> high limits.</p>
</dd>
</dl>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor hardshrink is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>lambda</p></td>
<td><p>value limits (-lambda to +lambda)</p></td>
<td><p>float</p></td>
<td><p>&gt;= 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.cos">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">cos</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.cos" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the cosine of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor cos is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.sin">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">sin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.sin" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the sine of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor sin is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.cosh">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">cosh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.cosh" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the hyperbolic cosine of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> in range [-9,9] with high accuracy.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor cosh is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.sinh">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">sinh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.sinh" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the hyperbolic sine of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> in range [-9,9] with high accuracy.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor sinh is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.acos">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">acos</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.acos" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the arccosine of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor acos is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.asin">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">asin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.asin" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the arcsine of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor asin is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.elu">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">elu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.elu" title="Permalink to this definition"></a>
</dt>
<dd>
<dl class="simple">
<dt>Returns tensor with the elu activation of all of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> and scale</dt>
<dd>
<p>factor alpha as <code class="docutils literal notranslate"><span class="pre">alpha</span></code>. ELU(x) = alpha*(exp(x) - 1) if x &lt; 0 else x.</p>
</dd>
</dl>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor elu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>alpha</p></td>
<td><p>alpha value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.exp2">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">exp2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.exp2" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the exp2 (2 power) of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor exp2 is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.tanhshrink">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">tanhshrink</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.tanhshrink" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies tanh on the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> and subtracted from the input tensor.</p>
<blockquote>
<div>
<p><code class="docutils literal notranslate"><span class="pre">tanhshrink(x)</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">-</span> <span class="pre">tanh(x)</span></code></p>
</div>
</blockquote>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor tanhshrink is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.heaviside">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">heaviside</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.heaviside" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the Heaviside step function of all of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> and value factor as <code class="docutils literal notranslate"><span class="pre">value</span></code>.</p>
<blockquote>
<div>
<p>HEAVISIDE(x) = 0 if x &lt; 0 , 1 if x &gt; 0 , else value.</p>
</div>
</blockquote>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor heaviside is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>value</p></td>
<td><p>value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.right_shift">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">right_shift</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shift_amt:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.right_shift" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes right shift of input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> by <code class="docutils literal notranslate"><span class="pre">shift_amt</span></code> bits. <code class="docutils literal notranslate"><span class="pre">shift_amt</span></code> range must be [0, 31]. Support provided only for Wormhole_B0.</p>
<p>Input tensor must have INT32 data type.</p>
<p>Output tensor will have INT32 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>shift_amt</p></td>
<td><p>Number of shift bits</p></td>
<td><p>int</p></td>
<td><p>[0, 31]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.left_shift">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">left_shift</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shift_amt:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.left_shift" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes left shift of input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> by <code class="docutils literal notranslate"><span class="pre">shift_amt</span></code> bits. <code class="docutils literal notranslate"><span class="pre">shift_amt</span></code> range must be [0, 31]. Support provided only for Wormhole_B0.</p>
<p>Input tensor must have INT32 data type.</p>
<p>Output tensor will have INT32 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>shift_amt</p></td>
<td><p>Number of shift bits</p></td>
<td><p>int</p></td>
<td><p>[0, 31]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.atan">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">atan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.atan" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the arctan of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor atan is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.atanh">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">atanh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.atanh" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the inverse hyperbolic tangent of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor atanh is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.atan2">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">atan2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.atan2" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the atan2 activation on elements of the input tensors <code class="docutils literal notranslate"><span class="pre">input_a</span></code> and <code class="docutils literal notranslate"><span class="pre">input_b</span></code>.</p>
<p>Both input tensors must be of equal shape.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>First tensor to atan2</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Second tensor to atan2</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.logical_xor">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">logical_xor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.logical_xor" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs eltwise-binary logical_xor (<code class="docutils literal notranslate"><span class="pre">input_a</span> <span class="pre">^</span> <span class="pre">input_b</span></code>) on two tensors.</p>
<p>Both input tensors must be of equal shape.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>First tensor to logical_xor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Second tensor to logical_xor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.logical_xori">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">logical_xori</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">immediate:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.logical_xori" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Perform an eltwise logical XOR (<code class="docutils literal notranslate"><span class="pre">input</span> <span class="pre">^</span> <span class="pre">immediate</span></code>) on input tensor and immediate value.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor logical_xori is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>immediate</p></td>
<td><p>Scalar</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.logical_not_unary">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">logical_not_unary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.logical_not_unary" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the logical not of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor logical_not_unary is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.subalpha">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">subalpha</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.subalpha" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Subtracts <code class="docutils literal notranslate"><span class="pre">input_b</span></code>, scaled by <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, from <code class="docutils literal notranslate"><span class="pre">input_a</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>Tensor subalpha is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>alpha</p></td>
<td><p>Alpha value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.celu">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">celu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.celu" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the celu function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor celu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>alpha</p></td>
<td><p>alpha value (PyTorch default)</p></td>
<td><p>float</p></td>
<td><p>default to 1.0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.addalpha">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">addalpha</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.addalpha" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>addalpha(input_a: tt::tt_metal::Tensor, input_b: tt::tt_metal::Tensor, alpha: float = 1.0, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt), output_tensor: Optional[tt::tt_metal::Tensor] = None) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Add <code class="docutils literal notranslate"><span class="pre">input_b</span></code>, scaled by <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, from <code class="docutils literal notranslate"><span class="pre">input_a</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>Tensor addalpha is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>alpha</p></td>
<td><p>Alpha value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_tensor</p></td>
<td><p>optional output tensor</p></td>
<td><p>Tensor</p></td>
<td><p>default is None</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>addalpha(cq_id: int = 0, input_a: tt::tt_metal::Tensor, input_b: tt::tt_metal::Tensor, alpha: float = 1.0, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt), output_tensor: Optional[tt::tt_metal::Tensor] = None) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Add <code class="docutils literal notranslate"><span class="pre">input_b</span></code>, scaled by <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, from <code class="docutils literal notranslate"><span class="pre">input_a</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>cq_id</p></td>
<td><p>Command queue id</p></td>
<td><p>integer</p></td>
<td><p>default to 0</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>input_a</p></td>
<td><p>Tensor addalpha is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input_b</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>alpha</p></td>
<td><p>Alpha value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_tensor</p></td>
<td><p>optional output tensor</p></td>
<td><p>Tensor</p></td>
<td><p>default is None</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.bias_gelu_unary">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">bias_gelu_unary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.bias_gelu_unary" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the Gelu activation function to the elements of the biased <code class="docutils literal notranslate"><span class="pre">bias</span></code> input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor bias_gelu_unary is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>bias</p></td>
<td><p>value limits (-bias to +bias)</p></td>
<td><p>float</p></td>
<td><p>&gt;= 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.isfinite">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">isfinite</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.isfinite" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns boolean tensor that is True where input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>, is finite and False elsewhere.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor isfinite is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.isinf">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">isinf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.isinf" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns boolean tensor that is True where input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>, is infinite and False elsewhere.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor isinf is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.isposinf">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">isposinf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.isposinf" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns each element of input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>, is positive infinity or not.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor isposinf is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.isneginf">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">isneginf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.isneginf" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns each element of input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>, is negative infinity or not.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor isneginf is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.isnan">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">isnan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.isnan" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns boolean tensor that is True where tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>, is NaN and False elsewhere.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor isnan is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.logit">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">logit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.logit" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a tensor that is a logit  of input tensor with shape <code class="docutils literal notranslate"><span class="pre">[W,</span> <span class="pre">Z,</span> <span class="pre">Y,</span> <span class="pre">X]</span></code> along clamp <code class="docutils literal notranslate"><span class="pre">eps</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor logit is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>eps</p></td>
<td><p>dimension to logit along</p></td>
<td><p>int</p></td>
<td><p>0, 1, 2, or 3</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.lgamma">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">lgamma</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.lgamma" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the natural logarithm of the absolute value of the gamma function on the  <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor for inputs greater than 0.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor lgamma is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.logical_andi">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">logical_andi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">immediate:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.logical_andi" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Perform an eltwise logical AND (<code class="docutils literal notranslate"><span class="pre">input</span> <span class="pre">&amp;&amp;</span> <span class="pre">immediate</span></code>) on input tensor and immediate value.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor logical_andi is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>immediate</p></td>
<td><p>Scalar</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.erfinv">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">erfinv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.erfinv" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes inverse error function for all elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> in the range (-1,1) .</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor erfinv is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.multigammaln">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">multigammaln</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.multigammaln" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the multivariate log-gamma function with dimension 4 element-wise on the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> for inputs greater than 1.5f. mvlgamma is refered as multigammaln.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor multigammaln is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.assign">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">assign</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.assign" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>assign(input: tt_lib.tensor.Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt), output_dtype: Optional[tt_lib.tensor.DataType] = None) -&gt; tt_lib.tensor.Tensor</p>
<blockquote>
<div>
<blockquote>
<div>
<p>Returns a new tensor which is a new copy of input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
</div>
</blockquote>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor assign is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_dtype</p></td>
<td><p>Output tensor data type</p></td>
<td><p>DataType</p></td>
<td><p>Default is None (Use input dtype)</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>assign(input_a: tt_lib.tensor.Tensor, input_b: tt_lib.tensor.Tensor) -&gt; tt_lib.tensor.Tensor</p>
<blockquote>
<div>
<p>Copies input tensor <code class="docutils literal notranslate"><span class="pre">arg0</span></code> (given by input_a) to <code class="docutils literal notranslate"><span class="pre">arg1</span></code> (given by input_b) if their
shapes and memory layouts match, and returns input_b tensor.</p>
<p>Input tensors can be of any data type.</p>
<p>Output tensor will be of same data type as Input tensor.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>Tensor assign is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>assign(queue_id: int = 0, input_a: tt_lib.tensor.Tensor, input_b: tt_lib.tensor.Tensor) -&gt; tt_lib.tensor.Tensor</p>
<blockquote>
<div>
<p>Copies input tensor <code class="docutils literal notranslate"><span class="pre">arg0</span></code> (given by input_a) to <code class="docutils literal notranslate"><span class="pre">arg1</span></code> (given by input_b) if their
shapes and memory layouts match, and returns input_b tensor.</p>
<p>Input tensors can be of any data type.</p>
<p>Output tensor will be of same data type as Input tensor.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>queue_id</p></td>
<td><p>queue_id</p></td>
<td><p>uint8_t</p></td>
<td><p>Default is 0</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>input_a</p></td>
<td><p>Tensor assign is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input_b</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.isclose">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">isclose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rtol:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">9.999999747378752e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">9.99999993922529e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equal_nan:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.isclose" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the isclose function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input_a</span></code> and <code class="docutils literal notranslate"><span class="pre">input_b</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<p>if equal_nan True, then two NaN s will be considered equal, else not equal.</p>
<p>isclose(input_a, input_b, rtol, atol) = ∣input_a−input_B∣ ≤ atol+rtol×∣input_b∣.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>Tensor isclose is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Tensor isclose is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>rtol</p></td>
<td><p>rtol value</p></td>
<td><p>float</p></td>
<td><p>default to 1e-05f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>atol</p></td>
<td><p>atol value</p></td>
<td><p>float</p></td>
<td><p>default to 1e-08f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>equal_nan</p></td>
<td><p>equal_nan value</p></td>
<td><p>bool</p></td>
<td><p>default to false</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.i0">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">i0</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.i0" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the zeroth order modified Bessel function of the first kind applied on the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>, for the input range -10 to 10.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor i0 is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.digamma">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">digamma</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.digamma" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the logarithmic derivative of the gamma function on input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> for the input range 1 to inf.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor digamma is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.tan">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">tan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.tan" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the tangent of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> for the range [-1.45, 1.45].</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor tan is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.logical_ori">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">logical_ori</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">immediate:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.logical_ori" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Perform an eltwise logical OR (<code class="docutils literal notranslate"><span class="pre">input</span> <span class="pre">||</span> <span class="pre">immediate</span></code>) on input tensor and immediate value.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor logical_ori is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>immediate</p></td>
<td><p>Scalar</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.polygamma">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">polygamma</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.polygamma" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a tensor that is a polygamma of input tensor where the range supports from 1 to 10 with shape <code class="docutils literal notranslate"><span class="pre">[W,</span> <span class="pre">Z,</span> <span class="pre">Y,</span> <span class="pre">X]</span></code> along n <code class="docutils literal notranslate"><span class="pre">n</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor polygamma is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>n</p></td>
<td><p>the order of the polygamma along</p></td>
<td><p>int</p></td>
<td><p>1 to 10</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.floor">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">floor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.floor" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies floor to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>. Support provided only for Wormhole_B0.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor floor is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.trunc">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">trunc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.trunc" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs the element-wise trunc operation on <code class="docutils literal notranslate"><span class="pre">input</span></code>. Support provided only for Wormhole_B0.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.round">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">round</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decimals:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.round" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs the element-wise round operation on <code class="docutils literal notranslate"><span class="pre">input</span></code> , to the given number of <code class="docutils literal notranslate"><span class="pre">decimals</span></code> places. Support provided only for Wormhole_B0 and <code class="docutils literal notranslate"><span class="pre">decimals</span> <span class="pre">=</span> <span class="pre">0</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>decimals</p></td>
<td><p>Number of decimal places to round to</p></td>
<td><p>int</p></td>
<td><p>default to 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.floor_div">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">floor_div</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.floor_div" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>floor_div(input_a: tt::tt_metal::Tensor, input_b: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Performs the element-wise floor division of <code class="docutils literal notranslate"><span class="pre">input_a</span></code> by <code class="docutils literal notranslate"><span class="pre">input_b</span></code>. Support provided only for Wormhole_B0.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>Numerator Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Denominator Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>floor_div(input: tt::tt_metal::Tensor, value: float, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Performs the element-wise floor_div on  a tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> and  a scalar <code class="docutils literal notranslate"><span class="pre">value</span></code>. Support provided only for Wormhole_B0.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Numerator Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>value</p></td>
<td><p>Denominator value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

</section>
<section id="tensor-relational-operations">
<h3>Tensor relational operations<a class="headerlink" href="#tensor-relational-operations" title="Permalink to this heading"></a>
</h3>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.gtz">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">gtz</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.gtz" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the greater than zero of all of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor gtz is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.gez">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">gez</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.gez" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the greater than equal zero of all of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor gez is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.ltz">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">ltz</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.ltz" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the less than zero of all of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor ltz is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.lez">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">lez</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.lez" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the less than equal zero of all of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor lez is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.eqz">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">eqz</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.eqz" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the result of equal to zero of all of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor eqz is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.nez">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">nez</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.nez" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the not equal zero of all of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor nez is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unary_ne">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unary_ne</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.unary_ne" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Perform an eltwise-unary not-equal (<code class="docutils literal notranslate"><span class="pre">input</span> <span class="pre">!=</span> <span class="pre">value</span></code>) on input tensor.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor unary_ne is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>value</p></td>
<td><p>value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unary_gt">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unary_gt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.unary_gt" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Perform an eltwise-unary greater-than (<code class="docutils literal notranslate"><span class="pre">input</span> <span class="pre">&gt;</span> <span class="pre">value</span></code>) on input tensor.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor unary_gt is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>value</p></td>
<td><p>value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unary_lt">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unary_lt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.unary_lt" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Perform an eltwise-unary less-than (<code class="docutils literal notranslate"><span class="pre">input</span> <span class="pre">&lt;</span> <span class="pre">value</span></code>) on input tensor.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor unary_lt is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>value</p></td>
<td><p>value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

</section>
<section id="tensor-ternary-operations">
<h3>Tensor ternary operations<a class="headerlink" href="#tensor-ternary-operations" title="Permalink to this heading"></a>
</h3>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.where">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">where</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.where" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>where(predicate: tt::tt_metal::Tensor, true_value: tt::tt_metal::Tensor, false_value: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt), output_tensor: Optional[tt::tt_metal::Tensor] = None) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Perform an ternary where operation on two tensors based on third @predicate.</p>
<p>where(predicate, true_value, false_value) implements (predicate) ? true_value : false_value.</p>
<p>All three input tensors must have BFLOAT16 data type, and be of equal shape.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>predicate</p></td>
<td><p>Predicate Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>true_value</p></td>
<td><p>True Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>false_value</p></td>
<td><p>False Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_tensor</p></td>
<td><p>optional output tensor</p></td>
<td><p>Tensor</p></td>
<td><p>default is None</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>where(predicate: tt::tt_metal::Tensor, true_value: float, false_value: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt), output_tensor: Optional[tt::tt_metal::Tensor] = None) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Perform an ternary where operation on two tensors based on third @predicate.</p>
<p>where(predicate, true_value, false_value) implements (predicate) ? true_value : false_value.</p>
<p>All three input tensors must have BFLOAT16 data type, and be of equal shape.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>predicate</p></td>
<td><p>Predicate Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>true_value</p></td>
<td><p>float</p></td>
<td><p>float</p></td>
<td><p>float scalar</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>false_value</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_tensor</p></td>
<td><p>optional output tensor</p></td>
<td><p>Tensor</p></td>
<td><p>default is None</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>where(predicate: tt::tt_metal::Tensor, true_value: tt::tt_metal::Tensor, false_value: float, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt), output_tensor: Optional[tt::tt_metal::Tensor] = None) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Perform an ternary where operation on two tensors based on third @predicate.</p>
<p>where(predicate, true_value, false_value) implements (predicate) ? true_value : false_value.</p>
<p>All three input tensors must have BFLOAT16 data type, and be of equal shape.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>predicate</p></td>
<td><p>Predicate Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>true_value</p></td>
<td><p>True Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>false_value</p></td>
<td><p>float</p></td>
<td><p>float</p></td>
<td><p>float scalar</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_tensor</p></td>
<td><p>optional output tensor</p></td>
<td><p>Tensor</p></td>
<td><p>default is None</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>where(predicate: tt::tt_metal::Tensor, true_value: float, false_value: float, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt), output_tensor: Optional[tt::tt_metal::Tensor] = None) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Perform an ternary where operation on two tensors based on third @predicate.</p>
<p>where(predicate, true_value, false_value) implements (predicate) ? true_value : false_value.</p>
<p>All three input tensors must have BFLOAT16 data type, and be of equal shape.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>predicate</p></td>
<td><p>Predicate Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>true_value</p></td>
<td><p>float</p></td>
<td><p>float</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>false_value</p></td>
<td><p>float</p></td>
<td><p>float</p></td>
<td><p>float scalar</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_tensor</p></td>
<td><p>optional output tensor</p></td>
<td><p>Tensor</p></td>
<td><p>default is None</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.threshold">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">threshold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.threshold" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the threshold activation on elements of the input tensors <code class="docutils literal notranslate"><span class="pre">arg0</span></code> at threshold <code class="docutils literal notranslate"><span class="pre">threshold</span></code>,
and value <code class="docutils literal notranslate"><span class="pre">value</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor threshold is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>threshold</p></td>
<td><p>Value to threshold at</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>value</p></td>
<td><p>Value to replace with</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

</section>
<section id="tensor-matrix-math-operations">
<h3>Tensor matrix math operations<a class="headerlink" href="#tensor-matrix-math-operations" title="Permalink to this heading"></a>
</h3>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.matmul">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">matmul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">untilize_out:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.matmul" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Perform a non-batched matrix multiplication <code class="docutils literal notranslate"><span class="pre">arg0</span> <span class="pre">x</span> <span class="pre">arg1</span></code> with two tensors.</p>
<p>Both input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>First tensor to multiply</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [1, 1, Y, S]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Second tensor to multiply</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [1, 1, S, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.bmm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">bmm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">untilize_out:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.bmm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Perform a batched matmul <code class="docutils literal notranslate"><span class="pre">arg0</span> <span class="pre">x</span> <span class="pre">arg1</span></code> with two tensors, where batch dims match.</p>
<p>Both input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>First tensor to multiply</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, S]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Second tensor to multiply</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, S, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<p>Tensor manipulation operations
-=============================</p>
<p>These operations change the tensor shape in some way, giving it new dimensions
but in general retaining the data.</p>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.reshape">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">reshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.reshape" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a tensor with the new shape of <code class="docutils literal notranslate"><span class="pre">[W,</span> <span class="pre">Z,</span> <span class="pre">Y,</span> <span class="pre">X]</span></code>. The X dimension of input and output tensor must have same size.</p>
<p>Input tensor must be on host device, in TILE layout, and have BFLOAT16 data type.</p>
<p>Output tensor will be on host device, in TILE layout, and have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>W</p></td>
<td><p>W dim of output tensor</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>Z</p></td>
<td><p>Z dim of output tensor</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>Y</p></td>
<td><p>Y dim of output tensor</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>X</p></td>
<td><p>X dim of output tensor</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.transpose">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">transpose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim0:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim1:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.transpose" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a tensor that is a transposed version of input tensor with shape <code class="docutils literal notranslate"><span class="pre">[W,</span> <span class="pre">Z,</span> <span class="pre">Y,</span> <span class="pre">X]</span></code>, where dimensions <code class="docutils literal notranslate"><span class="pre">arg1</span></code> and <code class="docutils literal notranslate"><span class="pre">arg2</span></code> are swapped.</p>
<p>Input tensor must have BFLOAT16 data type. Second and third input specify the dimensions of tensor to be transposed.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim0</p></td>
<td><p>dimension to transpose</p></td>
<td><p>int</p></td>
<td><p>Index within input tensor rank</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>dim1</p></td>
<td><p>dimension to transpose</p></td>
<td><p>int</p></td>
<td><p>Index within input tensor rank</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.permute">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">permute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor,</span> <span class="pre">dims:</span> <span class="pre">List[int],</span> <span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.permute" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a tensor that is input tensor <code class="docutils literal notranslate"><span class="pre">arg0</span></code> with its dimensions permuted to new order <code class="docutils literal notranslate"><span class="pre">dims</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dims</p></td>
<td><p>The desired ordering of dimensions</p></td>
<td><p>List[int]</p></td>
<td><p>All indices within input tensor rank</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.tilize">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">tilize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dtype:</span> <span class="pre">Optional[tt_lib.tensor.DataType]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_multicore:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.tilize" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Changes data layout of input tensor to TILE.</p>
<p>Input tensor must be on TT accelerator device, in ROW_MAJOR layout, and have BFLOAT16 data type.</p>
<p>Output tensor will be on TT accelerator device, in TILE layout, and have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X] where Y%32=0 and X%32=0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_dtype</p></td>
<td><p>Output tensor data type</p></td>
<td><p>DataType</p></td>
<td><p>Default is None (Use input dtype)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>use_multicore</p></td>
<td><p>Whether to use multi-core parallelization</p></td>
<td><p>bool</p></td>
<td><p>Default is false</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.untilize">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">untilize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_multicore:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_pack_untilize:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.untilize" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Changes data layout of input tensor to ROW_MAJOR.</p>
<p>Input tensor must be on TT accelerator device, in TILE, and have BFLOAT16 data type.</p>
<p>Output tensor will be on TT accelerator device, in ROW_MAJOR layout, and have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X] where Y%32=0 and X%32=0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>use_multicore</p></td>
<td><p>Whether to use multi-core parallelization</p></td>
<td><p>bool</p></td>
<td><p>Default is true</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>use_pack_untilize</p></td>
<td><p>Whether to use pack untilize</p></td>
<td><p>bool</p></td>
<td><p>Default is true</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.tilize_with_val_padding">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">tilize_with_val_padding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tensor_shape:</span> <span class="pre">tt_lib.tensor.Shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_value:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dtype:</span> <span class="pre">Optional[tt_lib.tensor.DataType]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_multicore:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.tilize_with_val_padding" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Tilizes a given tensor across memory on device. Pads to specified shape before tilizing.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_tensor_shape</p></td>
<td><p>Shape of output tensor</p></td>
<td><p>List[int[4]]</p></td>
<td><p>Shape [W, Z, Y, X] where Y%32=0 and X%32=0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>pad_value</p></td>
<td><p>Value to pad input tensor</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_dtype</p></td>
<td><p>Output tensor data type</p></td>
<td><p>DataType</p></td>
<td><p>Default is None (Use input dtype)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>use_multicore</p></td>
<td><p>Whether to use multi-core parallelization</p></td>
<td><p>bool</p></td>
<td><p>Default is false</p></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.untilize_with_unpadding">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">untilize_with_unpadding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tensor_end:</span> <span class="pre">tt_lib.tensor.Shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_multicore:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_pack_untilize:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.untilize_with_unpadding" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Changes data layout of input tensor to ROW_MAJOR and unpads/removes elements from the tensor.</p>
<p>Input tensor must be on TT accelerator device, in TILE, and have BFLOAT16 data type.</p>
<p>Output tensor will be on TT accelerator device, in ROW_MAJOR layout, and have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X] where Y%32=0 and X%32=0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_tensor_end</p></td>
<td><p>End indices of input tensor in output tensor</p></td>
<td><p>List[int[4]]</p></td>
<td><p>Values along each dim must be &lt; input_tensor_shape[i]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>use_multicore</p></td>
<td><p>Whether to use multi-core parallelization</p></td>
<td><p>bool</p></td>
<td><p>Default is false</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>use_pack_untilize</p></td>
<td><p>Whether to use pack untilize</p></td>
<td><p>bool</p></td>
<td><p>Default is true</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.tilize_with_zero_padding">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">tilize_with_zero_padding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dtype:</span> <span class="pre">Optional[tt_lib.tensor.DataType]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_multicore:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.tilize_with_zero_padding" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Tilizes a given tensor across memory on device. Pads zeroes height-wise and width-wise if required.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_dtype</p></td>
<td><p>Output tensor data type</p></td>
<td><p>DataType</p></td>
<td><p>Default is None (Use input dtype)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>use_multicore</p></td>
<td><p>Whether to use multi-core parallelization</p></td>
<td><p>bool</p></td>
<td><p>Default is false</p></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.pad">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">pad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tensor_shape:</span> <span class="pre">tt_lib.tensor.Shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_tensor_start:</span> <span class="pre">tt_lib.tensor.Shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_value:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_multicore:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.pad" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Pad TT Tensor with given pad value <code class="docutils literal notranslate"><span class="pre">arg2</span></code>.</p>
<p>The input tensor must be in ROW_MAJOR or TILE layout.</p>
<p>Returns an output tensor that contains the input tensor at the given input tensor start indices <code class="docutils literal notranslate"><span class="pre">arg3</span></code> and the padded value everywhere else.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_tensor_shape</p></td>
<td><p>Shape of output tensor</p></td>
<td><p>List[int[4]]</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input_tensor_start</p></td>
<td><p>Start indices to place input tensor in output tensor</p></td>
<td><p>List[int[4]]</p></td>
<td><p>Must be all 0s</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>pad_value</p></td>
<td><p>Value to pad input tensor</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unpad">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unpad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tensor_start:</span> <span class="pre">tt_lib.tensor.Shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tensor_end:</span> <span class="pre">tt_lib.tensor.Shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.unpad" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Unpad TT Tensor.</p>
<p>Returns an output tensor from output tensor start indices <code class="docutils literal notranslate"><span class="pre">arg1</span></code> to output tensor end indices <code class="docutils literal notranslate"><span class="pre">arg2</span></code> (inclusive) of the input tensor.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_tensor_start</p></td>
<td><p>Start indices of input tensor</p></td>
<td><p>List[int[tensor rank]]</p></td>
<td><p>Values along each dim must be &lt; input_tensor_shape[i]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_tensor_end</p></td>
<td><p>End indices of input tensor in output tensor</p></td>
<td><p>List[int[tensor rank]]</p></td>
<td><p>Values along each dim must be &lt; input_tensor_shape[i]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>pad_value</p></td>
<td><p>Value to pad input tensor</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.clone">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">clone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dtype:</span> <span class="pre">Optional[tt_lib.tensor.DataType]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.clone" title="Permalink to this definition"></a>
</dt>
<dd>
<blockquote>
<div>
<p>Returns a new tensor which is a new copy of input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
</div>
</blockquote>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor clone is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_dtype</p></td>
<td><p>Output tensor data type</p></td>
<td><p>DataType</p></td>
<td><p>Default is None (Use input dtype)</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.typecast">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">typecast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensors:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype:</span> <span class="pre">tt_lib.tensor.DataType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.typecast" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor which is a typecast of input tensor with new datatype``{0}``.</p>
<p>Input tensors must be on device, in ROW MAJOR or TILE layout, and have matching data type.</p>
<p>Datatype must be one ofthe following types BFLOAT16,BFLOAT8_B,BFLOAT4_B,UINT32,INT32 and UINT16.</p>
<p>Output tensor will be on device, in same layout, and have the given data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_tensors</p></td>
<td><p>Input tensors to typecast</p></td>
<td><p>List of Tensors</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dtype</p></td>
<td><p>datatype of typecast</p></td>
<td><p>Datatype</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.copy">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_a</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.copy" title="Permalink to this definition"></a>
</dt>
<dd>
<blockquote>
<div>
<p>Copies the elements from <code class="docutils literal notranslate"><span class="pre">input_a</span></code> into <code class="docutils literal notranslate"><span class="pre">input_b</span></code>. <code class="docutils literal notranslate"><span class="pre">input_b</span></code> is modified in place.</p>
</div>
</blockquote>
<p>Both input tensors must be of equal shape.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>First tensor to copy</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Second tensor to copy</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

</section>
<section id="tensor-creation-operations">
<h3>Tensor creation operations<a class="headerlink" href="#tensor-creation-operations" title="Permalink to this heading"></a>
</h3>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.arange">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">arange</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device:</span> <span class="pre">tt_lib.device.Device</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.arange" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new 1D tensor with the incremented values in size specified by inputs <code class="docutils literal notranslate"><span class="pre">start</span></code>, <code class="docutils literal notranslate"><span class="pre">end</span></code> and <code class="docutils literal notranslate"><span class="pre">step</span></code>.</p>
<p>Inpute scalars are integers specifying start, end, and step sizes.
Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>start</p></td>
<td><p>Start</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>end</p></td>
<td><p>End</p></td>
<td><p>int</p></td>
<td><p>&gt; start</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>step</p></td>
<td><p>Step</p></td>
<td><p>int</p></td>
<td><p>&gt; 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>device</p></td>
<td><p>Device tensor is placed on</p></td>
<td><p>Device</p></td>
<td><p>default is None (on host)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.full">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">full</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape:</span> <span class="pre">tt_lib.tensor.Shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill_value:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_type:</span> <span class="pre">tt_lib.tensor.DataType</span> <span class="pre">=</span> <span class="pre">&lt;DataType.BFLOAT16:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout:</span> <span class="pre">tt_lib.tensor.Layout</span> <span class="pre">=</span> <span class="pre">&lt;Layout.ROW_MAJOR:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device:</span> <span class="pre">tt_lib.device.Device</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.full" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor filled with the scalar value in shape specified by input <code class="docutils literal notranslate"><span class="pre">shape</span></code>.</p>
<p>Input shape is specified as a list of 4 integer elements</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>shape</p></td>
<td><p>Shape vector</p></td>
<td><p>Vector&lt;int&gt;</p></td>
<td><p>[W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>fill_value</p></td>
<td><p>Fill value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>data_type</p></td>
<td><p>Tensor data type</p></td>
<td><p>DataType</p></td>
<td><p>default is BFLOAT16</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>layout</p></td>
<td><p>Tensor layout</p></td>
<td><p>Layout</p></td>
<td><p>default is ROW_MAJOR</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>device</p></td>
<td><p>Device tensor is placed on</p></td>
<td><p>Device</p></td>
<td><p>default is None (on host)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.ones">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">ones</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape:</span> <span class="pre">tt_lib.tensor.Shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_type:</span> <span class="pre">tt_lib.tensor.DataType</span> <span class="pre">=</span> <span class="pre">&lt;DataType.BFLOAT16:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout:</span> <span class="pre">tt_lib.tensor.Layout</span> <span class="pre">=</span> <span class="pre">&lt;Layout.ROW_MAJOR:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device:</span> <span class="pre">tt_lib.device.Device</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.ones" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor filled with ones in shape specified by input <code class="docutils literal notranslate"><span class="pre">shape</span></code>.</p>
<p>Input shape is specified as a list of 4 integer elements</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>shape</p></td>
<td><p>Shape vector</p></td>
<td><p>Vector&lt;int&gt;</p></td>
<td><p>[W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>data_type</p></td>
<td><p>Tensor data type</p></td>
<td><p>DataType</p></td>
<td><p>default is BFLOAT16</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>layout</p></td>
<td><p>Tensor layout</p></td>
<td><p>Layout</p></td>
<td><p>default is ROW_MAJOR</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>device</p></td>
<td><p>Device tensor is placed on</p></td>
<td><p>Device</p></td>
<td><p>default is None (on host)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.ones_like">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">ones_like</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.ones_like" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor filled with ones shaped like reference tensor <code class="docutils literal notranslate"><span class="pre">arg0</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Reference Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.zeros">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">zeros</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape:</span> <span class="pre">tt_lib.tensor.Shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_type:</span> <span class="pre">tt_lib.tensor.DataType</span> <span class="pre">=</span> <span class="pre">&lt;DataType.BFLOAT16:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout:</span> <span class="pre">tt_lib.tensor.Layout</span> <span class="pre">=</span> <span class="pre">&lt;Layout.ROW_MAJOR:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device:</span> <span class="pre">tt_lib.device.Device</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.zeros" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor filled with zeros in shape specified by input <code class="docutils literal notranslate"><span class="pre">shape</span></code>.</p>
<p>Input shape is specified as a list of 4 integer elements</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>shape</p></td>
<td><p>Shape vector</p></td>
<td><p>Vector&lt;int&gt;</p></td>
<td><p>[W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>data_type</p></td>
<td><p>Tensor data type</p></td>
<td><p>DataType</p></td>
<td><p>default is BFLOAT16</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>layout</p></td>
<td><p>Tensor layout</p></td>
<td><p>Layout</p></td>
<td><p>default is ROW_MAJOR</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>device</p></td>
<td><p>Device tensor is placed on</p></td>
<td><p>Device</p></td>
<td><p>default is None (on host)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.zeros_like">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">zeros_like</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.zeros_like" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor filled with zeros shaped like reference tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Reference Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.full_like">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">full_like</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill_value:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.full_like" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor filled with the scalar value shaped like reference tensor <code class="docutils literal notranslate"><span class="pre">arg0</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Reference Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>fill_value</p></td>
<td><p>Fill value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.split_last_dim_two_chunks_tiled">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">split_last_dim_two_chunks_tiled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.split_last_dim_two_chunks_tiled" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Splits a tensor’s last dimension in two equal sized chunks. This assumes the last dim is tile sized.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W0, Z0, Y0, X0]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.empty">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape:</span> <span class="pre">tt_lib.tensor.Shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_type:</span> <span class="pre">tt_lib.tensor.DataType</span> <span class="pre">=</span> <span class="pre">&lt;DataType.BFLOAT16:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layout:</span> <span class="pre">tt_lib.tensor.Layout</span> <span class="pre">=</span> <span class="pre">&lt;Layout.ROW_MAJOR:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device:</span> <span class="pre">tt_lib.device.Device</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.empty" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new empty tensor (on device) in shape specified by input <code class="docutils literal notranslate"><span class="pre">shape</span></code>.</p>
<p>Input shape is specified as a list of 4 integer elements</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>shape</p></td>
<td><p>Shape vector</p></td>
<td><p>Vector&lt;int&gt;</p></td>
<td><p>[W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>data_type</p></td>
<td><p>Tensor data type</p></td>
<td><p>DataType</p></td>
<td><p>default is BFLOAT16</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>layout</p></td>
<td><p>Tensor layout</p></td>
<td><p>Layout</p></td>
<td><p>default is ROW_MAJOR</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>device</p></td>
<td><p>Device tensor is placed on</p></td>
<td><p>Device</p></td>
<td><p>default is None (on host)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.tril">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">tril</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diag:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.tril" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with lower triangular elements of input with rest being zero.</p>
<p>Input tensor will have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>tensor input to be lower triangular processed</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>diag</p></td>
<td><p>diagonal to be chosen</p></td>
<td><p>int32_t</p></td>
<td><p>-dim to +dim (default to 0)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.triu">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">triu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diag:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.triu" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with upper triangular elements of input with rest being zero.</p>
<p>Input tensor will have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>tensor input to be upper triangular processed</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>diag</p></td>
<td><p>diagonal to be chosen (default to 0)</p></td>
<td><p>int32_t</p></td>
<td><p>-dim to +dim (default to 0)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

</section>
<section id="broadcast-and-reduce">
<h3>Broadcast and Reduce<a class="headerlink" href="#broadcast-and-reduce" title="Permalink to this heading"></a>
</h3>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.bcast">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">bcast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">math_op:</span> <span class="pre">tt_lib.tensor.BcastOpMath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">tt_lib.tensor.BcastOpDim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.bcast" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Perform a binary elementwise operation <code class="docutils literal notranslate"><span class="pre">math_op</span></code> between tensors <code class="docutils literal notranslate"><span class="pre">input_a</span></code> and <code class="docutils literal notranslate"><span class="pre">input_b</span></code>, where values from tensor <code class="docutils literal notranslate"><span class="pre">input_b</span></code> are broadcast.</p>
<p>Let tensor <code class="docutils literal notranslate"><span class="pre">input_a</span></code> have shape <code class="docutils literal notranslate"><span class="pre">[W0,</span> <span class="pre">Z0,</span> <span class="pre">Y0,</span> <span class="pre">X0]</span></code> and tensor <code class="docutils literal notranslate"><span class="pre">input_b</span></code> shape <code class="docutils literal notranslate"><span class="pre">[W1,</span> <span class="pre">Z1,</span> <span class="pre">Y1,</span> <span class="pre">X1]</span></code>. <code class="docutils literal notranslate"><span class="pre">dim</span></code> determines the type of broadcast performed.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">dim=BcastOpDim::W</span></code> broadcast is performed on dimension <code class="docutils literal notranslate"><span class="pre">X</span></code>. <code class="docutils literal notranslate"><span class="pre">Y0</span></code> and <code class="docutils literal notranslate"><span class="pre">Y1</span></code> must be the same and either (W1=1 and Z1=1) or (W0=W1 and Z0=Z1).</p>
<p>For <code class="docutils literal notranslate"><span class="pre">dim=BcastOpDim::H</span></code> broadcast is performed on dimension  <code class="docutils literal notranslate"><span class="pre">Y</span></code>. <code class="docutils literal notranslate"><span class="pre">X0</span></code> and <code class="docutils literal notranslate"><span class="pre">X1</span></code> must be the same and either (W1=1 and Z1=1) or (W0=W1 and Z0=Z1).</p>
<p>For <code class="docutils literal notranslate"><span class="pre">dim=BcastOpDim::HW</span></code> broadcast is performed on dimensions <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">Y</span></code>. Either (W1=1 and Z1=1) or (W0=W1 and Z0=Z1) must hold for input shapes.</p>
<p>Both input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W0, Z0, Y0, X0]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Input tensor to broadcast</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W1, Z1, Y1, X1]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>math_op</p></td>
<td><p>Aggregating math operation</p></td>
<td>
<blockquote>
<div>
<p>BcastOpMath</p>
</div>
</blockquote>
</td>
<td><p>ADD, SUB, MUL</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>Dimension on which to broadcast</p></td>
<td><p>BcastOpDim</p></td>
<td><p>W, H, HW</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.reduce">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">reduce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">math_op:</span> <span class="pre">tt_lib.tensor.ReduceOpMath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">tt_lib.tensor.ReduceOpDim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaler:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dtype:</span> <span class="pre">Optional[tt_lib.tensor.DataType]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.reduce" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Perform a reduction of input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> using mathematical operation <code class="docutils literal notranslate"><span class="pre">math_op</span></code> on dimension <code class="docutils literal notranslate"><span class="pre">dim</span></code>.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">arg2=ReduceOpDim::W</span></code> reduce is done on dimension X.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">arg2=ReduceOpDim::H</span></code> reduce is done on dimension Y.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">arg2=ReduceOpDim::HW</span></code> reduce is done on dimensions X and Y.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>math_op</p></td>
<td><p>Aggregating math operation</p></td>
<td>
<blockquote>
<div>
<p>ReduceOpMath</p>
</div>
</blockquote>
</td>
<td><p>SUM, MAX, MIN</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>dim</p></td>
<td><p>Dimension on which reduction is performed</p></td>
<td><p>ReduceOpDim</p></td>
<td><p>W, H, HW</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_dtype</p></td>
<td><p>DataType of output tensor</p></td>
<td><p>DataType</p></td>
<td><p>Default is None (use input dtype)</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.global_min">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">global_min</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.global_min" title="Permalink to this definition"></a>
</dt>
<dd>
<blockquote>
<div>
<p>Returns a new tensor with the min of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> on all axes.</p>
</div>
</blockquote>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor global_min is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.global_max">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">global_max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.global_max" title="Permalink to this definition"></a>
</dt>
<dd>
<blockquote>
<div>
<p>Returns a new tensor with the max of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> on all axes.</p>
</div>
</blockquote>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor global_max is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.global_sum">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">global_sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.global_sum" title="Permalink to this definition"></a>
</dt>
<dd>
<blockquote>
<div>
<p>Returns a new tensor with the sum of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> on all axes.</p>
</div>
</blockquote>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor global_sum is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.global_mean">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">global_mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.global_mean" title="Permalink to this definition"></a>
</dt>
<dd>
<blockquote>
<div>
<p>Returns a new tensor with the mean of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> on all axes.</p>
</div>
</blockquote>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor global_mean is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.rpow">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">rpow</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.rpow" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor  raising <code class="docutils literal notranslate"><span class="pre">base</span></code> value to power of respective elements of the input exponent tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor rpow is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>base</p></td>
<td><p>base value</p></td>
<td><p>float</p></td>
<td><p>&gt;0.0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.rsub">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">rsub</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.rsub" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor  with respective elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> subtracted from the <code class="docutils literal notranslate"><span class="pre">value</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor rsub is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>value</p></td>
<td><p>subtrahent value which is actually calculated as minuend</p></td>
<td><p>float</p></td>
<td><p>Yes</p></td>
<td></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.rdiv">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">rdiv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">denominator:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.rdiv" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor  with value <code class="docutils literal notranslate"><span class="pre">denominator</span></code> divided by each of respective elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor rdiv is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>denominator</p></td>
<td><p>denominator value which is actually calculated as numerator</p></td>
<td><p>float</p></td>
<td><p>&gt;=0.0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

</section>
</section>
<section id="fallback-operations">
<h2>Fallback Operations<a class="headerlink" href="#fallback-operations" title="Permalink to this heading"></a>
</h2>
<p>These operations are currently not supported on TT accelerator device and will execute on host machine using Pytorch.</p>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.full">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">full</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill_value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.fallback_ops.full" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Creates a <code class="docutils literal notranslate"><span class="pre">tt_lib.tensor.Tensor</span></code> of shape <code class="docutils literal notranslate"><span class="pre">size</span></code> filled with <code class="docutils literal notranslate"><span class="pre">fill_value</span></code> value.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>size</p></td>
<td><p>Shape of output tensor</p></td>
<td><p>List[int]</p></td>
<td><p>list of 4 ints</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>fill_value</p></td>
<td><p>Value with which to fill output tensor</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.tensor_slice">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">tensor_slice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">slices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">slice</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">ellipsis</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.fallback_ops.tensor_slice" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Creates a <code class="docutils literal notranslate"><span class="pre">tt_lib.tensor.Tensor</span></code> from <code class="docutils literal notranslate"><span class="pre">input</span></code> using <code class="docutils literal notranslate"><span class="pre">slices</span></code>.
To use <code class="docutils literal notranslate"><span class="pre">...</span></code>, pass in <code class="docutils literal notranslate"><span class="pre">...</span></code> or <code class="docutils literal notranslate"><span class="pre">Ellipsis</span></code>.
To use <code class="docutils literal notranslate"><span class="pre">:</span></code>, pass in <code class="docutils literal notranslate"><span class="pre">slice(None)</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>slices</p></td>
<td><p>List of slices to slice the input tensor</p></td>
<td><p>List[slice, Ellipsis]</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.reshape">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">reshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">~tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">N:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_layout:</span> <span class="pre">~tt_lib.tensor.Layout</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">&lt;Layout.TILE:</span> <span class="pre">1&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_on_device:</span> <span class="pre">bool</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.fallback_ops.reshape" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new <code class="docutils literal notranslate"><span class="pre">tt_lib.tensor.Tensor</span></code> with the same data and number of elements as <code class="docutils literal notranslate"><span class="pre">input</span></code>, but with the specified shape <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>N</p></td>
<td><p>Size of the first dimension of output tensor</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>C</p></td>
<td><p>Size of the second dimension of output tensor</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>H</p></td>
<td><p>Size of the third dimension of output tensor</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>W</p></td>
<td><p>Size of the fourth dimension of output tensor</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_layout</p></td>
<td><p>Output layout</p></td>
<td><p>Layout</p></td>
<td><p>default is TILE</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_on_device</p></td>
<td><p>Output on device</p></td>
<td><p>bool</p></td>
<td><p>default is True</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.chunk">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">chunk</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#tt_lib.fallback_ops.chunk" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Attempts to split a <code class="docutils literal notranslate"><span class="pre">tt_lib.tensor.Tensor</span></code> into the specified number of chunks. Each chunk is a new copy of part of the input tensor.</p>
<p>If the tensor size along the given dimension <code class="docutils literal notranslate"><span class="pre">dim</span></code> is divisible by <code class="docutils literal notranslate"><span class="pre">chunks</span></code>, all returned chunks will be the same size.</p>
<p>If the tensor size along the given dimension <code class="docutils literal notranslate"><span class="pre">dim</span></code> is not divisible by <code class="docutils literal notranslate"><span class="pre">chunks</span></code>, all returned chunks will be the same size, except the last one. If such division is not possible, this function may return fewer than the specified number of chunks.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>chunks</p></td>
<td><p>Number of chunks to return</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>dim</p></td>
<td><p>Dimension along which to split the tensor</p></td>
<td><p>int</p></td>
<td><p>0, 1, 2, 3 (default is 0)</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.conv2d">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">conv2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.fallback_ops.conv2d" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies a 2D convolution over an input image composed of several input planes.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>weight</p></td>
<td><p>Weights tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>bias</p></td>
<td><p>Bias tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>strides</p></td>
<td><p>Stride of the convolution</p></td>
<td><p>int or tuple[int] (size 2)</p></td>
<td><p>positive ints (default value is 1)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>padding</p></td>
<td><p>Padding added to all four sides of the input</p></td>
<td>
<p>int or tuple[int] (size 2)</p>
<p>or string</p>
</td>
<td>
<p>positive ints (default value is 0)</p>
<p>for string <cite>valid</cite> or <cite>same</cite></p>
</td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>dilation</p></td>
<td><p>Spacing between kernel elements</p></td>
<td><p>int or (int, int)</p></td>
<td><p>positive ints (default value is 1)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>groups</p></td>
<td><p>Number of blocked connections from input channels to output channels</p></td>
<td><p>int</p></td>
<td><p>positive ints (default value is 1)</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.group_norm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">group_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_groups</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.fallback_ops.group_norm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies Group Normalization over a mini-batch of inputs as described in the paper <a class="reference external" href="https://arxiv.org/abs/1803.08494">Group Normalization</a>.</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta\]</div>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>num_groups</p></td>
<td><p>Number of groups to separate the input channels into</p></td>
<td><p>int</p></td>
<td><p>int, such that number of channels in input is divisble by it</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>weight</p></td>
<td><p>Weight tensor <span class="math notranslate nohighlight">\(\gamma\)</span></p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>bias</p></td>
<td><p>Bias tensor <span class="math notranslate nohighlight">\(\beta\)</span></p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>eps</p></td>
<td><p>A value added to the denominator for numerical stability</p></td>
<td><p>float</p></td>
<td><p>default value is 1e-05</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.layer_norm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">layer_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalized_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.fallback_ops.layer_norm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies Layer Normalization over a mini-batch of inputs as described in the paper <a class="reference external" href="https://arxiv.org/abs/1607.06450">Layer Normalization</a></p>
<div class="math notranslate nohighlight">
\[y = \frac{x - \text{E}[x]}{\sqrt{\text{Var}[x] + \epsilon}} * \gamma + \beta\]</div>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>normalized_shape</p></td>
<td><p>Shape over which to normalize</p></td>
<td><p>int or List[int]</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>weight</p></td>
<td><p>Weight tensor <span class="math notranslate nohighlight">\(\gamma\)</span></p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>bias</p></td>
<td><p>Bias tensor <span class="math notranslate nohighlight">\(\beta\)</span></p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>eps</p></td>
<td><p>A value added to the denominator for numerical stability</p></td>
<td><p>float</p></td>
<td><p>default value is 1e-05</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.pad">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">pad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input:</span> <span class="pre">~tt_lib.tensor.Tensor,</span> <span class="pre">pad:</span> <span class="pre">~typing.Tuple[int],</span> <span class="pre">mode:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'constant',</span> <span class="pre">value:</span> <span class="pre">int</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">output_layout:</span> <span class="pre">~tt_lib.tensor.Layout</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">&lt;Layout.TILE:</span> <span class="pre">1&gt;,</span> <span class="pre">output_on_device:</span> <span class="pre">bool</span> <span class="pre">|</span> <span class="pre">None</span> <span class="pre">=</span> <span class="pre">True</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.fallback_ops.pad" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Pads tensor.</p>
<p><code class="docutils literal notranslate"><span class="pre">pad</span></code> determines how much padding to add.</p>
<p>Values in <code class="docutils literal notranslate"><span class="pre">pad</span></code> specify padding starting from the last dimension of input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> and moving forward.</p>
<p><code class="docutils literal notranslate"><span class="pre">pad</span></code> is and m-elements tuple, where m/2 is less of equal to  input dimensions and m is even.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>pad</p></td>
<td><p>The padding size by which to pad some dimensions of input</p></td>
<td><p>Tuple[int]</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>mode</p></td>
<td><p>Padding mode</p></td>
<td><p>string</p></td>
<td><p><cite>constant</cite>, <cite>reflect</cite>, <cite>replicate</cite>, or <cite>circular</cite> (default is <cite>constant</cite>)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>value</p></td>
<td><p>Fill value for <cite>constant</cite> padding</p></td>
<td><p>int</p></td>
<td><p>default is 0</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_layout</p></td>
<td><p>Output layout</p></td>
<td><p>Layout</p></td>
<td><p>default is TILE</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_on_device</p></td>
<td><p>Output on device</p></td>
<td><p>bool</p></td>
<td><p>default is True</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.interpolate">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">interpolate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'nearest'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recompute_scale_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">antialias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.fallback_ops.interpolate" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Down/up samples the input to either the given size or the given scale_factor</p>
<p>The algorithm used for interpolation is determined by mode.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>size</p></td>
<td><p>Output spatial size</p></td>
<td><p>Tuple[int]</p></td>
<td><p>default is None</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>scale_factor</p></td>
<td><p>Multiplier for spatial size</p></td>
<td><p>Tuple[float]</p></td>
<td><p>default is None</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>mode</p></td>
<td><p>algorithm used for upsampling</p></td>
<td><p>string</p></td>
<td><p><cite>nearest</cite>, <cite>linear</cite>, <cite>bilinear</cite>, <cite>bicubic</cite>, <cite>trilinear</cite>,
<cite>area</cite>, or <cite>nearest-exact</cite> (default is <cite>nearest</cite>)</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>align_corners</p></td>
<td><p>Whether to align center or corner points of corner pixels</p></td>
<td><p>bool</p></td>
<td><p>default is None</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>recompute_scale_factor</p></td>
<td><p>Recompute the scale_factor for use in interpolation</p></td>
<td><p>bool</p></td>
<td><p>default is None</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>antialias</p></td>
<td><p>Flag to apply anti-aliasing</p></td>
<td><p>bool</p></td>
<td><p>default is False</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.repeat">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">repeat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">sizes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.fallback_ops.repeat" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> repeated along the specified dims.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>sizes</p></td>
<td><p>The number of times to repeat the tensor along each dim</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.repeat_interleave">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">repeat_interleave</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">repeats</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.fallback_ops.repeat_interleave" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a tensor with repeated elements of input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>repeats</p></td>
<td><p>The number of repetitions for each element</p></td>
<td><p>Tensor or int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>dim</p></td>
<td><p>The dimension along which to repeat values</p></td>
<td><p>int</p></td>
<td></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_size</p></td>
<td><p>Total output size for the given axis ( e.g. sum of repeats)</p></td>
<td><p>int</p></td>
<td></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.concat">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">concat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.fallback_ops.concat" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Concatenates input tensors in list <code class="docutils literal notranslate"><span class="pre">tensors</span></code> on provided dimension <code class="docutils literal notranslate"><span class="pre">dim</span></code>.</p>
<p>All tensors must either have the same shape (except in the concatenating dimension) or be empty.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>tensors</p></td>
<td><p>Input tensors</p></td>
<td><p>List[Tensor]</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>The dimension along which to concatenate</p></td>
<td><p>int</p></td>
<td><p>0, 1, 2, or 3 (default is 0)</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.silu">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">silu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.fallback_ops.silu" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the Sigmoid Linear Unit (SiLU) function, element-wise.
The SiLU function is also known as the swish function.</p>
<div class="math notranslate nohighlight">
\[\text{silu}(x) = x * \sigma(x), \text{where } \sigma(x) \text{ is the logistic sigmoid.}\]</div>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.softmax">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.fallback_ops.softmax" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies a softmax function to input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Softmax is defined as:</p>
<div class="math notranslate nohighlight">
\[\text{Softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}\]</div>
<p>It is applied to all slices along dim, and will re-scale them so that the elements lie in the range <cite>[0, 1]</cite> and sum to 1.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>A dimension along which Softmax will be computed</p></td>
<td><p>int</p></td>
<td><p>0, 1, 2, or 3</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.Conv2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">Conv2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">biases</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'zeros'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.Conv2d" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies a 2D convolution over an input signal composed of several input planes.</p>
<p>In the simplest case, the output value of the layer with input size
<span class="math notranslate nohighlight">\((N, C_{\text{in}}, H, W)\)</span> and output <span class="math notranslate nohighlight">\((N, C_{\text{out}}, H_{\text{out}}, W_{\text{out}})\)</span>
can be precisely described as:</p>
<div class="math notranslate nohighlight">
\[\text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) +
\sum_{k = 0}^{C_{\text{in}} - 1} \text{weight}(C_{\text{out}_j}, k) \star \text{input}(N_i, k)\]</div>
<p>where <span class="math notranslate nohighlight">\(\star\)</span> is a valid 2D cross-correlation operator, <span class="math notranslate nohighlight">\(N\)</span> is batch size, <span class="math notranslate nohighlight">\(C\)</span> denotes the number of channels,
<span class="math notranslate nohighlight">\(H\)</span> is a height of input planes in pixels, and <span class="math notranslate nohighlight">\(W\)</span> is width in pixels.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>weights</p></td>
<td><p>Weights tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>biases</p></td>
<td><p>Bias tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>in_channels</p></td>
<td><p>Number of channels in the input image</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>out_channels</p></td>
<td><p>Number of channels produced by the convolution</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>kernel_size</p></td>
<td><p>Size of the convolving kernel</p></td>
<td><p>int or Tuple[int]</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>stride</p></td>
<td><p>Stride of the convolution</p></td>
<td><p>int or Tuple[int]</p></td>
<td><p>default is 1</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>padding</p></td>
<td><p>Padding added to all four sides of the input</p></td>
<td>
<p>int or Tuple[int]</p>
<p>or string</p>
</td>
<td>
<p>default is 0</p>
<p>‘valid’ or ‘same’</p>
</td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>dilation</p></td>
<td><p>Spacing between kernel elements</p></td>
<td><p>int or Tuple[int]</p></td>
<td><p>default is 1</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>groups</p></td>
<td><p>Number of blocked connections from input channels to output channels</p></td>
<td><p>int</p></td>
<td><p>default is 1</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>bias</p></td>
<td><p>If <cite>True</cite>, adds a learnable bias to the output</p></td>
<td><p>bool</p></td>
<td><p>default is <cite>True</cite></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>padding_mode</p></td>
<td><p>Padding mode</p></td>
<td><p>string</p></td>
<td>
<p><cite>zeros</cite>, <cite>reflect</cite>, <cite>replicate</cite>, or <cite>circular</cite></p>
<p>default is <cite>zeros</cite></p>
</td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.BatchNorm2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">BatchNorm2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">biases</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">running_mean</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">running_var</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_batches_tracked</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">affine</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">track_running_stats</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.BatchNorm2d" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs
with additional channel dimension) as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing
Internal Covariate Shift</a> .</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta\]</div>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>weights</p></td>
<td><p>Weights tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>biases</p></td>
<td><p>Bias tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>running_mean</p></td>
<td><p>Tracked Running Mean tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>running_var</p></td>
<td><p>Tracked Running Variances tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>num_batches_tracked</p></td>
<td><p>Number of Batches Tracked tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>num_features</p></td>
<td><p>C from an expected input of size (N, C, H, W)</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>eps</p></td>
<td><p>A value added to the denominator for numerical stability</p></td>
<td><p>float</p></td>
<td><p>default is 1e-05</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>momentum</p></td>
<td><p>The value used for the running_mean and running_var computation.</p></td>
<td><p>float/None</p></td>
<td><p>default is 0.1</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>affine</p></td>
<td><p>Controls initialization of weights and biases</p></td>
<td><p>bool</p></td>
<td><p>default is <cite>True</cite></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>track_running_stats</p></td>
<td><p>Whether to track the running mean and variance</p></td>
<td><p>bool</p></td>
<td><p>default is <cite>True</cite></p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.GroupNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">GroupNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">biases</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_groups</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">affine</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.GroupNorm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies Group Normalization over a mini-batch of inputs as described in
the paper <a class="reference external" href="https://arxiv.org/abs/1803.08494">Group Normalization</a></p>
<div class="math notranslate nohighlight">
\[y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta\]</div>
<p><code class="docutils literal notranslate"><span class="pre">affine</span></code> is a boolean value that when set to <cite>True</cite>, this module has lernable per-channel affine parameters initialized to ones (for weights) and zeros (for biases).</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>weights</p></td>
<td><p>Weights tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>biases</p></td>
<td><p>Bias tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>num_groups</p></td>
<td><p>Number of groups to separate the channels into</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>num_channels</p></td>
<td><p>Number of channels expected in input</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>eps</p></td>
<td><p>A value added to the denominator for numerical stability</p></td>
<td><p>float</p></td>
<td><p>default is 1e-05</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>affine</p></td>
<td><p>Controls initialization of weights and biases</p></td>
<td><p>bool</p></td>
<td><p>default is <cite>True</cite></p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.LayerNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">LayerNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">biases</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalized_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">elementwise_affine</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.LayerNorm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies Layer Normalization over a mini-batch of inputs as described in the paper <a class="reference external" href="https://arxiv.org/abs/1607.06450">Layer Normalization</a></p>
<div class="math notranslate nohighlight">
\[y = \frac{x - \text{E}[x]}{\sqrt{\text{Var}[x] + \epsilon}} * \gamma + \beta\]</div>
<p><code class="docutils literal notranslate"><span class="pre">elementwise_affine</span></code> is a boolean value that when set to <cite>True</cite>, this module has learnable per-element affine parameters initialized to ones (for weights) and zeros (for biases).</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>weights</p></td>
<td><p>Weights tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>biases</p></td>
<td><p>Bias tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>normalized_shape</p></td>
<td><p>Shape over which to normalize</p></td>
<td><p>int or List[int]</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>eps</p></td>
<td><p>A value added to the denominator for numerical stability</p></td>
<td><p>float</p></td>
<td><p>default is 1e-05</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>elementwise_affine</p></td>
<td><p>Controls initialization of weights and biases</p></td>
<td><p>bool</p></td>
<td><p>default is <cite>True</cite></p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.MaxPool2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">MaxPool2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ceil_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channels_last</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reshape_2d</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.MaxPool2d" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies a 2D max pooling over an input signal composed of several input planes.</p>
<p>In the simplest case, the output value of the layer with input size <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>,
output <span class="math notranslate nohighlight">\((N, C, H_{out}, W_{out})\)</span> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code> <span class="math notranslate nohighlight">\((kH, kW)\)</span>
can be precisely described as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    out(N_i, C_j, h, w) ={} &amp; \max_{m=0, \ldots, kH-1} \max_{n=0, \ldots, kW-1} \\
                            &amp; \text{input}(N_i, C_j, \text{stride[0]} \times h + m,
                                           \text{stride[1]} \times w + n)
\end{aligned}\end{split}\]</div>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>kernel_size</p></td>
<td><p>The size of the window to take a max over</p></td>
<td><p>int or Tuple[int]</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>stride</p></td>
<td><p>The stride of the window. Default value is kernel_size</p></td>
<td><p>int or Tuple[int]</p></td>
<td><p>default is kernel_size</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>padding</p></td>
<td><p>Implicit negative infinity padding to be added on both sides</p></td>
<td><p>int or Tuple[int]</p></td>
<td><p>default is 0</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>dilation</p></td>
<td><p>A parameter that controls the stride of elements in the window</p></td>
<td><p>int or Tuple[int]</p></td>
<td><p>default is 1</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>return_indices</p></td>
<td><p>If True, will return the max indices along with the outputs.</p></td>
<td><p>bool</p></td>
<td><p>default is <cite>False</cite></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>ceil_mode</p></td>
<td><p>If True, will use ceil instead of floor to compute the output shape</p></td>
<td><p>bool</p></td>
<td><p>default is <cite>False</cite></p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.AdaptiveAvgPool2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">AdaptiveAvgPool2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channels_last</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.AdaptiveAvgPool2d" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies a 2D adaptive average pooling over an input signal composed of several input planes.</p>
<p>The output is of size H x W, for any input size.
The number of output features is equal to the number of input planes.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>output_size</p></td>
<td><p>The target output size of the image</p></td>
<td><p>int</p></td>
<td><p>int/None or tuple
of int/None (size 2)</p></td>
<td><p>yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.ceil">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">ceil</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.ceil" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the ceil of the elements of <code class="docutils literal notranslate"><span class="pre">input</span></code>, the smallest integer greater than or equal to each element.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor for ceil</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.floor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">floor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.floor" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the floor of the elements of <code class="docutils literal notranslate"><span class="pre">input</span></code>, the largest integer less than or equal to each element.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor for floor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.trunc">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">trunc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.trunc" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the truncated integer values of the elements of <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor for trunc</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.unary_fmod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">unary_fmod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.unary_fmod" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies mod operations and the result has the same sign as the dividend <code class="docutils literal notranslate"><span class="pre">input</span></code> and
its absolute value is less than that of <code class="docutils literal notranslate"><span class="pre">other</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>Other</p></td>
<td><p>Scalar</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.binary_fmod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">binary_fmod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.binary_fmod" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies mod operations and the result has the same sign as the dividend <code class="docutils literal notranslate"><span class="pre">input</span></code> and
its absolute value is less than that of <code class="docutils literal notranslate"><span class="pre">other</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>First tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>Other</p></td>
<td><p>Second tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.bitwise_not">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">bitwise_not</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.bitwise_not" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the bitwise NOT of the given <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.unary_bitwise_or">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">unary_bitwise_or</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.unary_bitwise_or" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the bitwise OR of <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">other</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>other</p></td>
<td><p>Immediate value</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.unary_bitwise_and">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">unary_bitwise_and</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.unary_bitwise_and" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the bitwise AND of <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">other</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>other</p></td>
<td><p>Immediate value</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.unary_bitwise_xor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">unary_bitwise_xor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.unary_bitwise_xor" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the bitwise XOR of <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">other</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>other</p></td>
<td><p>Immediate value</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.binary_bitwise_or">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">binary_bitwise_or</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.binary_bitwise_or" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the bitwise OR of <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">other</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>First tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>other</p></td>
<td><p>Second tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.binary_bitwise_and">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">binary_bitwise_and</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.binary_bitwise_and" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the bitwise AND of <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">other</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>First tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>other</p></td>
<td><p>Second Tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.binary_bitwise_xor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">binary_bitwise_xor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.binary_bitwise_xor" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the bitwise XOR of <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">other</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>First tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>other</p></td>
<td><p>Second tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.unary_bitwise_left_shift">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">unary_bitwise_left_shift</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.unary_bitwise_left_shift" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the left arithmetic shift of <code class="docutils literal notranslate"><span class="pre">input</span></code> by <code class="docutils literal notranslate"><span class="pre">other</span></code> bits. The input tensor must be of integral type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>other</p></td>
<td><p>Immediate value</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.unary_bitwise_right_shift">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">unary_bitwise_right_shift</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.unary_bitwise_right_shift" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the right arithmetic shift of <code class="docutils literal notranslate"><span class="pre">input</span></code> by <code class="docutils literal notranslate"><span class="pre">other</span></code> bits. The input tensor must be of integral type.
In any case, if the value of the right operand is negative or is greater or equal to the number of bits in the
promoted left operand, the behavior is undefined.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>other</p></td>
<td><p>Immediate value</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.binary_bitwise_left_shift">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">binary_bitwise_left_shift</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.binary_bitwise_left_shift" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the left arithmetic shift of <code class="docutils literal notranslate"><span class="pre">input</span></code> by <code class="docutils literal notranslate"><span class="pre">other</span></code> bits. The input tensor must be of integral type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>First tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>other</p></td>
<td><p>Second tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.binary_bitwise_right_shift">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">binary_bitwise_right_shift</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.binary_bitwise_right_shift" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the right arithmetic shift of <code class="docutils literal notranslate"><span class="pre">input</span></code> by <code class="docutils literal notranslate"><span class="pre">other</span></code> bits. The input tensor must be of integral type.
In any case, if the value of the right operand is negative or is greater or equal to the number of bits in the
promoted left operand, the behavior is undefined.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>First tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>other</p></td>
<td><p>Second tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.torch_argmax">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">torch_argmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.torch_argmax" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns the indices of the maximum values of a tensor along a dimension.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>Dimension along which to compute the argmax</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>keepdim</p></td>
<td><p>Whether to retain the dimensionality of input</p></td>
<td><p>bool</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py class">
<dt class="sig sig-object py" id="tt_lib.fallback_ops.torch_argmin">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tt_lib.fallback_ops.</span></span><span class="sig-name descname"><span class="pre">torch_argmin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fallback_ops.torch_argmin" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns the indices of the minimum values of a tensor along a dimension.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>Dimension along which to compute the argmin</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>keepdim</p></td>
<td><p>Whether to retain the dimensionality of input</p></td>
<td><p>bool</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

</section>
<section id="experimental-operations">
<h2>Experimental Operations<a class="headerlink" href="#experimental-operations" title="Permalink to this heading"></a>
</h2>
<p>Operations in this section are experimental, don’t have full support, and may behave in unexpected ways.</p>
<section id="fused-operations-from-tt-lib-mini-graph-library">
<h3>Fused Operations from <code class="docutils literal notranslate"><span class="pre">tt_lib</span></code> Mini-Graph Library<a class="headerlink" href="#fused-operations-from-tt-lib-mini-graph-library" title="Permalink to this heading"></a>
</h3>
<p>We have a variety of common operations that require fusion of multiple
base operations together.</p>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fused_ops.linear.Linear">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fused_ops.linear.</span></span><span class="sig-name descname"><span class="pre">Linear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fused_ops.linear.Linear" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a function that performs a Linear operation with optional bias.</p>
<p><code class="docutils literal notranslate"><span class="pre">weight</span></code> must be the weight as a tilized list of values.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fused_ops.softmax.softmax">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fused_ops.softmax.</span></span><span class="sig-name descname"><span class="pre">softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">stable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fused_ops.softmax.softmax" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs Softmax on a <code class="docutils literal notranslate"><span class="pre">tt_lib.tensor.Tensor</span></code>.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fused_ops.layernorm.Layernorm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fused_ops.layernorm.</span></span><span class="sig-name descname"><span class="pre">Layernorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fused_ops.layernorm.Layernorm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a function that performs LayerNorm with parameters.</p>
<p>H, W correspond to normalized_shape in pytorch Layernorm spec</p>
<p><em>Note</em>: Note that the only <code class="docutils literal notranslate"><span class="pre">num_dims</span></code> supported at the moment is <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.fused_ops.add_and_norm.AddAndNorm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.fused_ops.add_and_norm.</span></span><span class="sig-name descname"><span class="pre">AddAndNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.fused_ops.add_and_norm.AddAndNorm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a function that performs Eltwise-binary add two
<code class="docutils literal notranslate"><span class="pre">tt_lib.tensor.Tensor</span></code> s and then LayerNorm the result.</p>
</dd>
</dl>

</section>
<section id="complex-operations">
<h3>Complex Operations<a class="headerlink" href="#complex-operations" title="Permalink to this heading"></a>
</h3>
<blockquote>
<div>
<dl class="simple">
<dt>We use the following Tensor representation for complex tensors on device; we support complex tensor <strong>x</strong> as  N,H,W,C rank-4 tensor with last dim of size divisible by 64 to represent real and imaginary components</dt>
<dd>
<ul class="simple">
<li><p>with indices [:,:,:,0:N/2] being real, and</p></li>
<li><p>with indices [:,:,:,N/2:N] being imaginary.</p></li>
</ul>
</dd>
</dl>
</div>
</blockquote>
<p>The following functions are available,</p>
<p>Complex arithmetic can be carried out for multiply, divide, add and subtract as follows:</p>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.complex_add">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">complex_add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.complex_add" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>complex_add(input_a: tt::tt_metal::Tensor, input_b: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt::tt_metal::Tensor</p></li>
</ol>
<p>Perform an eltwise-binary addition <code class="docutils literal notranslate"><span class="pre">input_a</span> <span class="pre">+</span> <span class="pre">input_b</span></code> on two complex tensors.</p>
<ol class="arabic simple" start="2">
<li><p>complex_add(input_a: tt_lib.tensor.complex.ComplexTensor, input_b: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt_lib.tensor.complex.ComplexTensor</p></li>
</ol>
<p>Returns addition of a complex tensor <code class="docutils literal notranslate"><span class="pre">{0}</span></code> with <code class="docutils literal notranslate"><span class="pre">{1}</span></code>.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.complex_sub">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">complex_sub</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.complex_sub" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>complex_sub(input_a: tt::tt_metal::Tensor, input_b: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt::tt_metal::Tensor</p></li>
</ol>
<p>Perform an eltwise-binary subtraction <code class="docutils literal notranslate"><span class="pre">input_a</span> <span class="pre">-</span> <span class="pre">input_b</span></code> on two complex tensors.</p>
<ol class="arabic simple" start="2">
<li><p>complex_sub(input_a: tt_lib.tensor.complex.ComplexTensor, input_b: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt_lib.tensor.complex.ComplexTensor</p></li>
</ol>
<p>Returns subtraction of a complex tensor <code class="docutils literal notranslate"><span class="pre">{1}</span></code> from <code class="docutils literal notranslate"><span class="pre">{0}</span></code>.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.complex_mul">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">complex_mul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.complex_mul" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>complex_mul(input_a: tt::tt_metal::Tensor, input_b: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt::tt_metal::Tensor</p></li>
</ol>
<p>Perform an eltwise-binary multiplication <code class="docutils literal notranslate"><span class="pre">input_a</span> <span class="pre">*</span> <span class="pre">input_b</span></code> on two complex tensors.</p>
<ol class="arabic simple" start="2">
<li><p>complex_mul(input_a: tt_lib.tensor.complex.ComplexTensor, input_b: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt_lib.tensor.complex.ComplexTensor</p></li>
</ol>
<p>Returns addition of a complex multiplication of <code class="docutils literal notranslate"><span class="pre">{0}</span></code> and <code class="docutils literal notranslate"><span class="pre">{1}</span></code>.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.complex_div">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">complex_div</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.complex_div" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>complex_div(input_a: tt::tt_metal::Tensor, input_b: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt::tt_metal::Tensor</p></li>
</ol>
<p>Perform an eltwise-binary divide <code class="docutils literal notranslate"><span class="pre">input_a</span> <span class="pre">/</span> <span class="pre">input_b</span></code> on two complex tensors.</p>
<ol class="arabic simple" start="2">
<li><p>complex_div(input_a: tt_lib.tensor.complex.ComplexTensor, input_b: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt_lib.tensor.complex.ComplexTensor</p></li>
</ol>
<p>Returns addition of a complex division of <code class="docutils literal notranslate"><span class="pre">{0}</span></code> by <code class="docutils literal notranslate"><span class="pre">{1}</span></code>.</p>
</dd>
</dl>

<p>and then unary operations for,</p>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.real">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">real</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.real" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>real(input: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Returns real portion of complex tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor real is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li><p>real(input: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt::tt_metal::Tensor</p></li>
</ol>
<p>Returns real value of complex tensor <code class="docutils literal notranslate"><span class="pre">{0}</span></code>.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.imag">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">imag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.imag" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>imag(input: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Returns imag portion of complex tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor imag is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li><p>imag(input: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt::tt_metal::Tensor</p></li>
</ol>
<p>Returns imaginary value of complex tensor <code class="docutils literal notranslate"><span class="pre">{0}</span></code>.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.complex_abs">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">complex_abs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.complex_abs" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>complex_abs(input: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Returns elementwise abs value of complex tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor complex_abs is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li><p>complex_abs(input: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt::tt_metal::Tensor</p></li>
</ol>
<p>Returns absolute value of complex tensor <code class="docutils literal notranslate"><span class="pre">{0}</span></code>.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.conj">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">conj</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.conj" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>conj(input: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Returns elementwise complex conjugate of tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor conj is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li><p>conj(input: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt_lib.tensor.complex.ComplexTensor</p></li>
</ol>
<p>Returns complex conjugate value of complex tensor <code class="docutils literal notranslate"><span class="pre">{0}</span></code>.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.complex_recip">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">complex_recip</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.complex_recip" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>complex_recip(input: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Returns elementwise reciprocal of complex tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor complex_recip is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li><p>complex_recip(input: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt_lib.tensor.complex.ComplexTensor</p></li>
</ol>
<p>Returns complex reciprocal value of complex tensor <code class="docutils literal notranslate"><span class="pre">{0}</span></code>.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.polar">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">polar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.polar" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>polar(input_a: tt::tt_metal::ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt::tt_metal::ComplexTensor</p></li>
</ol>
<p>Perform an polar to Cartesian transformation of the input.real(r), input.imag(theta) into x + i*y generating a type-2 complex tensor.</p>
<ol class="arabic simple" start="2">
<li><p>polar(input_a: tt::tt_metal::Tensor, input_b: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; tt::tt_metal::Tensor</p></li>
</ol>
<p>Perform an polar to Cartesian transformation of the input_a (r), input_b(theta) into x + i*y generating a type-2 complex tensor.</p>
</dd>
</dl>

</section>
<section id="complex-operations-type-2">
<h3>Complex Operations (Type 2)<a class="headerlink" href="#complex-operations-type-2" title="Permalink to this heading"></a>
</h3>
<p>Type 2 Complex representation allows for more flexible storage than earlier one while providing same set of
operations; specifically this storage allows for compute without the cost of split-concat implicit in
the Type 1 contiguous representations.</p>
</section>
<section id="other-operations">
<h3>Other Operations<a class="headerlink" href="#other-operations" title="Permalink to this heading"></a>
</h3>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.concat">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">concat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input_tensors:</span> <span class="pre">List[tt_lib.tensor.Tensor],</span> <span class="pre">dim:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">0,</span> <span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.concat" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Concatenates shape of tensors <code class="docutils literal notranslate"><span class="pre">arg0</span></code> and <code class="docutils literal notranslate"><span class="pre">arg1</span></code> to new shape <code class="docutils literal notranslate"><span class="pre">[W,</span> <span class="pre">Z,</span> <span class="pre">Y,</span> <span class="pre">X]</span></code> along the specified dimension <code class="docutils literal notranslate"><span class="pre">arg1</span></code>.</p>
<p>Input tensors must be on device, in ROW MAJOR or TILE layout, and have matching data type.</p>
<p>Output tensor will be on device, in same layout, and have same data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_tensors</p></td>
<td><p>Input tensors to concat</p></td>
<td><p>List of Tensors</p></td>
<td><p>Tensors of shape [W, Z, Y, X], where Y or X must be a multiple of 32 if they are the concat dim</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>dimension of concat</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.sum">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.sum" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a tensor that is a sum  of input tensor with shape <code class="docutils literal notranslate"><span class="pre">[W,</span> <span class="pre">Z,</span> <span class="pre">Y,</span> <span class="pre">X]</span></code> along dimensions <code class="docutils literal notranslate"><span class="pre">dim</span></code>; input tensor in TILE LAYOUT.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor sum is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>dimension along which to apply sum</p></td>
<td><p>int</p></td>
<td><p>0, 1, 2, or 3</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.log_sigmoid">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">log_sigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.log_sigmoid" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the logsigmoid function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> for input range [-4,10].</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor log_sigmoid is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.expm1">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">expm1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.expm1" title="Permalink to this definition"></a>
</dt>
<dd>
<dl class="simple">
<dt>Returns a new tensor with the expm1 of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</dt>
<dd>
<p>expm1 = exp(x) - 1</p>
</dd>
</dl>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor expm1 is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.asinh">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">asinh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.asinh" title="Permalink to this definition"></a>
</dt>
<dd>
<dl class="simple">
<dt>Returns tensor with the inverse hyperbolic sine of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> in range [-1e-6, 1e6].</dt>
<dd>
<p>for +input , output = asinh(input)
for -input , output = -asinh(input)</p>
</dd>
</dl>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor asinh is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.acosh">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">acosh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.acosh" title="Permalink to this definition"></a>
</dt>
<dd>
<dl class="simple">
<dt>Returns tensor with the inverse hyperbolic cosine of elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> in range [-1e-6, 1e6].</dt>
<dd>
<p>for  input &gt; 1, output = acosh(input)
for  input ==1, ouptut = 0
for  input &lt; 1, output =  nan</p>
</dd>
</dl>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor acosh is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.erf">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">erf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fast_and_approx:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.erf" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes error function for all elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor erf is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>fast_and_approx</p></td>
<td><p>Indicate true for approx and fast mode; false for accurate and slow mode</p></td>
<td><p>bool</p></td>
<td><p>default of true</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.erfc">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">erfc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fast_and_approx:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.erfc" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes complementary error function for all elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor erfc is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>fast_and_approx</p></td>
<td><p>Indicate true for approx and fast mode; false for accurate and slow mode</p></td>
<td><p>bool</p></td>
<td><p>default of true</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.rsqrt">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">rsqrt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fast_and_approx:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.rsqrt" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the reciprocal of the square-root of each of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> for the input range -10 to 10.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor rsqrt is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>fast_and_approx</p></td>
<td><p>Indicate true for approx and fast mode; false for accurate and slow mode</p></td>
<td><p>bool</p></td>
<td><p>default of true</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.lerp">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">lerp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.lerp" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>lerp(input: tt::tt_metal::Tensor, end: tt::tt_metal::Tensor, weight: float, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Applies the linear interpolation of two tensors <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">end</span></code> based on a
scalar <code class="docutils literal notranslate"><span class="pre">weight</span></code> and returns the resulting out tensor.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor lerp is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>end</p></td>
<td><p>End value</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>weight</p></td>
<td><p>Weight value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>lerp(input: tt::tt_metal::Tensor, end: tt::tt_metal::Tensor, weight: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Applies the linear interpolation of two tensors <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">end</span></code> based on a
tensor <code class="docutils literal notranslate"><span class="pre">weight</span></code> and returns the resulting out tensor.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor lerp is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>end</p></td>
<td><p>End value</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>weight</p></td>
<td><p>Weight value</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.signbit">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">signbit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.signbit" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the signbit function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor signbit is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.fill_rm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">fill_rm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hOnes:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wOnes:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">any:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_hi:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_lo:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.fill_rm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Generates an NCHW row-major tensor and fill it with high values up to
hOnes, wOnes in each HW tile with the rest padded with high values. So
for H=2, W=3, hFill=1, wFill=2 the following tensor will be generated:</p>
<div class="highlight-default notranslate">
<div class="highlight"><pre><span></span><span class="o">+------------&gt;</span> <span class="n">W</span>
<span class="o">|</span> <span class="n">hi</span> <span class="n">hi</span> <span class="n">lo</span>
<span class="o">|</span> <span class="n">lo</span> <span class="n">lo</span> <span class="n">lo</span>
<span class="o">|</span>
<span class="n">v</span> <span class="n">H</span>
</pre></div>
</div>
<p>H, W are expected to be multiples of 32.</p>
<p>The ‘any’ Tensor arg is only used to pass the device and resulting
tensor dtype.</p>
<p>val_hi/lo are expected to be floats.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>N</p></td>
<td><p>Batch count of output tensor</p></td>
<td><p>int</p></td>
<td><p>N &gt; 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>C</p></td>
<td><p>Channel count of output tensor</p></td>
<td><p>int</p></td>
<td><p>C &gt; 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>H</p></td>
<td><p>Height count of output tensor</p></td>
<td><p>int</p></td>
<td><p>H &gt; 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>W</p></td>
<td><p>Width count of output tensor</p></td>
<td><p>int</p></td>
<td><p>W &gt; 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>hOnes</p></td>
<td><p>Height of high values region</p></td>
<td><p>int</p></td>
<td><p>hOnes &lt;= H</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>wOnes</p></td>
<td><p>Width of high values region</p></td>
<td><p>int</p></td>
<td><p>wOnes &lt;= W</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>any</p></td>
<td><p>Any input tensor with desired device and data types for output tensor</p></td>
<td><p>tt_lib.tensor.Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>val_hi</p></td>
<td><p>High value to use</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>val_lo</p></td>
<td><p>Low value to use</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.fill_ones_rm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">fill_ones_rm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hOnes:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wOnes:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">any:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.fill_ones_rm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Same as <code class="docutils literal notranslate"><span class="pre">fill_rm</span></code>, but <code class="docutils literal notranslate"><span class="pre">val_hi</span></code> is set to <code class="docutils literal notranslate"><span class="pre">1</span></code> and <code class="docutils literal notranslate"><span class="pre">val_lo</span></code> is
<code class="docutils literal notranslate"><span class="pre">0</span></code>.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>N</p></td>
<td><p>Batch count of output tensor</p></td>
<td><p>int</p></td>
<td><p>N &gt; 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>C</p></td>
<td><p>Channel count of output tensor</p></td>
<td><p>int</p></td>
<td><p>C &gt; 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>H</p></td>
<td><p>Height count of output tensor</p></td>
<td><p>int</p></td>
<td><p>H &gt; 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>W</p></td>
<td><p>Width count of output tensor</p></td>
<td><p>int</p></td>
<td><p>W &gt; 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>hOnes</p></td>
<td><p>Height of high values region</p></td>
<td><p>int</p></td>
<td><p>hOnes &lt;= H</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>wOnes</p></td>
<td><p>Width of high values region</p></td>
<td><p>int</p></td>
<td><p>wOnes &lt;= W</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>any</p></td>
<td><p>Any input tensor with desired device and data types for output tensor</p></td>
<td><p>tt_lib.tensor.Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.conv">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">arg0:</span> <span class="pre">tt::tt_metal::Tensor,</span> <span class="pre">arg1:</span> <span class="pre">tt::tt_metal::Tensor,</span> <span class="pre">arg2:</span> <span class="pre">Optional[tt::tt_metal::Tensor],</span> <span class="pre">arg3:</span> <span class="pre">List[int],</span> <span class="pre">arg4:</span> <span class="pre">int,</span> <span class="pre">arg5:</span> <span class="pre">int,</span> <span class="pre">arg6:</span> <span class="pre">int,</span> <span class="pre">arg7:</span> <span class="pre">int,</span> <span class="pre">arg8:</span> <span class="pre">int,</span> <span class="pre">arg9:</span> <span class="pre">int,</span> <span class="pre">arg10:</span> <span class="pre">bool</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.conv" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Perform a conv <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">x</span> <span class="pre">B</span></code> with two tensors
This op tilizes tensor A and untilizes the output</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>a</p></td>
<td><p>Conv activation TT tensor (CHANNELS LAST</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>b</p></td>
<td><p>Conv weight TT tensor (TILED)</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>conv_params</p></td>
<td><p>Conv parameters list: kernel size H, kernel size W ,stride H,stride W,pad H,pad W</p></td>
<td><p>Vector&lt;int&gt;</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.layernorm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">layernorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.layernorm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>“Performs a layernorm operation on the last tensor dimension with optional fused with post-multiplication and addition via W-bcast.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.groupnorm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">groupnorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_size:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.groupnorm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>“Performs a groupnorm operation on the channel dimension grouped per group_size, with optional fused with post-multiplication and addition via W-bcast.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.rmsnorm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">rmsnorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.rmsnorm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>“Performs a rmsnorm operation on the last tensor dimension with optional fused with post-multiplication and addition via W-bcast.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.add_layernorm">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">add_layernorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compute_kernel_config:</span> <span class="pre">Optional[Union[tt_lib.tensor.GrayskullComputeKernelConfig</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tt_lib.tensor.WormholeComputeKernelConfig]]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.add_layernorm" title="Permalink to this definition"></a>
</dt>
<dd>
<p>“Performs a layernorm(a+b)*gamma + beta operation.”</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.convert_conv_weight_tensor_to_tiled_layout">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">convert_conv_weight_tensor_to_tiled_layout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conv_weight_tensor:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in1_block_h:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in1_block_w:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dtype:</span> <span class="pre">Optional[tt_lib.tensor.DataType]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.convert_conv_weight_tensor_to_tiled_layout" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Converts convolution weights to 2d matrix tiled layout on host
Returns a new tensor with the converted layout.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>a</p></td>
<td><p>Input tensor</p></td>
<td><p>Tensor</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.xlogy">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">xlogy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.xlogy" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs eltwise-binary xlogy (<code class="docutils literal notranslate"><span class="pre">input_a</span> <span class="pre">*</span> <span class="pre">log(</span> <span class="pre">input_b</span> <span class="pre">)</span></code>) on two tensors.</p>
<p>Both input tensors must be of equal shape.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>First tensor to xlogy</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Second tensor to xlogy</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.prod">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">prod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">all_dimensions:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.prod" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Computes the prod function along specified <code class="docutils literal notranslate"><span class="pre">dim</span></code> or all dimensions on the <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor.
If <code class="docutils literal notranslate"><span class="pre">all_dimensions</span></code> is set to <code class="docutils literal notranslate"><span class="pre">true</span></code> irrespective of given dimension it will prod along all dimensions.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor prod is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>all_dimensions</p></td>
<td><p>Consider all dimension (ignores <code class="docutils literal notranslate"><span class="pre">dim</span></code> param)</p></td>
<td><p>bool</p></td>
<td><p>default to false</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>dim</p></td>
<td><p>Dimension to perform prod</p></td>
<td><p>int</p></td>
<td><p>default to 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.tiled_prod">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">tiled_prod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.tiled_prod" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs tile-wise multiplication on input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> and store the result in the last tile of the input tensor.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor tiled_prod is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.addcmul">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">addcmul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor1:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor2:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.addcmul" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs the element-wise multiplication of tensor1 <code class="docutils literal notranslate"><span class="pre">tensor1</span></code> by tensor2 <code class="docutils literal notranslate"><span class="pre">tensor2</span></code>, multiplies the result
by the scalar value <code class="docutils literal notranslate"><span class="pre">value</span></code> and adds it to input <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor addcmul is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>tensor1</p></td>
<td><p>First Tensor to multiply</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>tensor2</p></td>
<td><p>Second tensor to multiply</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>value</p></td>
<td><p>Value to be multiplied</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.addcdiv">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">addcdiv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor1:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor2:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.addcdiv" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs the element-wise division of tensor1 <code class="docutils literal notranslate"><span class="pre">tensor1</span></code> by tensor2 <code class="docutils literal notranslate"><span class="pre">tensor2</span></code>, multiplies the result
by the scalar value <code class="docutils literal notranslate"><span class="pre">value</span></code> and adds it to input <code class="docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor addcdiv is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>tensor1</p></td>
<td><p>Numerator Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>tensor2</p></td>
<td><p>Denominator Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>value</p></td>
<td><p>Value to be multiplied</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.mean_hw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">mean_hw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.mean_hw" title="Permalink to this definition"></a>
</dt>
<dd>
<blockquote>
<div>
<p>Returns a new tensor with the variance of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> on H,W axes.</p>
</div>
</blockquote>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor mean_hw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.var_hw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">var_hw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.var_hw" title="Permalink to this definition"></a>
</dt>
<dd>
<blockquote>
<div>
<p>Returns a new tensor with the variance of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> on H,W axes.</p>
</div>
</blockquote>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor var_hw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.logical_noti">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">logical_noti</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">immediate:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.logical_noti" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Perform an eltwise logical NOT (<code class="docutils literal notranslate"><span class="pre">!immediate</span></code>) on immediate value.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor logical_noti is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>immediate</p></td>
<td><p>immediate</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.std_hw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">std_hw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.std_hw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the standard deviation of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> on H,W axes.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor std_hw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.normalize_hw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">normalize_hw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.normalize_hw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the Gaussian normalize of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> on H,W axes.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor normalize_hw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.normalize_global">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">normalize_global</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.normalize_global" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor with the Gaussian normalize of the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> on N,C,H,W axes.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor normalize_global is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.glu">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">glu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.glu" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the Gated Linear Units (GLU) function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> split along dim <code class="docutils literal notranslate"><span class="pre">dim</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor glu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>dimension to split</p></td>
<td><p>No</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.geglu">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">geglu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.geglu" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the Gaussian Error Gated Linear Units function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> split along dim <code class="docutils literal notranslate"><span class="pre">dim</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor geglu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>dimension to split</p></td>
<td><p>No</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.reglu">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">reglu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.reglu" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the Rectified Linear Gated Linear Units (ReGLU) function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> split along dim <code class="docutils literal notranslate"><span class="pre">dim</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor reglu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>dimension to split</p></td>
<td><p>No</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.swiglu">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">swiglu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.swiglu" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Applies the Swish Gated Linear Units (SwiGLU) function to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> split along dim <code class="docutils literal notranslate"><span class="pre">dim</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor swiglu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>dimension to split</p></td>
<td><p>No</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.embeddings">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tilized:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings_type:</span> <span class="pre">tt_lib.tensor.EmbeddingsType</span> <span class="pre">=</span> <span class="pre">&lt;EmbeddingsType.GENERIC:</span> <span class="pre">0&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token:</span> <span class="pre">Optional[int]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dtype:</span> <span class="pre">Optional[tt_lib.tensor.DataType]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.embeddings" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns specific indices of the embedding table specified by the input tensor</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
<th class="head"></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor containing rows we want</p></td>
<td><p>UInt32 Tensor</p></td>
<td><p>Each element greater than 0 and less than number of embeddings in table.  Shape [batch_size, 1, 1, num_rows]</p></td>
<td><p>Yes</p></td>
<td></td>
</tr>
<tr class="row-odd">
<td><p>weights</p></td>
<td><p>Entire embedding table</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor shape is [1,1, num_embeddings, num_columns]. Num_columns must be divisible by 32.</p></td>
<td><p>Yes</p></td>
<td></td>
</tr>
<tr class="row-even">
<td><p>tilized</p></td>
<td><p>Enable fused tilize on output. Default is true.</p></td>
<td><p>Bool</p></td>
<td></td>
<td><p>No</p></td>
<td></td>
</tr>
<tr class="row-odd">
<td><p>embeddings_type</p></td>
<td><p>Version of optimized embeddings to run. PADDED requires passing pad_token. BINARY expects the indices to only be 0, 1 and weights to have 2 rows</p></td>
<td><p>EmbeddingsType</p></td>
<td><p>GENERIC, PADDED, BINARY</p></td>
<td><p>No</p></td>
<td></td>
</tr>
<tr class="row-even">
<td><p>pad_token</p></td>
<td><p>pad_token used in token ids</p></td>
<td><p>uint32_t</p></td>
<td><p>Default is None</p></td>
<td><p>No</p></td>
<td></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
<td></td>
</tr>
<tr class="row-even">
<td><p>output_dtype</p></td>
<td><p>DataType of output tensor</p></td>
<td><p>DataType</p></td>
<td><p>Default is weights dtype</p></td>
<td><p>No</p></td>
<td></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.nextafter">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">nextafter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.nextafter" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns the next floating-point value after input_a towards input_b of the input tensors <code class="docutils literal notranslate"><span class="pre">input_a</span></code> and <code class="docutils literal notranslate"><span class="pre">input_b</span></code>.</p>
<p>Both input tensors must be of equal shape.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>First tensor to nextafter</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Second tensor to nextafter</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.lamb_optimizer">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">lamb_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_avg:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_avg_sq:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta1:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta2:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_size:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.lamb_optimizer" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns tensor with the threshold activation on elements of the input tensors <code class="docutils literal notranslate"><span class="pre">arg0</span></code> at threshold <code class="docutils literal notranslate"><span class="pre">threshold</span></code>,
and value <code class="docutils literal notranslate"><span class="pre">value</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>data</p></td>
<td><p>Tensor data is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>grad</p></td>
<td><p>Tensor grad is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>exp_avg</p></td>
<td><p>Tensor exp_avg is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>exp_avg_sq</p></td>
<td><p>exp_avg_sq threshold is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>beta1</p></td>
<td><p>Value to beta1 at</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>beta2</p></td>
<td><p>Value to beta2 with</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>step_size</p></td>
<td><p>Value to beta1 at</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>eps</p></td>
<td><p>Value to beta2 with</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>weight_decay</p></td>
<td><p>Value to beta1 at</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.repeat">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">repeat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size:</span> <span class="pre">tt_lib.tensor.Shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.repeat" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor filled with repetition of input <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor according to number of times specified in <code class="docutils literal notranslate"><span class="pre">size</span></code>. The rank of <code class="docutils literal notranslate"><span class="pre">size</span></code> should be less than or equal to the rank of tensor <code class="docutils literal notranslate"><span class="pre">input_a</span></code>.</p>
<p>Output tensor will have same data type as input.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor for which repetition is computed</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of any shape</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>size</p></td>
<td><p>The number of times to repeat this tensor along each dimension</p></td>
<td><p>List[Int]</p></td>
<td><p>Positive repetition values</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.repeat_interleave">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">repeat_interleave</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repeat:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.repeat_interleave" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Repeated tensor which has the same shape as <code class="docutils literal notranslate"><span class="pre">input</span></code>, except along the given axis.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor input is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>repeat</p></td>
<td><p>Repeat value</p></td>
<td><p>int</p></td>
<td><p>1 to inf</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>dim</p></td>
<td><p>dim value</p></td>
<td><p>int</p></td>
<td><p>0 to 2</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.pow">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">pow</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.pow" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>pow(input: tt::tt_metal::Tensor, exponent: float, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Returns a new tensor filled with power of input <code class="docutils literal notranslate"><span class="pre">input</span></code> raised to value of <code class="docutils literal notranslate"><span class="pre">exponent</span></code>.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor for which power is computed</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of any shape</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>exponent</p></td>
<td><p>exponent value</p></td>
<td><p>float</p></td>
<td><p>positive floating point value</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>pow(input: tt::tt_metal::Tensor, exponent: int, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; tt::tt_metal::Tensor</p>
<blockquote>
<div>
<p>Returns a new tensor filled with power of input <code class="docutils literal notranslate"><span class="pre">input</span></code> raised to value of <code class="docutils literal notranslate"><span class="pre">exponent</span></code>.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input tensor for which power is computed</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of any shape</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>exponent</p></td>
<td><p>exponent value</p></td>
<td><p>integer</p></td>
<td><p>positive integer value</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.identity">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">identity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt_lib.tensor.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="tensor.html#tt_lib.tensor.Tensor" title="tt_lib.tensor.Tensor"><span class="pre">tt_lib.tensor.Tensor</span></a></span></span><a class="headerlink" href="#tt_lib.tensor.identity" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a copy of same tensor <code class="docutils literal notranslate"><span class="pre">input</span></code>; useful for profiling the SFPU.
this shouldn’t normally be used; users should normally use clone operation instead for same functionality as this would be lower performance.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor identity is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is INTERLEAVED in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.argmax">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">argmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">all:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.argmax" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns the indices of the maximum value of elements in the <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor
If <code class="docutils literal notranslate"><span class="pre">all</span></code> is set to <code class="docutils literal notranslate"><span class="pre">true</span></code> irrespective of given dimension it will return the indices of maximum value of all elements in given <code class="docutils literal notranslate"><span class="pre">input</span></code></p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor argmax is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>Dimension to perform argmax</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>all</p></td>
<td><p>Consider all dimension (ignores <code class="docutils literal notranslate"><span class="pre">dim</span></code> param)</p></td>
<td><p>bool</p></td>
<td><p>default to false</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.argmin">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">argmin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">all:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.argmin" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns the indices of the minimum value of elements in the <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor
If <code class="docutils literal notranslate"><span class="pre">all</span></code> is set to <code class="docutils literal notranslate"><span class="pre">true</span></code> irrespective of given dimension it will return the indices of minimum value of all elements in given <code class="docutils literal notranslate"><span class="pre">input</span></code></p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Tensor argmin is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>Dimension to perform argmin</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>all</p></td>
<td><p>Consider all dimension (ignores <code class="docutils literal notranslate"><span class="pre">dim</span></code> param)</p></td>
<td><p>bool</p></td>
<td><p>default to false</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

</section>
<section id="backward-operations">
<h3>Backward Operations<a class="headerlink" href="#backward-operations" title="Permalink to this heading"></a>
</h3>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.prod_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">prod_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">all_dimensions:</span> <span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.prod_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for prod on <code class="docutils literal notranslate"><span class="pre">input_a</span></code> along <code class="docutils literal notranslate"><span class="pre">all_dimensions</span></code> or a particular <code class="docutils literal notranslate"><span class="pre">dim</span></code>.
If <code class="docutils literal notranslate"><span class="pre">all_dimensions</span></code> is set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, irrespective of given dimension it will perform backward prod for all dimensions.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>all_dimensions</p></td>
<td><p>Consider all dimension (ignores <code class="docutils literal notranslate"><span class="pre">dim</span></code> param)</p></td>
<td><p>bool</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>dim</p></td>
<td><p>Dimension to perform prod</p></td>
<td><p>int</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.addalpha_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">addalpha_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor,</span> <span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor,</span> <span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor,</span> <span class="pre">alpha:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0,</span> <span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt),</span> <span class="pre">are_required_outputs:</span> <span class="pre">List[bool]</span> <span class="pre">=</span> <span class="pre">[True,</span> <span class="pre">True],</span> <span class="pre">input_grad:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">other_grad:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[Optional[tt::tt_metal::Tensor]]</span></span></span><a class="headerlink" href="#tt_lib.tensor.addalpha_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for multiplication of <code class="docutils literal notranslate"><span class="pre">input_b</span></code> and <code class="docutils literal notranslate"><span class="pre">alpha</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_a</p></td>
<td><p>Tensor addalpha is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input_b</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>alpha</p></td>
<td><p>Alpha value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>are_required_outputs</p></td>
<td><p>Boolean values for the required outputs: input_a_grad, input_b_grad</p></td>
<td><p>List of bool</p></td>
<td><p>Default value is [True, True]</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>input_grad</p></td>
<td><p>Optional Output Tensor for input_grad</p></td>
<td><p>Tensor</p></td>
<td><p>Default value is None</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>other_grad</p></td>
<td><p>Optional Output Tensor for other_grad</p></td>
<td><p>Tensor</p></td>
<td><p>Default value is None</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.addcmul_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">addcmul_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor1:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor2:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.addcmul_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for multiplication of <code class="docutils literal notranslate"><span class="pre">tensor1</span></code>, <code class="docutils literal notranslate"><span class="pre">tensor2</span></code> and <code class="docutils literal notranslate"><span class="pre">value</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor addcmul is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>tensor1</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>tensor2</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>value</p></td>
<td><p>Value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.addcdiv_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">addcdiv_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor1:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor2:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.addcdiv_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for multiplication and division of <code class="docutils literal notranslate"><span class="pre">tensor1</span></code>, <code class="docutils literal notranslate"><span class="pre">tensor2</span></code> and <code class="docutils literal notranslate"><span class="pre">value</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor addcdiv is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>tensor1</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>tensor2</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>value</p></td>
<td><p>Value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.conj_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">conj_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.conj_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>conj_bw(grad: tt_lib.tensor.complex.ComplexTensor, input: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = None) -&gt; List[tt_lib.tensor.complex.ComplexTensor]</p>
<blockquote>
<div>
<p>Performs backward operations for conjugate for complex tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>conj_bw(grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt::tt_metal::Tensor]</p>
<blockquote>
<div>
<p>Performs backward operations for conjugate for complex tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unary_mul_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unary_mul_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scalar:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.unary_mul_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for multiplication with given <code class="docutils literal notranslate"><span class="pre">grad</span></code> and <code class="docutils literal notranslate"><span class="pre">scalar</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>scalar</p></td>
<td><p>Scalar value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unary_add_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unary_add_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.unary_add_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for addition with given <code class="docutils literal notranslate"><span class="pre">grad</span></code> and <code class="docutils literal notranslate"><span class="pre">alpha</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>alpha</p></td>
<td><p>Alpha value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unary_assign_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unary_assign_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.unary_assign_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for assign with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.binary_assign_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">binary_assign_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.binary_assign_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for binary assign on <code class="docutils literal notranslate"><span class="pre">other</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unary_div_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unary_div_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scalar:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">round_mode:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'None'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.unary_div_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for division with given <code class="docutils literal notranslate"><span class="pre">grad</span></code> and <code class="docutils literal notranslate"><span class="pre">scalar</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>scalar</p></td>
<td><p>Scalar value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.div_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">div_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">round_mode:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'None'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.div_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for division of <code class="docutils literal notranslate"><span class="pre">input_b</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_a</p></td>
<td><p>Tensor div is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input_b</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.rdiv_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">rdiv_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scalar:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">round_mode:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'None'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.rdiv_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for division for <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor and <code class="docutils literal notranslate"><span class="pre">scalar</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>scalar</p></td>
<td><p>Scalar value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.sqrt_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">sqrt_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.sqrt_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for sqrt with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.mul_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">mul_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor,</span> <span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor,</span> <span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor,</span> <span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt),</span> <span class="pre">are_required_outputs:</span> <span class="pre">List[bool]</span> <span class="pre">=</span> <span class="pre">[True,</span> <span class="pre">True],</span> <span class="pre">input_a_grad:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">input_b_grad:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[Optional[tt::tt_metal::Tensor]]</span></span></span><a class="headerlink" href="#tt_lib.tensor.mul_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for multiplication of two input tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_a</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input_b</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>are_required_outputs</p></td>
<td><p>Boolean values for the required outputs: input_a_grad, input_b_grad</p></td>
<td><p>List of bool</p></td>
<td><p>Default value is [True, True]</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>input_grad</p></td>
<td><p>Optional Output Tensor for input_a gradient</p></td>
<td><p>Tensor</p></td>
<td><p>Default value is None</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>other_grad</p></td>
<td><p>Optional Output Tensor for input_b gradient</p></td>
<td><p>Tensor</p></td>
<td><p>Default value is None</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.max_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">max_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.max_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for maximum of <code class="docutils literal notranslate"><span class="pre">input_b</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_a</p></td>
<td><p>Tensor max is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input_b</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.min_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">min_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.min_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for minimum of <code class="docutils literal notranslate"><span class="pre">input_b</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_a</p></td>
<td><p>Tensor min is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input_b</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.add_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">add_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor,</span> <span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor,</span> <span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor,</span> <span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt),</span> <span class="pre">are_required_outputs:</span> <span class="pre">List[bool]</span> <span class="pre">=</span> <span class="pre">[True,</span> <span class="pre">True],</span> <span class="pre">input_grad:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">other_grad:</span> <span class="pre">Optional[tt::tt_metal::Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[Optional[tt::tt_metal::Tensor]]</span></span></span><a class="headerlink" href="#tt_lib.tensor.add_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for addition of <code class="docutils literal notranslate"><span class="pre">input_b</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_a</p></td>
<td><p>Tensor add is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input_b</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>are_required_outputs</p></td>
<td><p>Boolean values for the required outputs: input_a_grad, input_b_grad</p></td>
<td><p>List of bool</p></td>
<td><p>Default value is [True, True]</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>input_grad</p></td>
<td><p>Optional Output Tensor for input_a gradient</p></td>
<td><p>Tensor</p></td>
<td><p>Default value is None</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>other_grad</p></td>
<td><p>Optional Output Tensor for input_b gradient</p></td>
<td><p>Tensor</p></td>
<td><p>Default value is None</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.tan_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">tan_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.tan_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for tangent with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.exp_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">exp_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.exp_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for exponential with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.exp2_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">exp2_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.exp2_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for exp2 with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.expm1_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">expm1_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.expm1_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for expm1 with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unary_pow_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unary_pow_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exponent:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.unary_pow_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for power with given <code class="docutils literal notranslate"><span class="pre">grad</span></code> and <code class="docutils literal notranslate"><span class="pre">exponent</span></code> where exponent value is greater than 1.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>exponent</p></td>
<td><p>Exponent value</p></td>
<td><p>integer</p></td>
<td><p>default to 1</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.embedding_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">embedding_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.embedding_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for embedding_bw function and it returns specific indices of the embedding table specified by the grad tensor.
The input tensor should be unique.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor containing rows we want</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>weight</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.where_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">where_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.where_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for where selected from either <code class="docutils literal notranslate"><span class="pre">input_a</span></code> or <code class="docutils literal notranslate"><span class="pre">input_b</span></code>, depending on <code class="docutils literal notranslate"><span class="pre">condition</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.
When condition True (nonzero), yield grad, otherwise yield zero’s.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>condition</p></td>
<td><p>Tensor</p></td>
<td><p>Bool</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input_a</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_b</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.tanh_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">tanh_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.tanh_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for tanh with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.fill_zero_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">fill_zero_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.fill_zero_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.fill_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">fill_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.fill_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor with sum of tensor values</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.sub_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">sub_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.sub_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for subraction of <code class="docutils literal notranslate"><span class="pre">other</span></code> and <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unary_sub_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unary_sub_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.unary_sub_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for subraction of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor add is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.log_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">log_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.log_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for logarithm of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor add is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.rsub_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">rsub_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.rsub_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for subraction of <code class="docutils literal notranslate"><span class="pre">input</span></code> from <code class="docutils literal notranslate"><span class="pre">other</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code> (reversed order of subtraction operator).</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor add is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.abs_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">abs_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.abs_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for abs of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor add is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.complex_abs_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">complex_abs_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.complex_abs_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>complex_abs_bw(grad: tt::tt_metal::Tensor, input: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt_lib.tensor.complex.ComplexTensor]</p>
<blockquote>
<div>
<p>Performs backward operations for abs of complex <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor add is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>complex_abs_bw(grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt::tt_metal::Tensor]</p>
<blockquote>
<div>
<p>Performs backward operations for abs of complex <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor add is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.rsqrt_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">rsqrt_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.rsqrt_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for rsqrt of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor add is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.neg_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">neg_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.neg_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for negative with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.lt_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">lt_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.lt_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.gt_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">gt_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.gt_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.relu_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">relu_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.relu_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for relu of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor relu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.ne_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">ne_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.ne_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.clamp_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">clamp_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.clamp_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for clamp of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>min</p></td>
<td><p>Minimum Value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>max</p></td>
<td><p>Maximum Value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.clamp_min_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">clamp_min_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.clamp_min_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for clamp min of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>min</p></td>
<td><p>Minimum Value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.clamp_max_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">clamp_max_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.clamp_max_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for clamp max of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>max</p></td>
<td><p>Maximum Value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.binary_le_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">binary_le_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.binary_le_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor and <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor LE is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.atan2_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">atan2_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.atan2_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for atan2 of <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">other</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor atan2 is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Tensor atan2 is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.hypot_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">hypot_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.hypot_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for hypotenuse of <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">other</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>First input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Second input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.gelu_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">gelu_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approximate:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.gelu_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for gelu of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor gelu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>approximate</p></td>
<td><p>Approximation type</p></td>
<td><p>String</p></td>
<td><p>None, tanh</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.bias_gelu_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">bias_gelu_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approximate:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.bias_gelu_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for binary gelu of <code class="docutils literal notranslate"><span class="pre">input_a</span></code> and <code class="docutils literal notranslate"><span class="pre">input_b</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_a</p></td>
<td><p>Tensor gelu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input_b</p></td>
<td><p>Tensor gelu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>approximate</p></td>
<td><p>Approximation type</p></td>
<td><p>String</p></td>
<td><p>None, tanh</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.bias_gelu_unary_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">bias_gelu_unary_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approximate:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.bias_gelu_unary_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for unary gelu of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code> at given <code class="docutils literal notranslate"><span class="pre">bias</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor gelu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>bias</p></td>
<td><p>Bias value</p></td>
<td><p>float</p></td>
<td><p>float</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>approximate</p></td>
<td><p>Approximation type</p></td>
<td><p>String</p></td>
<td><p>None, tanh</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.squared_difference_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">squared_difference_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.squared_difference_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for squared difference of <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">other</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor squared difference is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Tensor squared difference is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.lerp_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">lerp_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.lerp_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>lerp_bw(grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, end: tt::tt_metal::Tensor, weight: float, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt::tt_metal::Tensor]</p>
<blockquote>
<div>
<p>Applies the linear interpolation of two tensors <code class="docutils literal notranslate"><span class="pre">arg0</span></code> (given by input) and <code class="docutils literal notranslate"><span class="pre">arg1</span></code> based on a
scalar <code class="docutils literal notranslate"><span class="pre">arg2</span></code>  with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor lerp is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>end</p></td>
<td><p>End value</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>weight</p></td>
<td><p>Weight value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>lerp_bw(grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, end: tt::tt_metal::Tensor, weight: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt::tt_metal::Tensor]</p>
<blockquote>
<div>
<p>Applies the linear interpolation of two tensors <code class="docutils literal notranslate"><span class="pre">arg0</span></code> (given by input) and <code class="docutils literal notranslate"><span class="pre">arg1</span></code> based on a
tensor <code class="docutils literal notranslate"><span class="pre">arg2</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor lerp is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>end</p></td>
<td><p>End value</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>weight</p></td>
<td><p>Weight value</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.ldexp_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">ldexp_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.ldexp_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for ldexp of <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">other</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.xlogy_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">xlogy_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.xlogy_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for xlogy  for <code class="docutils literal notranslate"><span class="pre">input</span></code> and  <code class="docutils literal notranslate"><span class="pre">other</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.logaddexp_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">logaddexp_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.logaddexp_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for logaddexp (<code class="docutils literal notranslate"><span class="pre">input</span></code>, <code class="docutils literal notranslate"><span class="pre">other</span></code>)  with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.logaddexp2_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">logaddexp2_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.logaddexp2_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for logaddexp2 (<code class="docutils literal notranslate"><span class="pre">input</span></code>, <code class="docutils literal notranslate"><span class="pre">other</span></code>)  with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.concat_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">concat_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_a:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_b:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.concat_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for concat of <code class="docutils literal notranslate"><span class="pre">input_a</span></code> and <code class="docutils literal notranslate"><span class="pre">input_b</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_a</p></td>
<td><p>Tensor concat is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input_b</p></td>
<td><p>Tensor concat is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>Dim</p></td>
<td><p>Dim value</p></td>
<td><p>int</p></td>
<td><p>default to 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.hardsigmoid_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">hardsigmoid_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.hardsigmoid_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for hardsigmoid of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor hardsigmoid is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.i0_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">i0_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.i0_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for i0 of <code class="docutils literal notranslate"><span class="pre">input</span></code> and tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor i0 is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.hardshrink_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">hardshrink_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.hardshrink_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for hardshrink to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">{0}</span></code> between limits <code class="docutils literal notranslate"><span class="pre">-{1}</span></code> low and the <code class="docutils literal notranslate"><span class="pre">+{1}</span></code> high limits with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor hardshrink_bw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>lambda</p></td>
<td><p>lambda value</p></td>
<td><p>float</p></td>
<td><p>float</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.softshrink_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">softshrink_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambd:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.softshrink_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for softshrink to the elements of the input tensor <code class="docutils literal notranslate"><span class="pre">{input}</span></code> between limits <code class="docutils literal notranslate"><span class="pre">-{lambd}</span></code> low and the <code class="docutils literal notranslate"><span class="pre">+{lambd}</span></code> high limits with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor softshrink_bw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>lambd</p></td>
<td><p>lambda value</p></td>
<td><p>float</p></td>
<td><p>float value &gt;= 0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.hardswish_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">hardswish_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.hardswish_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for hardswish_bw of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.softplus_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">softplus_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">20.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.softplus_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for softplus_bw of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>beta</p></td>
<td><p>Beta value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>threshold</p></td>
<td><p>Threshold value</p></td>
<td><p>float</p></td>
<td><p>default to 20.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.polygamma_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">polygamma_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.polygamma_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for polygamma of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor for order <code class="docutils literal notranslate"><span class="pre">n</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor polygamma is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>n</p></td>
<td><p>order of the polygamma</p></td>
<td><p>int</p></td>
<td><p>1 to 10</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.atan_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">atan_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.atan_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for atan of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.atanh_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">atanh_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.atanh_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for atanh of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.asin_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">asin_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.asin_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for asin_bw of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor asin_bw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.asinh_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">asinh_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.asinh_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for asinh_bw of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor asinh_bw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.cosh_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">cosh_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.cosh_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for hyperbolic cos of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.cos_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">cos_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.cos_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for cos of the <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.acosh_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">acosh_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.acosh_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for acosh of <code class="docutils literal notranslate"><span class="pre">input</span></code> and tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.acos_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">acos_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.acos_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for acos for the <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.erfinv_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">erfinv_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.erfinv_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for erfinv of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.leaky_relu_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">leaky_relu_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">negative_slope:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.009999999776482582</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.leaky_relu_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for leaky_relu_bw of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor leaky_relu_bw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.elu_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">elu_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.elu_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for elu for the <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>alpha</p></td>
<td><p>alpha value</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.hardtanh_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">hardtanh_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">-1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.hardtanh_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for hardtanh activation function on <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>, <code class="docutils literal notranslate"><span class="pre">min</span></code> and <code class="docutils literal notranslate"><span class="pre">max</span></code>.</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor hardtanh is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>Min</p></td>
<td><p>Min value</p></td>
<td><p>Float</p></td>
<td><p>default to -1.0f</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>Max</p></td>
<td><p>Max value</p></td>
<td><p>Float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.angle_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">angle_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.angle_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>angle_bw(grad: tt::tt_metal::Tensor, input: tt_lib.tensor.complex.ComplexTensor, is_complextensor: bool = True, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt_lib.tensor.complex.ComplexTensor]</p>
<blockquote>
<div>
<p>Performs backward operations for angle for the <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>is_complextensor</p></td>
<td><p>True(default) if input is complex tensor</p></td>
<td><p>bool</p></td>
<td><p>True/False</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>angle_bw(grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, is_complextensor: bool = True, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt::tt_metal::Tensor]</p>
<blockquote>
<div>
<p>Performs backward operations for angle for the <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>is_complextensor</p></td>
<td><p>True(default) if input is complex tensor</p></td>
<td><p>bool</p></td>
<td><p>True/False</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.sin_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">sin_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.sin_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for sin of the <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.sinh_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">sinh_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.sinh_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for hyperbolic sin of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.celu_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">celu_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.celu_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for Celu of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor  with given <code class="docutils literal notranslate"><span class="pre">grad</span></code> and <code class="docutils literal notranslate"><span class="pre">alpha</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor Celu is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>alpha</p></td>
<td><p>Alpha value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.binary_lt_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">binary_lt_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.binary_lt_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor and <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor LT is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.subalpha_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">subalpha_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.subalpha_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for subraction of <code class="docutils literal notranslate"><span class="pre">other</span></code> and <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with alpha for the given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>alpha</p></td>
<td><p>Alpha value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.log10_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">log10_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.log10_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for log10 of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.log1p_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">log1p_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.log1p_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for log1p of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.binary_ne_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">binary_ne_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.binary_ne_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor and <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.erf_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">erf_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.erf_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for erf of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.erfc_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">erfc_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.erfc_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for erfc of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.digamma_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">digamma_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.digamma_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for digamma for the <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.deg2rad_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">deg2rad_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.deg2rad_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for deg2rad for the <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.rad2deg_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">rad2deg_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.rad2deg_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for rad2deg for the <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.reciprocal_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">reciprocal_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.reciprocal_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for reciprocal for the <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.relu6_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">relu6_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.relu6_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of backward operation of relu6 for <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor and <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor relu6 is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.rpow_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">rpow_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exponent:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.rpow_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for rpow for the <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">exponent</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>exponent</p></td>
<td><p>exponent</p></td>
<td><p>float</p></td>
<td><p>&gt;0.0</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.silu_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">silu_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.silu_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for silu sin of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor silu_bw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.selu_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">selu_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.selu_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for selu sin of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor selu_bw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.binary_ge_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">binary_ge_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.binary_ge_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor and <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.binary_eq_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">binary_eq_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.binary_eq_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>binary_eq_bw(grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, other: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt), are_required_outputs: List[bool] = [True, True], input_grad: Optional[tt::tt_metal::Tensor] = None, other_grad: Optional[tt::tt_metal::Tensor] = None) -&gt; List[Optional[tt::tt_metal::Tensor]]</p>
<blockquote>
<div>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor and <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Other Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>are_required_outputs</p></td>
<td><p>Boolean values for the required outputs: input_grad, other_grad</p></td>
<td><p>List of bool</p></td>
<td><p>Default value is [True, True]</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>input_grad</p></td>
<td><p>Optional Output Tensor for input gradient</p></td>
<td><p>Tensor</p></td>
<td><p>Default value is None</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>other_grad</p></td>
<td><p>Optional Output Tensor for other gradient</p></td>
<td><p>Tensor</p></td>
<td><p>Default value is None</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>binary_eq_bw(queue_id: int = 0, grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, other: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt), are_required_outputs: List[bool] = [True, True], input_grad: Optional[tt::tt_metal::Tensor] = None, other_grad: Optional[tt::tt_metal::Tensor] = None) -&gt; List[Optional[tt::tt_metal::Tensor]]</p>
<blockquote>
<div>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor and <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>queue_id</p></td>
<td><p>queue_id</p></td>
<td><p>uint8_t</p></td>
<td><p>Default is 0</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>other</p></td>
<td><p>Other Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>are_required_outputs</p></td>
<td><p>Boolean values for the required outputs: input_grad, other_grad</p></td>
<td><p>List of bool</p></td>
<td><p>Default value is [True, True]</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>input_grad</p></td>
<td><p>Optional Output Tensor for input gradient</p></td>
<td><p>Tensor</p></td>
<td><p>Default value is None</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>other_grad</p></td>
<td><p>Optional Output Tensor for other gradient</p></td>
<td><p>Tensor</p></td>
<td><p>Default value is None</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.binary_gt_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">binary_gt_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.binary_gt_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor and <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.square_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">square_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.square_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward square operations on <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor square_bw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.lgamma_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">lgamma_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.lgamma_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for lgamma of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor lgamma is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.trunc_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">trunc_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.trunc_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for trunc of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor trunc is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.frac_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">frac_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.frac_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for frac of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor frac is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.log_sigmoid_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">log_sigmoid_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.log_sigmoid_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for log_sigmoid <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor log_sigmoid is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.tanhshrink_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">tanhshrink_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.tanhshrink_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward tanhshrink operations on <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor tanhshrink_bw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.threshold_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">threshold_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.threshold_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward threshold operation on <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor threshold_bw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>threshold</p></td>
<td><p>Value to threshold at</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>value</p></td>
<td><p>Value to replace with</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unary_eq_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unary_eq_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.unary_eq_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Value to compare</p></td>
<td><p>float</p></td>
<td></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.logit_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">logit_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.logit_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for logit of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.logiteps_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">logiteps_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.logiteps_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for logit of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with <cite>eps</cite> for the given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>eps</p></td>
<td><p>eps value</p></td>
<td><p>float</p></td>
<td><p>default to 0.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.softsign_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">softsign_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.softsign_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward softsign operations on <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor softsign_bw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.sign_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">sign_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.sign_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward sign operations on <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor sign_bw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.ceil_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">ceil_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.ceil_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward ceil operations on <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor ceil_bw is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.log2_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">log2_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.log2_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for log2 of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.ge_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">ge_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.ge_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.le_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">le_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.le_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unary_fmod_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unary_fmod_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scalar:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.unary_fmod_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for fmod of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with <cite>scalar</cite> for the given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>scalar</p></td>
<td><p>scalar value</p></td>
<td><p>float</p></td>
<td><p>float</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unary_remainder_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unary_remainder_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scalar:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.unary_remainder_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for ramainder of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with <cite>scalar</cite> for the given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>scalar</p></td>
<td><p>scalar value</p></td>
<td><p>float</p></td>
<td><p>float</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.complex_recip_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">complex_recip_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.complex_recip_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>complex_recip_bw(grad: tt_lib.tensor.complex.ComplexTensor, input: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt_lib.tensor.complex.ComplexTensor]</p>
<blockquote>
<div>
<p>Performs backward operations for reciprocal of complex tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>complex_recip_bw(grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt::tt_metal::Tensor]</p>
<blockquote>
<div>
<p>Performs backward operations for reciprocal of complex tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.imag_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">imag_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.imag_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>imag_bw(grad: tt::tt_metal::Tensor, input: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt_lib.tensor.complex.ComplexTensor]</p>
<blockquote>
<div>
<p>Performs backward operations for imaginary part of complex tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>imag_bw(grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt::tt_metal::Tensor]</p>
<blockquote>
<div>
<p>Performs backward operations for imaginary part of complex tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.real_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">real_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.real_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>real_bw(grad: tt::tt_metal::Tensor, input: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt_lib.tensor.complex.ComplexTensor]</p>
<blockquote>
<div>
<p>Performs backward operations for real part of complex tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>real_bw(grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt::tt_metal::Tensor]</p>
<blockquote>
<div>
<p>Performs backward operations for real part of complex tensor <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.complex_mul_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">complex_mul_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.complex_mul_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>complex_mul_bw(grad: tt_lib.tensor.complex.ComplexTensor, input: tt_lib.tensor.complex.ComplexTensor, other: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt_lib.tensor.complex.ComplexTensor]</p>
<blockquote>
<div>
<p>Performs backward operations for multiplication of complex tensors``input`` and <code class="docutils literal notranslate"><span class="pre">other</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>First input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Second input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>complex_mul_bw(grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, other: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt::tt_metal::Tensor]</p>
<blockquote>
<div>
<p>Performs backward operations for multiplication of complex tensors``input`` and <code class="docutils literal notranslate"><span class="pre">other</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>First input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Second input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.complex_div_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">complex_div_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.complex_div_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>complex_div_bw(grad: tt_lib.tensor.complex.ComplexTensor, input: tt_lib.tensor.complex.ComplexTensor, other: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt_lib.tensor.complex.ComplexTensor]</p>
<blockquote>
<div>
<p>Performs backward operations for division of complex tensors``input`` and <code class="docutils literal notranslate"><span class="pre">other</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>First input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Second input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>complex_div_bw(grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, other: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt::tt_metal::Tensor]</p>
<blockquote>
<div>
<p>Performs backward operations for division of complex tensors``input`` and <code class="docutils literal notranslate"><span class="pre">other</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>First input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Second input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.polar_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">polar_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.polar_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>polar_bw(grad: tt_lib.tensor.complex.ComplexTensor, input: tt_lib.tensor.complex.ComplexTensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt_lib.tensor.complex.ComplexTensor]</p>
<blockquote>
<div>
<p>Performs backward operations for polar <code class="docutils literal notranslate"><span class="pre">input</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input complex tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>polar_bw(grad: tt::tt_metal::Tensor, input_a: tt::tt_metal::Tensor, input_b: tt::tt_metal::Tensor, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt::tt_metal::Tensor]</p>
<blockquote>
<div>
<p>Performs backward operations for polar <code class="docutils literal notranslate"><span class="pre">input_a</span></code> and  <code class="docutils literal notranslate"><span class="pre">input_b</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code></p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input_a</p></td>
<td><p>absolute value of the complex tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>input_b</p></td>
<td><p>angle of the complex tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.complex_add_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">complex_add_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.complex_add_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>complex_add_bw(grad: tt_lib.tensor.complex.ComplexTensor, input: tt_lib.tensor.complex.ComplexTensor, other: tt_lib.tensor.complex.ComplexTensor, alpha: float = 1.0, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt_lib.tensor.complex.ComplexTensor]</p>
<blockquote>
<div>
<p>Performs backward operations for addition of  complex tensors``input`` and <code class="docutils literal notranslate"><span class="pre">other</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>First input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Second input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>alpha</p></td>
<td><p>Alpha value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>complex_add_bw(grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, other: tt::tt_metal::Tensor, alpha: float = 1.0, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt::tt_metal::Tensor]</p>
<blockquote>
<div>
<p>Performs backward operations for addition of  complex tensors``input`` and <code class="docutils literal notranslate"><span class="pre">other</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>First input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Second input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>alpha</p></td>
<td><p>Alpha value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.complex_sub_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">complex_sub_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tt_lib.tensor.complex_sub_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Overloaded function.</p>
<ol class="arabic">
<li>
<p>complex_sub_bw(grad: tt_lib.tensor.complex.ComplexTensor, input: tt_lib.tensor.complex.ComplexTensor, other: tt_lib.tensor.complex.ComplexTensor, alpha: float = 1.0, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt_lib.tensor.complex.ComplexTensor]</p>
<blockquote>
<div>
<p>Performs backward operations for subtraction of  complex tensors``input`` and <code class="docutils literal notranslate"><span class="pre">other</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>First input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Second input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>alpha</p></td>
<td><p>Alpha value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
<li>
<p>complex_sub_bw(grad: tt::tt_metal::Tensor, input: tt::tt_metal::Tensor, other: tt::tt_metal::Tensor, alpha: float = 1.0, output_mem_config: tt_lib.tensor.MemoryConfig = tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED,buffer_type=BufferType::DRAM,shard_spec=std::nullopt)) -&gt; List[tt::tt_metal::Tensor]</p>
<blockquote>
<div>
<p>Performs backward operations for subtraction of  complex tensors``input`` and <code class="docutils literal notranslate"><span class="pre">other</span></code> with given <code class="docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>First input tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>other</p></td>
<td><p>Second input Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of complex shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>alpha</p></td>
<td><p>Alpha value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
</li>
</ol>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.multigammaln_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">multigammaln_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.multigammaln_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for multigammaln of <code class="docutils literal notranslate"><span class="pre">input</span></code> tensors with given <code class="docutils literal notranslate"><span class="pre">grad</span></code> and value of P is taken as 4.</p>
<p>mvlgamma is refered as multigammaln.</p>
<p>Input value must be greater than 2.5f</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensors will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor mvlgamma is applied to</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.repeat_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">repeat_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape:</span> <span class="pre">tt_lib.tensor.Shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.repeat_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns a new tensor filled with repetition of input <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor according to number of times specified in <code class="docutils literal notranslate"><span class="pre">shape</span></code>. The rank of <code class="docutils literal notranslate"><span class="pre">shape</span></code> should be same as rank of tensor <code class="docutils literal notranslate"><span class="pre">input_a</span></code>.
The limitation in our implementation is N and C should be 1 and the repeat is of any number for such dim, other should be 1.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Input tensor for which repetition is computed</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [1, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>shape</p></td>
<td><p>Shape value</p></td>
<td><p>Shape</p></td>
<td><p>The number of times to repeat this tensor along each dimension</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.floor_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">floor_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.floor_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.round_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">round_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.round_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns an tensor of zeros like <code class="docutils literal notranslate"><span class="pre">grad</span></code> tensor</p>
<p>Input tensor must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.unary_div_no_nan_bw">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">unary_div_no_nan_bw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scalar:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">tt::tt_metal::MemoryConfig(memory_layout=TensorMemoryLayout::INTERLEAVED</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_type=BufferType::DRAM</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shard_spec=std::nullopt)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">List[tt::tt_metal::Tensor]</span></span></span><a class="headerlink" href="#tt_lib.tensor.unary_div_no_nan_bw" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Performs backward operations for division with given <code class="docutils literal notranslate"><span class="pre">grad</span></code> and <code class="docutils literal notranslate"><span class="pre">scalar</span></code> with no nan.</p>
<p>Input tensors must have BFLOAT16 data type.</p>
<p>Output tensor will have BFLOAT16 data type.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd">
<th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Data type</p></th>
<th class="head"><p>Valid range</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>grad</p></td>
<td><p>Gradient tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p>input</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor</p></td>
<td><p>Tensor of shape [W, Z, Y, X]</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p>scalar</p></td>
<td><p>Scalar value</p></td>
<td><p>float</p></td>
<td><p>default to 1.0f</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p>output_mem_config</p></td>
<td><p>Layout of tensor in TT Accelerator device memory banks</p></td>
<td><p>MemoryConfig</p></td>
<td><p>Default is interleaved in DRAM</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>

</section>
<section id="loss-functions">
<h3>Loss Functions<a class="headerlink" href="#loss-functions" title="Permalink to this heading"></a>
</h3>
<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.mseloss">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">mseloss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_reference:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_prediction:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_mode:</span> <span class="pre">tt_lib.tensor.LossReductionMode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.mseloss" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns mean squared error loss function for <code class="docutils literal notranslate"><span class="pre">{0}</span></code> and <code class="docutils literal notranslate"><span class="pre">{1}</span></code>.</p>
</dd>
</dl>

<dl class="py function">
<dt class="sig sig-object py" id="tt_lib.tensor.maeloss">
<span class="sig-prename descclassname"><span class="pre">tt_lib.tensor.</span></span><span class="sig-name descname"><span class="pre">maeloss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_reference:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_prediction:</span> <span class="pre">tt::tt_metal::Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_mode:</span> <span class="pre">tt_lib.tensor.LossReductionMode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_mem_config:</span> <span class="pre">tt_lib.tensor.MemoryConfig</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">tt::tt_metal::Tensor</span></span></span><a class="headerlink" href="#tt_lib.tensor.maeloss" title="Permalink to this definition"></a>
</dt>
<dd>
<p>Returns mean absolute error loss function for <code class="docutils literal notranslate"><span class="pre">{0}</span></code> and <code class="docutils literal notranslate"><span class="pre">{1}</span></code>.</p>
</dd>
</dl>

</section>
</section>
</section>



           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Dependencies" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="tensor.html" class="btn btn-neutral float-right" title="Tensor" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Tenstorrent.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        Version: v0.49.0
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        
        <dl>
            <dt>Versions</dt>
            
            <dd><a href="https://tenstorrent.github.io/docs-test/ttnn/latest/index.html">latest</a></dd>
            
            <dd><a href="https://tenstorrent.github.io/docs-test/ttnn/v0.49.0/index.html">v0.49.0</a></dd>
            
        </dl>
        
        <br>
        </dl>
    </div>
</div>
<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>