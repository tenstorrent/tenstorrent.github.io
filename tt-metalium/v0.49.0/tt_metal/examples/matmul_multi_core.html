<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Matmul (Multi Core) &mdash; TT-Metalium  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/tt_theme.css?v=ea036265" />

  
    <link rel="shortcut icon" href="../../_static/cropped-favicon-32x32.png"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=b3ba4146"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Matmul (Multi Core Optimized)" href="matmul_multi_core_optimized.html" />
    <link rel="prev" title="Matmul (Single Core)" href="matmul_single_core.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >



<a href="https://tenstorrent.github.io/docs-test/core/latest/">
    <img src="../../_static/tt_logo.svg" class="logo" alt="Logo"/>
</a>

<a href="../../index.html">
    TT-Metalium
</a>
    <div class="version">
      v0.49.0
    </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../get_started/get_started.html">Getting Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">TT-Metalium</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../programming_model/index.html">Programming Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/index.html">APIs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Programming Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="dram_loopback.html">DRAM Loopback</a></li>
<li class="toctree-l2"><a class="reference internal" href="eltwise_sfpu.html">Eltwise SFPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="eltwise_binary.html">Eltwise binary</a></li>
<li class="toctree-l2"><a class="reference internal" href="matmul_single_core.html">Matmul (Single Core)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Matmul (Multi Core)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#accessing-all-the-cores">Accessing all the cores</a></li>
<li class="toctree-l3"><a class="reference internal" href="#splitting-the-work-across-cores">Splitting the work across cores</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-different-kernels-for-reader-writer">Using different kernels for reader/writer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compute-kernel-args">Compute kernel args</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reader-writer-kernel-runtime-args">Reader/writer kernel runtime args</a></li>
<li class="toctree-l3"><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="matmul_multi_core_optimized.html">Matmul (Multi Core Optimized)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../tools/index.html">Tools</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../resources/support.html">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources/contributing.html">Contributing as a developer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">TT-Metalium</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Programming Examples</a></li>
      <li class="breadcrumb-item active">Matmul (Multi Core)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tt_metal/examples/matmul_multi_core.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="matmul-multi-core">
<span id="matmul-multi-core-example"></span><h1>Matmul (Multi Core)<a class="headerlink" href="#matmul-multi-core" title="Permalink to this heading"></a>
</h1>
<p>We’ll build a program that will perform matmul operations on two tensors
with equal-size inner dimension on as many cores as possible on the accelerator
chip. This example builds on top of the previous single core example.</p>
<p>In terms of API usage, there isn’t much change. We will discuss the specific
changes to:</p>
<ul class="simple">
<li><p>Using different kernels with their different runtime arguments.</p></li>
<li><p>Programming in terms of looping over all cores we will use.</p></li>
</ul>
<p>All important ways we use the API different are in the new
<code class="docutils literal notranslate"><span class="pre">matmul_multi_core</span></code> function.</p>
<p>The full example program is in
<code class="docutils literal notranslate"><span class="pre">tt_metal/programming_examples/matmul_multi_core/matmul_multi_core.cpp</span></code></p>
<p>To build and execute, you may use the following commands. Note that we include
the necessary environment variables here, but you may possibly need more
depending on the most up-to-date installation methods.</p>
<div class="highlight-default notranslate">
<div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">ARCH_NAME</span><span class="o">=&lt;</span><span class="n">arch</span> <span class="n">name</span><span class="o">&gt;</span>
<span class="n">export</span> <span class="n">TT_METAL_HOME</span><span class="o">=&lt;</span><span class="n">this</span> <span class="n">repo</span> <span class="nb">dir</span><span class="o">&gt;</span>
<span class="o">./</span><span class="n">build_metal</span><span class="o">.</span><span class="n">sh</span>
<span class="o">./</span><span class="n">build</span><span class="o">/</span><span class="n">programming_examples</span><span class="o">/</span><span class="n">matmul_multi_core</span>
</pre></div>
</div>
<section id="accessing-all-the-cores">
<h2>Accessing all the cores<a class="headerlink" href="#accessing-all-the-cores" title="Permalink to this heading"></a>
</h2>
<p>We first must get information on the layout of the entire chip. This means the
grid of cores and its x/y dimensions in number of cores.</p>
<div class="highlight-cpp notranslate">
<div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">compute_with_storage_grid_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device</span><span class="o">-&gt;</span><span class="n">compute_with_storage_grid_size</span><span class="p">();</span>
<span class="kt">uint32_t</span><span class="w"> </span><span class="n">num_cores_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compute_with_storage_grid_size</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="kt">uint32_t</span><span class="w"> </span><span class="n">num_cores_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compute_with_storage_grid_size</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</pre></div>
</div>
</section>
<section id="splitting-the-work-across-cores">
<h2>Splitting the work across cores<a class="headerlink" href="#splitting-the-work-across-cores" title="Permalink to this heading"></a>
</h2>
<p>We need to split the work across multiple cores. This means figuring out how
many tiles each core will use to compute the matmul.</p>
<p>We use a helper function that the Metal team developed to do this. Given the
number of tiles of the multiplication and the entire grid upon which we want to
execute, we receive back:</p>
<ul class="simple">
<li><p>The total number of cores, which is the product of the dimensions</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">CoreRangeSet</span></code> of all cores</p></li>
<li><p>The first <code class="docutils literal notranslate"><span class="pre">CoreRangeSet</span></code> of cores which will perform a certain count of tile operations, A</p></li>
<li><p>The second <code class="docutils literal notranslate"><span class="pre">CoreRangeSet</span></code> of cores which will perform another count of tile operations, B, if applicable</p></li>
<li><p>A as <code class="docutils literal notranslate"><span class="pre">uint32_t</span></code></p></li>
<li><p>B as <code class="docutils literal notranslate"><span class="pre">uint32_t</span></code>, if applicable</p></li>
</ul>
<div class="highlight-cpp notranslate">
<div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="p">[</span><span class="n">num_cores</span><span class="p">,</span><span class="w"> </span><span class="n">all_cores</span><span class="p">,</span><span class="w"> </span><span class="n">core_group_1</span><span class="p">,</span><span class="w"> </span><span class="n">core_group_2</span><span class="p">,</span><span class="w"> </span><span class="n">num_output_tiles_per_core_group_1</span><span class="p">,</span><span class="w"> </span><span class="n">num_output_tiles_per_core_group_2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">split_work_to_cores</span><span class="p">(</span><span class="n">compute_with_storage_grid_size</span><span class="p">,</span><span class="w"> </span><span class="n">num_output_tiles_total</span><span class="p">);</span>
</pre></div>
</div>
<p>The reason why we may have two separate sets of cores and tile counts is
because depending on the grid size, it may not be possible to evenly distribute
tiles over the full set of cores. We may need another separate set of cores to
perform the “spill-over” number of computations.</p>
<p>This means we will need to be careful when it comes programming each set of
cores. We also need to account for the case where we can evenly distribute
work, meaning the second set will be empty.</p>
</section>
<section id="using-different-kernels-for-reader-writer">
<h2>Using different kernels for reader/writer<a class="headerlink" href="#using-different-kernels-for-reader-writer" title="Permalink to this heading"></a>
</h2>
<p>We use more complex reader/writer kernels to feed our compute engine.</p>
<p>These kernels will use banking and interleaving techniques to ensure consistent
and performant dataflow operations. We must ensure that cores only receive and
perform computations on their specific set of tiles, and nothing more or less.</p>
<div class="highlight-cpp notranslate">
<div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">reader_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tt_metal</span><span class="o">::</span><span class="n">CreateKernel</span><span class="p">(</span>
<span class="w">    </span><span class="n">program</span><span class="p">,</span>
<span class="w">    </span><span class="s">"tt_metal/programming_examples/matmul_common/kernels/dataflow/reader_bmm_8bank_output_tiles_partitioned.cpp"</span><span class="p">,</span>
<span class="w">    </span><span class="n">all_cores</span><span class="p">,</span>
<span class="w">    </span><span class="n">tt_metal</span><span class="o">::</span><span class="n">DataMovementConfig</span><span class="p">{.</span><span class="n">processor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataMovementProcessor</span><span class="o">::</span><span class="n">RISCV_1</span><span class="p">,</span><span class="w"> </span><span class="p">.</span><span class="n">noc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">NOC</span><span class="o">::</span><span class="n">RISCV_1_default</span><span class="p">,</span><span class="w"> </span><span class="p">.</span><span class="n">compile_args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reader_compile_time_args</span><span class="p">});</span>

<span class="k">auto</span><span class="w"> </span><span class="n">writer_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tt_metal</span><span class="o">::</span><span class="n">CreateKernel</span><span class="p">(</span>
<span class="w">    </span><span class="n">program</span><span class="p">,</span>
<span class="w">    </span><span class="s">"tt_metal/programming_examples/matmul_common/kernels/dataflow/writer_unary_interleaved_start_id.cpp"</span><span class="p">,</span>
<span class="w">    </span><span class="n">all_cores</span><span class="p">,</span>
<span class="w">    </span><span class="n">tt_metal</span><span class="o">::</span><span class="n">DataMovementConfig</span><span class="p">{.</span><span class="n">processor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataMovementProcessor</span><span class="o">::</span><span class="n">RISCV_0</span><span class="p">,</span><span class="w"> </span><span class="p">.</span><span class="n">noc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">NOC</span><span class="o">::</span><span class="n">RISCV_0_default</span><span class="p">,</span><span class="w"> </span><span class="p">.</span><span class="n">compile_args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">writer_compile_time_args</span><span class="p">});</span>
</pre></div>
</div>
</section>
<section id="compute-kernel-args">
<h2>Compute kernel args<a class="headerlink" href="#compute-kernel-args" title="Permalink to this heading"></a>
</h2>
<p>We need to account for the fact that we may two separate groups of cores
that require different arguments for tile count.</p>
<div class="highlight-cpp notranslate">
<div class="highlight"><pre><span></span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint32_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">compute_args_group_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="c1">// B</span>
<span class="w">    </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="c1">// Mt</span>
<span class="w">    </span><span class="n">Kt</span><span class="p">,</span><span class="w"> </span><span class="c1">// Kt</span>
<span class="w">    </span><span class="n">num_output_tiles_per_core_group_1</span><span class="w"> </span><span class="c1">// Nt</span>
<span class="p">};</span><span class="w"> </span><span class="c1">// bmm compute kernel the B, Mt, Nt are just 3 for loops that technically act as 1 large loop, so only set Nt for simplicity</span>

<span class="k">auto</span><span class="w"> </span><span class="n">matmul_multi_core_kernel_group_1_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tt_metal</span><span class="o">::</span><span class="n">CreateKernel</span><span class="p">(</span>
<span class="w">    </span><span class="n">program</span><span class="p">,</span>
<span class="w">    </span><span class="s">"tt_metal/programming_examples/matmul_common/kernels/compute/bmm.cpp"</span><span class="p">,</span>
<span class="w">    </span><span class="n">core_group_1</span><span class="p">,</span>
<span class="w">    </span><span class="n">tt_metal</span><span class="o">::</span><span class="n">ComputeConfig</span><span class="p">{.</span><span class="n">math_fidelity</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">math_fidelity</span><span class="p">,</span><span class="w"> </span><span class="p">.</span><span class="n">compile_args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compute_args_group_1</span><span class="p">}</span>
<span class="p">);</span>

<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">core_group_2</span><span class="p">.</span><span class="n">ranges</span><span class="p">().</span><span class="n">empty</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint32_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">compute_args_group_2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="c1">// B</span>
<span class="w">        </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="c1">// Mt</span>
<span class="w">        </span><span class="n">Kt</span><span class="p">,</span><span class="w"> </span><span class="c1">// Kt</span>
<span class="w">        </span><span class="n">num_output_tiles_per_core_group_2</span><span class="w"> </span><span class="c1">// Nt</span>
<span class="w">    </span><span class="p">};</span><span class="w"> </span><span class="c1">// bmm compute kernel the B, Mt, Nt are just 3 for loops that technically act as 1 large loop, so only set Nt for simplicity</span>

<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">matmul_multi_core_kernel_group_2_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tt_metal</span><span class="o">::</span><span class="n">CreateKernel</span><span class="p">(</span>
<span class="w">        </span><span class="n">program</span><span class="p">,</span>
<span class="w">        </span><span class="s">"tt_metal/programming_examples/matmul_common/kernels/compute/bmm.cpp"</span><span class="p">,</span>
<span class="w">        </span><span class="n">core_group_2</span><span class="p">,</span>
<span class="w">        </span><span class="n">tt_metal</span><span class="o">::</span><span class="n">ComputeConfig</span><span class="p">{.</span><span class="n">math_fidelity</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">math_fidelity</span><span class="p">,</span><span class="w"> </span><span class="p">.</span><span class="n">compile_args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compute_args_group_2</span><span class="p">}</span>
<span class="w">    </span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="reader-writer-kernel-runtime-args">
<h2>Reader/writer kernel runtime args<a class="headerlink" href="#reader-writer-kernel-runtime-args" title="Permalink to this heading"></a>
</h2>
<p>Here, we introduce the concept of looping over all cores to apply an API.</p>
<p>In this case, we must set runtime args for reader/writer kernels. Note that we
also must take care to account for the split groups of cores and to use the
appropriate tile count when assigning args.</p>
<div class="highlight-cpp notranslate">
<div class="highlight"><pre><span></span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">num_tiles_written</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_cores</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">){</span>

<span class="w">    </span><span class="n">CoreCoord</span><span class="w"> </span><span class="n">core</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">i</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">num_cores_y</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">num_cores_y</span><span class="p">};</span>

<span class="w">    </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">num_output_tiles_per_core</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">core_group_1</span><span class="p">.</span><span class="n">core_coord_in_core_ranges</span><span class="p">(</span><span class="n">core</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">num_output_tiles_per_core</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_output_tiles_per_core_group_1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">core_group_2</span><span class="p">.</span><span class="n">core_coord_in_core_ranges</span><span class="p">(</span><span class="n">core</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">num_output_tiles_per_core</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_output_tiles_per_core_group_2</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">TT_ASSERT</span><span class="p">(</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="s">"Core not in specified core ranges"</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="n">tt_metal</span><span class="o">::</span><span class="n">SetRuntimeArgs</span><span class="p">(</span>
<span class="w">        </span><span class="n">program</span><span class="p">,</span><span class="w"> </span><span class="n">reader_id</span><span class="p">,</span><span class="w"> </span><span class="n">core</span><span class="p">,</span>
<span class="w">        </span><span class="p">{</span><span class="n">src0_addr</span><span class="p">,</span>
<span class="w">        </span><span class="n">src1_addr</span><span class="p">,</span>
<span class="w">        </span><span class="n">Mt</span><span class="p">,</span>
<span class="w">        </span><span class="n">Kt</span><span class="p">,</span>
<span class="w">        </span><span class="n">Nt</span><span class="p">,</span>
<span class="w">        </span><span class="n">MtKt</span><span class="p">,</span>
<span class="w">        </span><span class="n">KtNt</span><span class="p">,</span>
<span class="w">        </span><span class="n">B</span><span class="p">,</span>
<span class="w">        </span><span class="kt">uint32_t</span><span class="p">(</span><span class="n">bcast_batch</span><span class="p">),</span>
<span class="w">        </span><span class="n">num_tiles_written</span><span class="p">,</span>
<span class="w">        </span><span class="n">num_output_tiles_per_core</span><span class="p">,</span>
<span class="w">        </span><span class="n">MtNt</span><span class="w"> </span><span class="p">}</span>
<span class="w">    </span><span class="p">);</span>
<span class="w">    </span><span class="n">tt_metal</span><span class="o">::</span><span class="n">SetRuntimeArgs</span><span class="p">(</span>
<span class="w">        </span><span class="n">program</span><span class="p">,</span>
<span class="w">        </span><span class="n">writer_id</span><span class="p">,</span>
<span class="w">        </span><span class="n">core</span><span class="p">,</span>
<span class="w">        </span><span class="p">{</span><span class="n">dst_addr</span><span class="p">,</span>
<span class="w">        </span><span class="n">num_output_tiles_per_core</span><span class="p">,</span>
<span class="w">        </span><span class="n">num_tiles_written</span><span class="w"> </span><span class="p">}</span>
<span class="w">    </span><span class="p">);</span>
<span class="w">    </span><span class="n">num_tiles_written</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">num_output_tiles_per_core</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this heading"></a>
</h2>
<p>Those are all the major changes that we made in order to upgrade our single
core matmul example into one that will use as many cores as possible.  To see a more complicated example using data reuse among these cores, please refer to please refer to the <a class="reference internal" href="matmul_multi_core_optimizations/data_reuse.html#matmul-multi-core-data-reuse-example"><span class="std std-ref">Matmul
multi-core data reuse example</span></a>.</p>
</section>
</section>



           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="matmul_single_core.html" class="btn btn-neutral float-left" title="Matmul (Single Core)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="matmul_multi_core_optimized.html" class="btn btn-neutral float-right" title="Matmul (Multi Core Optimized)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Tenstorrent.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        Version: v0.49.0
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        
        <dl>
            <dt>Versions</dt>
            
            <dd><a href="https://tenstorrent.github.io/docs-test/tt-metalium/latest/index.html">latest</a></dd>
            
            <dd><a href="https://tenstorrent.github.io/docs-test/tt-metalium/v0.49.0/index.html">v0.49.0</a></dd>
            
        </dl>
        
        <br>
        </dl>
    </div>
</div>
<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>